{"posts":[{"title":"踩坑与收获：2025独立开发者Google Play上架实战复盘","text":"背景与初衷入行安卓开发已有一段时间。学生时期曾注册并使用过Google Play 开发者账号，在当时的审核环境下完成过多款应用的发布与实践。 随着平台政策和合规要求的持续调整，该历史账号已主动终止使用，相关应用亦已停止维护。该阶段的经历主要作为个人技术成长过程的一部分予以记录。 最近一段时间，出于对Compose的兴趣，我边学边做，开发了一款安卓平台的ESP32烧录工具，命名为ESPFlash 开端：注册开发者账号上架Play Store的第一步，是使用谷歌账号支付25美元注册成为Play开发者。注册链接是https://play.google.com/console/signup 作为个人开发者，我选择注册个人类型的账号。 填写完基本信息后，输入信用卡信息完成扣款。我使用的是学生时代办理的交通银行Youth Power卡，支持银联和VISA。 创建应用和完善信息在开发者控制台创建应用后，需要填写基本信息，并准备应用截图和隐私政策页面。 尺寸符合要求即可。若追求美观，可使用 theapplaunchpad 或 app-mockup-mockup 等在线工具生成。 隐私政策：这是关键。即使你的APP是工具类，未主动收集用户数据，但只要接入了Firebase、AdMob等第三方SDK，就必须在隐私政策中明确告知。我使用 free privacy policy 这类工具生成内容，并托管在自己的域名下。 封闭测试：在开发者社区找人“搭伙”这是整个流程里最消磨耐心的地方。按照谷歌的新政策，新注册的个人账号必须找齐12个人，连续不间断地测试14天才能申请正式上架。 刚看到这个要求时我是一头雾水的——身边哪来那么多安卓用户，还得天天帮我点开APP？好在后来我摸到了Reddit的 AndroidClosedTesting 板块。这地方简直是独立开发者的“互助加油站”，大家都在面临同样的困境。 我在社区里发了贴，很快就凑够了人头。这种互助是双向的：别人帮我测，我也得帮别人测。那两周我手机里装了五六十个奇奇怪怪的 APP，每天的任务就是挨个点开刷一遍。虽然有点累，但看着测试进度一天天走完，心里确实踏实了不少。 国内也可以在V2EX的分享创造板块发布自己的APP, 凭借我潜水多年的经验了. 看到过不少开发者发布自己的APP后, 堆起万丈高楼(夸张了,几百层还是有的). 正式版14天测试期满后，即可在控制台提交正式版发布申请。约3天后，我收到了审核未通过的邮件，要求整改。排查后发现，问题很可能出在隐私政策上——初始版本未充分说明Firebase和AdMob的数据处理情况。 更新隐私政策并重新提交后，仅用了几个小时就审核通过，成功上架Google Play。 总结 政策研究要先行：尤其关注测试和隐私政策要求。 封闭测试：别硬扛，去社区找同伴。互助测试比自己找亲戚朋友靠谱得多。 隐私政策无小事：必须覆盖所有第三方SDK的行为。 耐心与细致：审核被拒是常态，仔细阅读反馈，针对性修改。 后续差不多过了一个月,迎接了第一份付费用户.","link":"/2025-Google-Play-%E4%B8%AA%E4%BA%BA%E5%BC%80%E5%8F%91%E8%80%85%E4%B8%8A%E6%9E%B6%E8%AE%B0%E5%BD%95/"},{"title":"改装米家1代屏幕挂灯,接入HomeKit","text":"前言我住的屋子床头没有插座也没有控制房间顶灯的开关,假如熄灯睡觉的话会让房间陷入一片漆黑.所以很长一段时间里我都把米家屏幕挂灯的控制器放在床头,用于临时照明.这就引发了另外一个问题,每次回家开电脑打开屏幕挂灯,我都得走到床头找到控制器开启屏幕挂灯.在经历了多次麻烦后,我决定把这个屏幕挂灯接入HomeKit. 这样就可以用语音或者手机控制了. 资料搜集在阅读了这篇拆解报告：MJ米家显示器挂灯MJGJD01YL后, 需要做的工作就很明确了.大致分为以下几个步骤 阅读手册,找到控制引脚 拆除芯片,替换成ESP32 编写代码,接入HomeKit 阅读手册,找到控制引脚看完拆解报告后,得知亮度由TLSR8368和SY7301A芯片控制实现, 两款芯片的资料很容易在Google上搜索到.基本上可以确定是由TLSR8368发送PWM信号给SY7301A进行调光. TLSR8368一共就16个引脚, 对照手册配合示波器挨个测量控制引脚测出PWM引脚是由#3,#5产生, 还有一个引脚#8用于使能SY7301A芯片. 测量出引脚如下 拆除芯片,替换成ESP32到了这一步需要选择合适尺寸的芯片,然后重新绘制一块板子寄生在原始位置即可. 拆除原来的TLSR8368以后,留下的空间还算宽敞.选用尺寸较小的ESP32-C3(对应的型号名称是ESP8685), 封装为QFN28 4x4mm 这里右半部分的TypeC和LDO部分将会在在烧录后折断, 后续固件可以通过4P 2mm间距探针或者OTA进行更新. 附上一张初版焊接后的图片, 初版为之前没有预留可折断TypeC部分的版本. 编写代码,接入HomeKit得益于HomeSpan这个库,需要编写的代码很简单. 目前实现了白色LED的调光, 由于我损坏了暖黄色LED控制引脚的阻焊,导致最终版本未能实现色温调节功能。 因此，以下代码主要演示了如何控制白色LED的开关与调光 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869##include &lt;Arduino.h&gt;##include &quot;HomeSpan.h&quot;##include &quot;extras/PwmPin.h&quot; // library of various PWM functions////////////////////////////////////struct FadingLED : Service::LightBulb { LedPin *ledPin; // reference to Led Pin SpanCharacteristic *power; // reference to the On Characteristic SpanCharacteristic *level; // reference to the Brightness Characteristic SpanCharacteristic *colorTemperature; // reference to the Color Temperature FadingLED(int _ledPin) : Service::LightBulb() { power = new Characteristic::On(); level = new Characteristic::Brightness(0); colorTemperature = new Characteristic::ColorTemperature(200, true); ledPin = new LedPin(_ledPin); } boolean update() { Serial.printf(&quot;power-&gt;getNewVal()=%d&quot;, power-&gt;getNewVal()); Serial.printf(&quot;,level-&gt;getNewVal()=%d&quot;, level-&gt;getNewVal()); Serial.printf(&quot;,colorTemperature-&gt;getNewVal()=%d\\n&quot;, colorTemperature-&gt;getNewVal()); ledPin-&gt;fade(power-&gt;getNewVal() * level-&gt;getNewVal(), 2000, LedPin::PROPORTIONAL); while (ledPin-&gt;fadeStatus() == LedPin::FADING) ; return (true); } void loop() override { if (ledPin-&gt;fadeStatus() == LedPin::COMPLETED) { power-&gt;setVal(1 - power-&gt;getVal()); level-&gt;setVal(power-&gt;getVal() ? 100 : 0); } }};//////////////////////////////////void setup() { pinMode(5, OUTPUT); pinMode(10, OUTPUT); digitalWrite(5, HIGH); digitalWrite(10, LOW); Serial.begin(115200); digitalWrite(10, HIGH); Serial.println(&quot;Wi-Fi is Connected!&quot;); homeSpan.enableOTA(&quot;12345678&quot;); homeSpan.setPairingCode(&quot;11223344&quot;); homeSpan.begin(Category::Lighting, &quot;Lamp++&quot;); new SpanAccessory(); new Service::AccessoryInformation(); new Characteristic::Identify(); new Characteristic::ColorTemperature(200, true); new FadingLED(4);}//////////////////////////////////////void loop() { homeSpan.poll();} 123456789101112[env:airm2m_core_esp32c3]platform = espressif32@5.4.0board = airm2m_core_esp32c3framework = arduinomonitor_speed = 115200lib_deps = homespan/HomeSpan@^1.8.0; upload_protocol = espota; upload_flags = --auth=12345678; upload_port = 192.168.0.104build_flags = -D ARDUINO_USB_MODE=1 -D ARDUINO_USB_CDC_ON_BOOT=1 效果展示 参考资料 拆解报告：MJ米家显示器挂灯MJGJD01YL","link":"/Add-your-Xiaomi-Yeelight-Monitor-Light-Bar-to-HomeKit-with-ESP32-C3/"},{"title":"Claude Code初体验","text":"背景之前买的Jetpack Compose教程的群群主最近一直在称赞Codex,Claude Code之类的有多么强大, 激发了我对这种CLI式的AI兴趣.是时候研究一下了. 初步了解在哔哩哔哩上简单搜索到几个介绍视频, 尤其是看到了Codex的那个演示, 一个人下发多个任务,然后每个任务后面都有一个AI在不同分支为他自动修改代码,调试代码直到完成任务,更是迫不及待的体验一下这种一个人就是一个团队的力量. 获取APIOpenAI和Claude的政策原因(还有我的卡无法直接付款购买), 所以我没有选择直接购买Chat GPT Plus和Claude Pro.综合考虑我选择代理公司提供的API中转服务.这种方式优点是便宜, 而且既能用Codex也能用Claude, 还无需配置额外的网络代理.为了获得较好的体验,我购买了160美元的额度.主流的模型都是以token来计费, 代理商还会根据模型类型设置不同的倍率,比如codex是0.5倍率, claude则是正常的1倍率. 安装Codex和Claude CodeCodex和Claude Code都提供了插件式和命令行形式的使用方法.出于灵活性考虑,我没有选择插件式安装,因为我不确定Idea的插件能否直接在Android Stduio的上使用.最终选择了CLI方式安装和使用,这样不管我用什么代码编辑器或者IDE均可以使用. 两个工具的CLI版本安装方式都很简单, 官方均提供安装脚本方法. 安装Codex1npm i -g @openai/codex 如果使用openai官方账号, 这时候控制台输入codex启动后按照说明打开浏览器登录即可.我用的是代理, 下一节会说明API的配置. 安装claude code1irm https://claude.ai/install.ps1 | iex 和Codex类似, 如果用的是Claude官方账号, 启动后按照说明打开浏览器登陆. 配置API因为用的是中转,所以我需要额外配置才可以正常使用.好在我的中转商提供命令配置工具, 让这件事变得不再费心. 安装88-auto-config配置工具这里我使用88code提供的命令行配置工具 1npm install -g 88-auto-config 启动配置工具12345678[1] 配置 Claude Code (已安装)[2] 配置 Codex (已安装)[3] 配置 Claude Code + Codex 🚀 (推荐新手使用)[4] 自定义选择[5] 配置 Droid 自定义模型 (自动配置三个模型)[8] 检测配置是否生效 🔍[9] 配置 VS Code Claude 插件 📝[0] 退出直接输入3, 回车, 再输入88code创建的API, 回车即可. 保存配置source ~/.zshrc刷新终端缓存或者重启终端 暂时放弃codex不知道什么原因,我的codex无法正常使用,总是报401错误. 后面单独开一个新的坑来分析和排查究竟为什么无法使用.于是转而使用claude code,等将来会再次回来用用codex,因为他的token消耗速率只有一半. 第一个任务进入到项目工程目录后,输入claude,再使用/init命令让claude分析当前工程,创建基础的配置.配置创建完成之后,根目录则会生成一个CLAUDE.md, 里面记录了Claude对项目的理解. 我们也可以手动修改CLAUDE.md内容补充说明或者纠正.检查CLAUDE.md内容无误后, 我告诉Claude希望Claude能为我的烧录软件开发串口监视器部分.而此前我已经预留了底部NavigationBar的路由和占位页面, 不知道他会开发到什么程度, 还要求Claude考虑串口占用问题.对话完成后,Claude开始工作, 接下来的过程中他自己会检测语法错误, 并且会调用编译检查编译是否成功.活脱脱一个真实的人在写代码. 验收Claude开发完成了,终端响了一声, 这是提醒我验收的时刻到了.怀着期待和未知的心情输入了ctrl+r, 看到实际效果后十分震惊,不亚于第一次使用ChatGPT那种震撼.除了UI适配上有些小问题, 整个串口监视器功能上来说很完善, 甚至还用上一个BottomSheet来进行串口参数配置. 最后 后续又用2天来继续完善APP功能, 比如串口输出文本着色, 排查ESP8266上无法dump固件等问题.尤其是这个dump固件问题的处理, 我在Claude的配合下, 花费不少token去分析dump出来的固件, 最终排查出来是SLIP包的解码存在问题, 坦白说我没有自信和能力排查出这个问题. 仅仅是用了两天,我就已经上瘾了, 就像现在很难再去通过传统搜索引擎去排查问题而直接借助AI来编程一样.","link":"/Claude-Code%E5%88%9D%E4%BD%93%E9%AA%8C/"},{"title":"DWM3001CDK点亮WS2812 RGB LED","text":"背景去年参加了FastBond的第四期活动, 为了能够白嫖到这块开发板子, 不得不掏出这块板子在Deadline之前完成一个项目.看了下活动要求, 感觉点灯是最简单的. 不过既然点灯了, 就点个稍微有点难度的吧.比如点亮能让性能增加200%的WS2812 RGB LED. 开发板介绍 板子上带有DWM3001C模块 可以和Apple U1 chip &amp; U2 互操作 支持UWB channels 5 (6.5 GHz) and 9 (8 GHz) 板载J-Link用于调试和烧录 USB接口用于直接连接DWM3001C USB接口 26 pin 树莓派兼容接口 带有reset和一个用户按钮,板载LED 所有的DWM3001C GPIOs和接口都引出 DWM3001C内部具有一个nRF52833芯片,实际的代码其实就是运行在这颗芯片上.开发工具也都是基于nRF52833的SDK. 控制普通LEDnRF的文档和资料都很齐全, 不仅有点灯的例子, 连板子的LED和Button的引脚定义也都预定义好了. 话不多说 , 直接打开官方的例子看看.虽然之前完全没接触过nRF的SDK, 但是基于以前ESP开发经验, 理解示例代码并不困难. 示例工程启动时候会看到板载的4颗LED会闪烁, 对着启动代码查抄到实际代码是 1234567891011121314void BoardInit(void){ bsp_board_init(BSP_INIT_LEDS | BSP_INIT_BUTTONS); peripherals_init(); for (int i = 0; i &lt; 6; i++) { bsp_board_led_invert(BSP_BOARD_LED_0); bsp_board_led_invert(BSP_BOARD_LED_1); bsp_board_led_invert(BSP_BOARD_LED_2); bsp_board_led_invert(BSP_BOARD_LED_3); nrf_delay_ms(250); }} 甚至连LED控制也贴心的封装好了,bsp_board_led_on和bsp_board_led_off, 同时还看到了在串口刷新时候闪烁LED的代码123456789101112static void logger_thread(void *arg) { UNUSED_PARAMETER(arg); while (1) { NRF_LOG_FLUSH(); bsp_board_led_on(BSP_BOARD_LED_1); nrf_delay_ms(1); bsp_board_led_off(BSP_BOARD_LED_1); nrf_delay_ms(1); vTaskSuspend(NULL); // Suspend myself }} 编写WS2812的驱动驱动WS2812的办法有很多, 视情况选择最合适的驱动方式. IO模拟(Bit-Banging)这是最经典的方式, 如果芯片比较简单, 没有SPI接口, 或者SPI接口被占用了, 可以考虑使用IO模拟. 缺点是消耗CPU资源. Arduino Uno就是用这种方式驱动WS2812的1. PWM + DMA模拟这个方式相当于IO模拟的优化版本, 引入DMA之后, 释放了CPU资源压力. SPI模拟这是一种曲线救国办法, 利用SPI的发送机制来模拟WS2812的协议, 适合SPI接口空闲的场景.配合SPI DMA的情况下, 几乎不消耗CPU资源. RMT模拟这是ESP32芯片的驱动方式, 利用RMT外设来模拟WS2812的协议.最为优雅, 模拟的时序非常精准, 且不需要CPU干预.2. 最终选择考虑到实现难度和实际效果, 我决定采用SPI模拟的办法在DWM3001CDK上实现WS2812的驱动模拟. 驱动编写参照https://www.cnblogs.com/milton/p/17892606.html, 将其中的spi驱动修改为nrf52833版本.编写初始化SPI代码123456789101112131415void ws2812_init(void) { nrf_gpio_cfg_output(30); nrf_gpio_cfg_output(27); nrf_gpio_cfg_output(31); memset(ws2812_buffer, 0, WS2812_BUFFER_SIZE); nrf_drv_spi_config_t spi_config = NRF_DRV_SPI_DEFAULT_CONFIG; spi_config.ss_pin = NRF_GPIO_PIN_MAP(0, 30); spi_config.miso_pin = NRF_DRV_SPI_PIN_NOT_USED; spi_config.mosi_pin = NRF_GPIO_PIN_MAP(0, 27); spi_config.sck_pin = NRF_GPIO_PIN_MAP(0, 31); spi_config.frequency = NRF_DRV_SPI_FREQ_4M; spi_config.mode = NRF_DRV_SPI_MODE_0; // SPI 模式 0 int spi_ret = nrf_drv_spi_init(&amp;spi, &amp;spi_config, spi_event_handler, NULL); NRF_LOG_ERROR(&quot;ws2812_init() = %d&quot;, spi_ret);} 编写发送函数代码123456789NRF_LOG_INFO(&quot;ws2812_send_spi()&quot;);APP_ERROR_CHECK(nrf_drv_spi_transfer(&amp;spi, ws2812_buffer, WS2812_BUFFER_SIZE, NULL, 0));while (!spi_xfer_done) { __WFE();}// 发送复位信号（保持 MOSI 低电平至少 50µs）nrf_gpio_pin_clear(NRF_GPIO_PIN_MAP(0, 27));nrf_delay_us(50);需要修改nrf_drv_spi_transfer声明和定义,将第三个参数修改为size_t类型, 不然无法一次性传输WS2812_BUFFER_SIZE大小的数据导致颜色异常. 编写颜色设置函数, 增加颜色转换函数.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566void ws2812_pixel(uint16_t led_no, uint8_t r, uint8_t g, uint8_t b) { uint8_t *ptr = &amp;ws2812_buffer[led_no * 24]; WS2812_FILL_BUFFER(g); WS2812_FILL_BUFFER(r); WS2812_FILL_BUFFER(b);}void ws2812_pixel_all(uint8_t r, uint8_t g, uint8_t b) { uint8_t *ptr = ws2812_buffer; for (uint16_t i = 0; i &lt; WS2812_NUM_LEDS; ++i) { WS2812_FILL_BUFFER(g); WS2812_FILL_BUFFER(r); WS2812_FILL_BUFFER(b); }}void hsv_to_rgb(uint8_t h, uint8_t s, uint8_t v, uint8_t *r, uint8_t *g, uint8_t *b) { uint8_t region, remainder, p, q, t; if (s == 0) { *r = v; *g = v; *b = v; return; } region = h / 43; remainder = (h - (region * 43)) * 6; p = (v * (255 - s)) &gt;&gt; 8; q = (v * (255 - ((s * remainder) &gt;&gt; 8))) &gt;&gt; 8; t = (v * (255 - ((s * (255 - remainder)) &gt;&gt; 8))) &gt;&gt; 8; switch (region) { case 0: *r = v; *g = t; *b = p; break; case 1: *r = q; *g = v; *b = p; break; case 2: *r = p; *g = v; *b = t; break; case 3: *r = p; *g = q; *b = v; break; case 4: *r = t; *g = p; *b = v; break; default: *r = v; *g = p; *b = q; break; }} 最后加上经典的渐变函数 12345678910111213141516171819202122232425262728293031323334353637void ws2812_row_gradient(uint16_t i) { for (uint8_t row = 0; row &lt; WS2812_ROWS; row++) { for (uint8_t col = 0; col &lt; WS2812_COLS; col++) { // 计算当前 LED 的色相值 uint8_t hue = (i + row * 256 / WS2812_ROWS) % 256; uint8_t r, g, b; // 将 HSV 转换为 RGB，亮度设置为 50 hsv_to_rgb(hue, 255, 16, &amp;r, &amp;g, &amp;b); // 计算 LED 索引 uint16_t led = row * WS2812_COLS + col; // 设置 LED 颜色 ws2812_pixel(led, r, g, b); } }}void ws2812_col_gradient(uint16_t i) { for (uint8_t col = 0; col &lt; WS2812_COLS; col++) { for (uint8_t row = 0; row &lt; WS2812_ROWS; row++) { // 计算当前 LED 的色相值 uint8_t hue = (i + col * 256 / WS2812_COLS) % 256; uint8_t r, g, b; // 将 HSV 转换为 RGB，亮度设置为 50 hsv_to_rgb(hue, 255, 50, &amp;r, &amp;g, &amp;b); // 计算 LED 索引 uint16_t led = row * WS2812_COLS + col; // 设置 LED 颜色 ws2812_pixel(led, r, g, b); } }} 第一颗灯珠颜色异常修复上面的代码编写完成烧录运行后, 发现第一个灯珠总是绿色,一番搜索后找到了修复办法, 核心思想是就是在发送数据前, 先发送几个零字节.3 所以我们为buffer增加头部零字节1234#define WS2812_NUM_LEDS 60 // 6x10 灯板，共 60 个 LED#define WS2812_RESET_PULSE 60#define WS2812_EXTRA_ZEROS 4 // 添加 4 个零字节#define WS2812_BUFFER_SIZE (WS2812_NUM_LEDS * 24 + WS2812_RESET_PULSE + WS2812_EXTRA_ZEROS) 同时更新初始化代码, 颜色设置和发送函数123456789101112131415161718void ws2812_send_spi(void) { NRF_LOG_INFO(&quot;ws2812_send_spi()&quot;); memset(ws2812_buffer, 0, WS2812_EXTRA_ZEROS); APP_ERROR_CHECK(nrf_drv_spi_transfer(&amp;spi, ws2812_buffer, WS2812_BUFFER_SIZE, NULL, 0)); while (!spi_xfer_done) { __WFE(); } // 发送复位信号（保持 MOSI 低电平至少 50µs） nrf_gpio_pin_clear(NRF_GPIO_PIN_MAP(0, 27)); nrf_delay_us(50);}void ws2812_pixel(uint16_t led_no, uint8_t r, uint8_t g, uint8_t b) { uint8_t *ptr = &amp;ws2812_buffer[WS2812_EXTRA_ZEROS + led_no * 24]; WS2812_FILL_BUFFER(g); WS2812_FILL_BUFFER(r); WS2812_FILL_BUFFER(b);} 再次编写测试代码,检查最终效果是否正常1234567891011ws2812_init();uint16_t i = 0;while (1) { // 列渐变效果 ws2812_col_gradient(i); ws2812_send_spi(); nrf_delay_ms(5); // 更新色相值 i = (i + 1) % 256;}这一次第一个LED终于听话了. 数字显示手动编写一个字库, 并且按照对应的位置填充到buffer中.实际运行如下.这里我接了一个温湿度传感器, 屏幕会用不同颜色展示温度和湿度数值.上图中展示的是当前湿度53%. 总结通过 SPI 模拟时序驱动 WS2812 是一种在硬件资源受限且无 RMT 外设的情况下的绝佳选择。在 DWM3001CDK 上实现这一功能，不仅达到了 FastBond 项目的要求，也为后续开发更复杂的 UWB 定位可视化界面打下了基础。 1. https://github.com/adafruit/Adafruit_NeoPixel/blob/master/Adafruit_NeoPixel.cpp ↩ 2. https://docs.espressif.com/projects/arduino-esp32/en/latest/api/rmt.html ↩ 3. https://www.reddit.com/r/arduino/comments/499ods/strip_of_144_ws2812b_leds_first_led_stuck_green/ ↩","link":"/DWM3001CDK-spi-ws2812-driver/"},{"title":"屏幕不够，算法来凑(二)：ESP32 单色屏上的 Ditherpunk 实战","text":"0x00 序在上一篇文章中，我们在浏览器中通过 JavaScript 模拟了各种抖动算法的视觉效果。虽然原理通透了，但真正的挑战在于硬件端：如何在资源受限的嵌入式设备上复现这些效果？ 本文将记录我基于 ESP32-S3 和一块 1.54 寸 ST7305 单色屏的实战过程，探讨如何在单片机上实现从基础的阈值法到复杂的误差扩散等多种图像处理算法。 0x01 硬件环境 MCU: ESP32-S3 (当然，普通的 ESP32 甚至 ESP8266 也完全足以胜任) 屏幕: 1.54 inch Monochrome Display 鱼鹰光电单色屏幕 驱动: ST7305 (这种控制器也常见于一些黑白双色或黑白红三色的小尺寸墨水屏) 分辨率: 200 x 200 (1-bit Monza, 纯黑白) 选择 ESP32-S3 主要是因为其内置的大容量 SRAM（512KB+）和对 PSRAM 的支持，让我们在处理 200x200（只要 5KB）甚至更高分辨率的图像缓冲区时游刃有余。而 ST7305 是一款主要用于点阵电子纸显示器的驱动芯片，通过 SPI 接口通信。 0x02 核心挑战在 PC 网页端，我们有 Float32Array 和近乎无限的内存。但在 ESP32-S3 上，我们需要关注： 内存管理：尽量复用 Buffer，避免频繁 malloc/free 产生内存碎片。 Gamma 校正：必须在 C 语言中手动实现 Gamma Table，否则画面会严重偏暗。 驱动适配：屏幕通常需要较为复杂的 SPI 初始化序列，特别是针对不同的屏幕玻璃面板，需要配置正确的电压和驱屏波形。 0x03 代码实现详解项目工程结构如下：12345main/├── blue_noise.h // 预计算的蓝噪声纹理数组├── esp_lcd_st7305.c // 屏幕驱动实现├── hello_world_main.c// 核心逻辑与算法实现└── sample_img.h // 测试用灰度图片数组 建立 Gamma 查找表 (LUT)正如第一篇所述，这是最关键的一步。如果不做 Gamma 校正，线性空间的抖动算法处理 sRGB 图片时，中间调会偏暗。由于 powf 函数在嵌入式上计算非常昂贵，我们绝对不能对每个像素实时计算。为了性能，我们在启动时预计算一个 256 长度的查找表。 123456789// Gamma correction LUT (0-255 -&gt; 0.0-1.0 linear)static float s_gamma_lut[256];void init_gamma_lut() { for (int i = 0; i &lt; 256; i++) { // sRGB to Linear: ((val / 255.0) ^ 2.2) s_gamma_lut[i] = powf(i / 255.0f, 2.2f); }} 任何后续的像素读取，都通过 s_gamma_lut[pixel] 来获取其线性亮度值。这是一种经典的空间换时间策略。 基础算法：Threshold &amp; Random最简单的算法往往是很好的基准线。 Threshold (阈值法) ：也就是二值化。这是最快的方法，但也是效果最差的方法。12345678void dither_threshold(const uint8_t *src, uint8_t *dst) { memset(dst, 0, ST7305_FRAMEBUFFER_SIZE); for (int i = 0; i &lt; ST7305_WIDTH * ST7305_HEIGHT; i++) { float val = s_gamma_lut[src[i]]; bool white = val &gt; 0.5f; set_pixel_1bit(dst, i % ST7305_WIDTH, i / ST7305_WIDTH, white); }}实拍效果：细节大量丢失，俗称“两色图”。它只能保留最硬的边缘，几乎完全丢失了所有的灰度信息。 Random (随机抖动)为了找回丢失的灰度，我们引入 rand() 来打破量化阶梯。通过给每个像素值增加一个随机噪声，使得原本在阈值附近的像素有一半概率翻转，从而宏观上表现出灰度。 12float noise = ((float)rand() / RAND_MAX) - 0.5f; // -0.5 to 0.5bool white = (val + noise) &gt; 0.5f; 实拍效果：虽然有灰度感了，但画面非常脏，充满了白噪声。这种高频噪声在人眼看来就是“雪花点”，并不讨喜。 有序抖动：Bayer Matrix有序抖动非常适合没有 Framebuffer 的超低端单片机（如 Arduino Uno, ATtiny85），因为它是 Point-Operation（点操作），不需要知道邻居像素的信息，也不需要存储上一行的误差。我们可以对每个像素独立计算。 123456789static const float s_bayer_matrix[4][4] = { {0.0f / 16.0f, 8.0f / 16.0f, 2.0f / 16.0f, 10.0f / 16.0f}, {12.0f / 16.0f, 4.0f / 16.0f, 14.0f / 16.0f, 6.0f / 16.0f}, // ... complete matrix};// Inside loopfloat threshold = s_bayer_matrix[y % 4][x % 4];bool white = (val &gt; threshold); 实拍效果：经典的十字交叉网纹。这种风格在复古 GameBoy 游戏和早期的 Macintosh 系统中非常常见。它通过规则的纹理来模拟灰度，虽然看起来有点“人工”，但比随机抖动干净得多。 误差扩散：Floyd-Steinberg &amp; Atkinson对于支持 Framebuffer 的设备（ESP32 有足够 RAM），误差扩散是最佳选择。你需要一个浮点数 Buffer 来存储扩散过程中的误差。 Floyd-Steinberg 是教科书般的标准，扩散系数为 7, 3, 5, 1 (/16)。它试图将量化产生的每一个误差都完美地分配给邻居，从数学上讲是最精确的。实拍效果： Atkinson 则更适合这种高解析度但低色深的屏幕。它由 Bill Atkinson 设计，不像 Floyd-Steinberg 那样保留 100% 的误差，而是只保留 75% 的误差用于扩散，这就人为制造了一些“死黑”和“死白”区域。这听起来像是缺点，但在低对比度的单色屏上，但这反而增加了局部对比度，让图像看起来更清晰锐利，减少了“蠕虫”伪影。 12345678// Distribute 1/8 to neighbors (Atkinson)float err_part = quant_error / 8.0f;if (x + 1 &lt; ST7305_WIDTH) work_buf[y * ST7305_WIDTH + x + 1] += err_part;if (x + 2 &lt; ST7305_WIDTH) work_buf[y * ST7305_WIDTH + x + 2] += err_part;// ... bottom neighbors 实拍效果：这是我在这块屏上最喜欢的算法。线条硬朗，质感极佳，特别适合显示文字和 icon 混合的 UI 界面。 别有风味：Blue Noise (蓝噪声)如果在嵌入式设备上想要模拟胶片感，蓝噪声是唯一的选择。它的计算成本和 Bayer 一样低（只需要查表），但效果却能通过“排列无序但分布均匀”的噪点来欺骗人眼。 我们需要将一张预计算好的蓝噪声纹理转换成 C 数组 (blue_noise.h) 存储在 Flash 中。这意味着你需要牺牲几十 KB 的 Flash 空间来换取这种效果。 123// Map 0-255 texture to 0.0-1.0float threshold = blue_noise_map[(y % BN_H) * BN_W + (x % BN_W)] / 255.0f;bool white = (val &gt; threshold); 实拍效果：非常自然的颗粒感，没有任何规律性条纹，就像一张老照片。这种算法特别适合显示人像和风景摄影。 0x04 总结在 ESP32 这种级别的 MCU 上，我们完全可以实现高质量的即时图像抖动。不同的算法适用于不同的场景： Bayer 有序抖动：计算开销最小，适合资源极端受限（如不带 RAM 的低端单片机）或复古风格游戏。 Atkinson：对比度最高，边缘清晰，适合 UI 界面、文字混排场景。 Blue Noise：颗粒感自然，适合显示摄影图片，但需要额外的 Flash 空间存储纹理。 希望本文能为你在单色屏幕开发中提供一些思路。 0x05 参考资料 Kevincoooool/esp_lcd_st7305 - 本文 ST7305 驱动移植参考 DuRuofu/esp-idf-st7305-Ink-screen - 另一个优秀的 ST7305 驱动实现","link":"/Ditherpunk-The-Art-of-Dithering-2-ESP32/"},{"title":"ESP-IDF 插件：用 embed_txtfiles 优雅地在固件里“塞”文件","text":"0x00 背景最近在翻看 GSC (Google Search Console) 的搜索关键词时，发现 esp-idf embed-txtfiles 这个词的出现频率高得惊人。看来大家在搞 ESP32 开发的时候，都被“如何在固件里优雅地放一个文件”这个问题困扰过。 在此之前，我为了实现一些功能（比如之前的那个桌面像素小屏幕），曾傻乎乎地把图片全转成了巨大的 C 数组（.h 文件）。结果可想而知：代码文件膨胀到几万行，IDE 索引卡死，每次微调一个像素都要重新编译半天，简直是灾难。 不管是 HTTPS 的根证书、前端 HTML 页面，还是简单的配置文件，如果全都写成巨大的 const char[] 硬编码到代码里，那工程维护简直是自我折磨。今天就拿着我那块斥 9.9 元巨资买回来的 ESP32-C3 演示一下如何用 ESP-IDF 里的这个黑科技优雅地填坑。 0x01 方案对比为什么推荐使用 embed_txtfiles？我们可以先看一张直观的对比表： 方案 优点 缺点 适用场景 C 数组 (.h) 零环境要求，哪里都能编 破坏代码整洁，编译极慢 极小的资源（如 8x8 字体） 文件系统 (SPIFFS) 动态读写，空间大 需手工配置分区表，访问繁琐 大量图片、用户日志 embed_txtfiles 原生格式，访问极快，零配置 固件只读，增加 Bin 体积 CA证书、网页模板、默认配置 0x02 快速上手ESP-IDF 构建系统（基于 CMake）允许你直接把磁盘上的二进制文件或文本文件，在编译阶段自动转换并“缝合”进你的 .bin 固件中。 0x00 准备资源文件在你的项目或组件目录下创建一个文件夹（例如 assets），把你的文本文件（比如 hello.txt）放进去。 0x01 修改 CMakeLists.txt在组件目录下的 CMakeLists.txt 里，只需要在 idf_component_register 函数里通过 EMBED_TXTFILES 参数指定路径： 1234## main/CMakeLists.txtidf_component_register(SRCS &quot;main.c&quot; INCLUDE_DIRS &quot;.&quot; EMBED_TXTFILES &quot;assets/hello.txt&quot;) 0x02 在 C/C++ 代码中调用编译系统自动生成了三个全局符号。它们的命名规则是：_binary_[文件名]_[扩展名]_start 和 _binary_[文件名]_[扩展名]_end。 12345678910111213141516##include &lt;stdio.h&gt;##include &quot;esp_log.h&quot;// 0x01. 声明外部资源变量extern const uint8_t hello_txt_start[] asm(&quot;_binary_hello_txt_start&quot;);extern const uint8_t hello_txt_end[] asm(&quot;_binary_hello_txt_end&quot;);void app_main(void){ // 0x02. 获取资源长度 size_t size = hello_txt_end - hello_txt_start; // 因为是 txtfiles，所以末尾自带 \\0，可以直接作为字符串处理 ESP_LOGI(&quot;APP&quot;, &quot;Embedded file content: %s&quot;, (char *)hello_txt_start); ESP_LOGI(&quot;APP&quot;, &quot;File Size: %d bytes&quot;, size);} Tips： 如果你使用的是 .cpp 文件，请务必给声明加上 extern &quot;C&quot;，否则会因为 Name Mangling 导致链接找不到符号。 0x03 填坑：那些让我崩溃的“翻车”时刻虽然这招用起来很爽，但第一次上手的兄弟大概率会像我当年一样，在几个莫名的坑里反复横跳。这里分享几个我亲身经历的“翻车”现场： 0x00 翻车现场：Symbol not found这是最搞心态的报错。通常是因为我傻乎乎地写了个绝对路径，或者路径算错了。 血泪教训： EMBED_TXTFILES 里的路径必须是相对于当前 CMakeLists.txt 的。如果你在 main 目录下嵌入文件，却想在其他自定义组件里调用，链接器分分钟教你做人。我当时的解决办法是：哪个组件要用，就把资源老老实实塞到哪个组件的文件夹里。 0x01 修改只读内存，直接炸了由于 EMBED_TXTFILES 贴心地帮我们加了 \\0，我第一次用的时候，居然想用 strtok 去切割这段文本。结果呢？ESP32 直接炸了（LoadProhibited），不停地循环重启。 填坑总结： 别忘了这东西是存在 Flash 里的，它是只读的！你要是想修改，得先用 malloc 开辟一块战场，再用 memcpy 把数据导过去。 0x02 变量命名的“玄学”文件名里的减号、点号全变下划线，有时候规则复杂到我怀疑人生。比如我的文件名叫 my-config.v1.json，生成的符号名会变成 _binary_my_config_v1_json_start。 验证大法： 别在那瞎猜了，这太要命了。直接去 build 目录下，祭出 nm 大法查看生成的符号。 0x04 进阶：我是怎么验证这些“鬼符号”的0x00 别猜，直接看产物作为一个硬核（折腾型）开发者，实在没底的时候，我会直接翻看生成的 .elf 文件。在你的工程目录下运行这行命令，比搜半天文档管用得多：1nm -gC build/*.elf | grep _binary如果列表里能看到预期的 start/end 地址，那心态就稳了。 0x01 实战：证书处理的“极简主义”在折腾 HTTPS 或者 MQTTS 的时候，证书处理简直是灾难。我以前也是老老实实写文件系统驱动，现在直接在代码里这么搞： 12345678// main.c// 这里的 asm 名称就是通过上面 nm 命令确定的extern const uint8_t mqtt_ca_pem_start[] asm(&quot;_binary_mqtt_ca_pem_start&quot;);esp_mqtt_client_config_t mqtt_cfg = { .broker.address.uri = &quot;mqtts://your-iot-server.com&quot;, .broker.verification.certificate = (const char *)mqtt_ca_pem_start,}; 直接把起始指针丢进去，连长度都不用写（因为 TXTFILES 自带终止符），这种感觉只能用“丝滑”来形容。 0x02 EMBED_FILES vs EMBED_TXTFILES：我当年就栽在这儿这是很多新手最容易“踩坑”的地方，我当年就栽在这儿。ESP-IDF 提供了两个类似的参数，区别很关键： EMBED_FILES: 纯二进制嵌入。它原封不动地把文件塞进固件。适用于图片、字体、压缩包等非文本资源。 EMBED_TXTFILES: 专门针对文本。它会在嵌入资源的末尾自动追加一个空终止符 \\0。 如果你错用了 EMBED_FILES 来嵌入证书，你会发现代码运行到最后会莫名其妙地读取到内存后面的垃圾数据，导致 TLS 校验失败。实战建议：HTTPS 证书 (PEM 格式) 或 HTML 请务必使用 EMBED_TXTFILES。 0x03 命名规则的“魔法”名字是怎么生成的？规则很简单：文件名中的所有非字母数字字符（如 .、-）都会被替换成下划线 _。 例如： 文件路径：certs/ca.pem -&gt; 变量名：_binary_ca_pem_start C 语言声明时：asm(&quot;_binary_ca_pem_start&quot;) 提示：建议始终使用相对于 CMakeLists.txt 的相对路径，否则变量名可能会变得非常长且难以预料。 为什么不直接用文件系统？虽然 SPIFFS 或 LittleFS 也很方便，但在以下场景 embed_txtfiles 是最优解： 安全性：证书放在固件里不易因文件系统损坏而丢失，OTA 更新固件也就是更新了证书。 极简方案：避免专门为了几百字节去折腾分区表镜像。 读取速度：数据通过 MMU 直接映射到指令总线，读取速度和读代码一样快，没有文件系统的寻址开销。 0x05 最后从笨重的 C 数组转换到优雅的 embed_txtfiles，本质上是让资源回归其原本的格式，把生成的苦活交给构建系统。正如我之前在Claude Code初体验中感受到的，现代开发的魅力就在于不断利用工具去解开那些重复而低效的死结。 这次填坑心得就分享到这，希望能帮到在被资源路径折磨的你。下个坑见，收工！ 环境1234Framework: ESP-IDF v5.xTarget: ESP32 / S2 / S3 / C3 (RISC-V)Language: C / C++Build System: CMake 参考 ESP-IDF 编程指南 - 指南文档：嵌入二进制数据","link":"/ESP-IDF-embed-txtfiles-tricks/"},{"title":"ESP32-C3 PlatformIO &#39;embed_txtfiles&#39; 修复","text":"前言9.9元入手了一块ESP32-C3板子, 用来取代手上引脚不足的ESP8266.但是编译时候总是失败,从Log上看是这一步出了错误.12345prepare_file([&quot;.pio\\build\\esp32c3\\lite.ttf.txt.o&quot;], [&quot;src\\lite.ttf&quot;])Converting .pio\\build\\esp32c3\\lite.ttf.txt.o'xtensa-esp32-elf-objcopy' \\xb2\\xbb\\xca\\xc7\\xc4ڲ\\xbf\\xbb\\xf2\\xcdⲿ\\xc3\\xfc\\xc1Ҳ\\xb2\\xbb\\xcaǿ\\xc9\\xd4\\xcb\\xd0еĳ\\xcc\\xd0\\xf2\\xbb\\xf2\\xc5\\xfa\\xb4\\xa6\\xc0\\xed\\xceļ\\xfe\\xa1\\xa3*** [.pio\\build\\esp32c3\\lite.ttf.txt.o] Error 1此外并没有任何提示了. 错误分析lite.ttf是我的一个放在src目录下的文件, 为其在platformio.ini配置”board_build.embed_txtfiles = src/lite.ttf”,就可以让这个文件嵌入固件中.从日志里看到是转化的时候出了问题, xtensa-esp32-elf-objcopy xtensa是ESP32,ESP32-S2,ESP32-S3的处理器结构,而ESP32-C3是RISC-V的,所以这里出错应该是结构不匹配.去ESP-IDF的文件夹搜索”elf-objcopy”后发现的确有不同很多类似关键字.12345678910111213141516171819for dir in esp32 esp32s2 esp32c3 esp32s3; do if [ $dir = esp32 ]; then TOOLCHAIN=&quot;xtensa-esp32-elf&quot; elif [ $dir = esp32s2 ]; then TOOLCHAIN=&quot;xtensa-esp32s2-elf&quot; elif [ $dir = esp32c3 ]; then TOOLCHAIN=&quot;riscv32-esp-elf&quot; elif [ $dir = esp32s3 ]; then TOOLCHAIN=&quot;xtensa-esp32s3-elf&quot; else echo &quot;$dir does not exist&quot; fi if [ -d &quot;$dir&quot; ]; then cd $dir git status libphy.a | grep &quot;modified&quot; &gt;/dev/null 2&gt;&amp;1 if [ $? -eq 0 ]; then echo $dir/libphy.a fixed $TOOLCHAIN-objcopy --redefine-sym ets_printf=phy_printf libphy.a fi所以应该是PlatformIO在转化的时候调用了错误的程序导致的. 解决问题去PlatformIO的工作目录(.platformio)下搜索xtensa-esp32-elf-objcopy12345678910111213[ &quot;xtensa-esp32-elf-objcopy&quot;, &quot;--input-target&quot;, &quot;binary&quot;, &quot;--output-target&quot;, &quot;elf32-xtensa-le&quot;, &quot;--binary-architecture&quot;, &quot;xtensa&quot;, &quot;--rename-section&quot;, &quot;.data=.rodata.embedded&quot;, &quot;$SOURCE&quot;, &quot;$TARGET&quot;,]确实搜索到了多个包含这个关键字的文件_embed_files.py(platforms\\espressif32\\builder\\frameworks_embed_files.py)其中platforms下有好几个文件夹 1234567├── .platformio│ └── platforms│ └── espressif32│ └── espressif32@src-ba2d3999402da5eaf2c9d5863ef113c7│ └── espressif32@src-ebefb4289db63a9f0ca5ee29fa328eef│ └── espressif8266│ └── raspberrypi 这应该是不同项目所需的platform,凑巧这次C3项目的platform是专门下载的,所以从文件夹修改日期上来看,我这次C3使用的应该是espressif32@src-ebefb4289db63a9f0ca5ee29fa328eef打开espressif32@src-ebefb4289db63a9f0ca5ee29fa328eef下的_embed_files.py里面果然还在使用xtensa-esp32-elf-objcopy按照ESP-IDF里面的描述,应该使用riscv32-esp-elf-objcopy,并且要把xtensa相关的都修改为riscv. 所以最后修改成了 12345678910111213[ &quot;riscv32-esp-elf-objcopy&quot;, &quot;--input-target&quot;, &quot;binary&quot;, &quot;--output-target&quot;, &quot;elf32-littleriscv&quot;, &quot;--binary-architecture&quot;, &quot;riscv&quot;, &quot;--rename-section&quot;, &quot;.data=.rodata.embedded&quot;, &quot;$SOURCE&quot;, &quot;$TARGET&quot;,] 重新执行编译,这一次终于通过了.12345678910111213Building in release modeprepare_file([&quot;.pio\\build\\esp32c3\\lite.ttf.txt.o&quot;], [&quot;src\\lite.ttf&quot;])Converting .pio\\build\\esp32c3\\lite.ttf.txt.orevert_original_file([&quot;.pio\\build\\esp32c3\\lite.ttf.txt.o&quot;], [&quot;src\\lite.ttf&quot;])Linking .pio\\build\\esp32c3\\firmware.elfRetrieving maximum program size .pio\\build\\esp32c3\\firmware.elfChecking size .pio\\build\\esp32c3\\firmware.elfAdvanced Memory Usage is available via &quot;PlatformIO Home &gt; Project Inspect&quot;RAM: [ ] 4.7% (used 15480 bytes from 327680 bytes)Flash: [= ] 14.1% (used 443870 bytes from 3145728 bytes)Building .pio\\build\\esp32c3\\firmware.binesptool.py v3.1Merged 2 ELF sections 附_embed_files.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177## Copyright 2014-present PlatformIO &lt;contact@platformio.org&gt;#### Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);## you may not use this file except in compliance with the License.## You may obtain a copy of the License at#### http://www.apache.org/licenses/LICENSE-2.0#### Unless required by applicable law or agreed to in writing, software## distributed under the License is distributed on an &quot;AS IS&quot; BASIS,## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.## See the License for the specific language governing permissions and## limitations under the License.import shutilfrom os import SEEK_CUR, SEEK_ENDfrom os.path import basename, isfile, joinfrom SCons.Script import BuilderImport(&quot;env&quot;)board = env.BoardConfig()#### Embedded files helpers##def extract_files(cppdefines, files_type): files = [] if &quot;build.&quot; + files_type in board: files.extend( [ join(&quot;$PROJECT_DIR&quot;, f) for f in board.get(&quot;build.&quot; + files_type, &quot;&quot;).split() if f ] ) else: files_define = &quot;COMPONENT_&quot; + files_type.upper() for define in cppdefines: if files_define not in define: continue value = define[1] if not isinstance(define, tuple): print(&quot;Warning! %s macro cannot be empty!&quot; % files_define) return [] if not isinstance(value, str): print( &quot;Warning! %s macro must contain &quot; &quot;a list of files separated by ':'&quot; % files_define ) return [] for f in value.split(&quot;:&quot;): if not f: continue files.append(join(&quot;$PROJECT_DIR&quot;, f)) for f in files: if not isfile(env.subst(f)): print('Warning! Could not find file &quot;%s&quot;' % basename(f)) return filesdef remove_config_define(cppdefines, files_type): for define in cppdefines: if files_type in define: env.ProcessUnFlags(&quot;-D%s&quot; % &quot;=&quot;.join(str(d) for d in define)) returndef prepare_file(source, target, env): filepath = source[0].get_abspath() shutil.copy(filepath, filepath + &quot;.piobkp&quot;) with open(filepath, &quot;rb+&quot;) as fp: fp.seek(-1, SEEK_END) if fp.read(1) != &quot;\\0&quot;: fp.seek(0, SEEK_CUR) fp.write(b&quot;\\0&quot;)def revert_original_file(source, target, env): filepath = source[0].get_abspath() if isfile(filepath + &quot;.piobkp&quot;): shutil.move(filepath + &quot;.piobkp&quot;, filepath)def embed_files(files, files_type): for f in files: filename = basename(f) + &quot;.txt.o&quot; file_target = env.TxtToBin(join(&quot;$BUILD_DIR&quot;, filename), f) env.Depends(&quot;$PIOMAINPROG&quot;, file_target) if files_type == &quot;embed_txtfiles&quot;: env.AddPreAction(file_target, prepare_file) env.AddPostAction(file_target, revert_original_file) env.AppendUnique(PIOBUILDFILES=[env.File(join(&quot;$BUILD_DIR&quot;, filename))])def transform_to_asm(target, source, env): files = [join(&quot;$BUILD_DIR&quot;, s.name + &quot;.S&quot;) for s in source] return files, sourceenv.Append( BUILDERS=dict( TxtToBin=Builder( action=env.VerboseAction( &quot; &quot;.join( [ &quot;riscv32-esp-elf-objcopy&quot;, &quot;--input-target&quot;, &quot;binary&quot;, &quot;--output-target&quot;, &quot;elf32-littleriscv&quot;, &quot;--binary-architecture&quot;, &quot;riscv&quot;, &quot;--rename-section&quot;, &quot;.data=.rodata.embedded&quot;, &quot;$SOURCE&quot;, &quot;$TARGET&quot;, ] ), &quot;Converting $TARGET&quot;, ), suffix=&quot;.txt.o&quot;, ), TxtToAsm=Builder( action=env.VerboseAction( &quot; &quot;.join( [ join( env.PioPlatform().get_package_dir(&quot;tool-cmake&quot;) or &quot;&quot;, &quot;bin&quot;, &quot;cmake&quot;, ), &quot;-DDATA_FILE=$SOURCE&quot;, &quot;-DSOURCE_FILE=$TARGET&quot;, &quot;-DFILE_TYPE=TEXT&quot;, &quot;-P&quot;, join( env.PioPlatform().get_package_dir(&quot;framework-espidf&quot;) or &quot;&quot;, &quot;tools&quot;, &quot;cmake&quot;, &quot;scripts&quot;, &quot;data_file_embed_asm.cmake&quot;, ), ] ), &quot;Generating assembly for $TARGET&quot;, ), emitter=transform_to_asm, single_source=True, ), ))flags = env.get(&quot;CPPDEFINES&quot;)for files_type in (&quot;embed_txtfiles&quot;, &quot;embed_files&quot;): if ( &quot;COMPONENT_&quot; + files_type.upper() not in env.Flatten(flags) and &quot;build.&quot; + files_type not in board ): continue files = extract_files(flags, files_type) if &quot;espidf&quot; in env.subst(&quot;$PIOFRAMEWORK&quot;): env.Requires(join(&quot;$BUILD_DIR&quot;, &quot;${PROGNAME}.elf&quot;), env.TxtToAsm(files)) else: embed_files(files, files_type) remove_config_define(flags, files_type) 环境:12345PLATFORM: Espressif 32 (3.3.0+sha.3b5de56) &gt; Espressif ESP32 Dev Module - framework-arduinoespressif32 0.0.0+sha.68daea4 - tool-esptoolpy 1.30100.210531 (3.1.0) - toolchain-riscv-esp 1.80400.0 (8.4.0) - toolchain-riscv32-esp 8.4.0+2021r1","link":"/ESP32-C3-PlatformIO-embed-txtfiles-fix/"},{"title":"ESP32-串流显示","text":"让你的ESP32试试串流吧 （2025 年 11 月更新）这篇文章写于 5 年前，但它至今仍是我流量最高的文章之一。它所展示的‘PC 到 ESP32 实时串流’的核心原理——即‘Python 抓帧/编码’ + ‘自定义 TCP 协议’ + ‘ESP32 解码/DMA 渲染’——这个架构在今天依然极具参考价值。 既然有了屏幕，又有了网络，那岂不是可以串流了！ 序这次我们来整个活。利用ESP32来显示电脑的画面！如果你用的是其他屏幕也没关系，只要是ESP32配合TFT_eSPI就可以实现，只是在帧率上会有所区别。这个视频为你展示了在M5StickC上的运行效果现在是除了游戏性以外，一无所有的原神@bilibili 实现方式电脑作为发送端，负责发送图像数据-&gt;EPS32作为接收端，负责接收并绘制图像数据发送端使用python编写，使用mss模块捕获屏幕画面，再使用python opencv 编码为JPG 接收端使用C++编写，TJpg_Decoder解码，TFT_eSPI绘制 发送的数据以帧为单位，为了减小帧的体积，将会对每一帧原始位图数据使用JPG编码，ESP32接收到数据以后，先对JPG进行解码，再进行绘制。 一次完整通信流程为: 精简的代码要让 Python上位机 和 下位机C++ 沟通，第一步是定义一个‘协议’。我没有用复杂的 HTTP，而是设计了一个极简的 3 步握手协议（PREPAREOK, HEADEROK, FRAMEOK），用它来确保帧数据不会丢失或错位 common_macro.h12345678910111213141516171819202122232425262728293031323334##ifndef COMMON_MACRO_H_##define COMMON_MACRO_H_// Debug情况下，暂时不去测试串流，也无需连接wifi##define DEBUG/*======================串流相关======================*/// 帧数据接收完毕##define FRAMEOK 0x01// 头部接收完毕，接收帧##define HEADEROK 0x02// 准备完毕，接收头部 注:0x03无法正常发送// https://www.cnblogs.com/young525/p/5873795.html##define PREPAREOK 0x41/*======================屏幕相关======================*/##define SCREEN_WIDTH 240##define SCREEN_HEIGHT 135/*======================WiFi相关======================*/##define ssid &quot;CloseWrt_2.5G&quot;// WiFi 密码##define password &quot;have5seeds&quot;##endif 在 ESP32（接收端），我把所有逻辑封装成一个 StreamingComponent 类。它的核心是状态机（IDLES, RUNNING）和两个关键的缓冲区：一个 headerBuffer（用来接收帧大小）和一个 wifiBuffer（用来接收 JPG 数据） StreamingComponent.h123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899##ifndef STREAMINGCOMPONENT_H_##define STREAMINGCOMPONENT_H_##define IDLES 0##define RUNNING 1##define EXITING 2##include &lt;TFT_eSPI.h&gt;##include &lt;TJpg_Decoder.h&gt;##include &lt;WiFi.h&gt;##include &quot;utils.h&quot;##include &quot;common_macro.h&quot;class StreamingComponent {public: StreamingComponent(WiFiClient &amp;clt, TFT_eSPI &amp;tft); uint8_t status = IDLES; void enter(); void exit(); void loop(); bool drawCallBack(int16_t x, int16_t y, uint16_t w, uint16_t h, uint16_t *bitmap);// ~StreamingComponent() {// Serial.printf(&quot;~StreamingComponent\\n&quot;);// free(wifiBuffer);// free(headerBuffer);// free(frameSizeBuffer);// };private: // WiFiClient指针 WiFiClient *client; // TFT_eSPI指针 TFT_eSPI *Tft; // 帧率相关 double fps_avg = 0.0; uint32_t sec{}, psec{}; uint16_t fps = 0, frame_count = 0; // 帧率相关 // 执行时间相关 // 函数执行时间 uint32_t cost{}; // 一次loop执行时间 uint32_t loopCost{}; // 缓冲部分 // 帧数据大小 uint16_t size{}; // 已经下载帧数据大小 uint16_t bSize{}; // DMA缓冲相关 // 2020.12.04若出现发送端发送超过wifiFrameSize大小(32kb)， // 则会导致出错，而此处无法分配更大内存。 // 暂时未找到正确开启SPIRAM方法 // 2020.12.04将图片压缩方式从LZO改为jpg const int wifiFrameSize = 1024 * 32; // 头数据大小 const int headerFrameSize = 10; // 待下载的jpg图片缓冲 uint8_t *wifiBuffer = (uint8_t *) heap_caps_malloc(wifiFrameSize, MALLOC_CAP_8BIT); // 头数据缓冲 uint8_t *headerBuffer = (uint8_t *) heap_caps_malloc(headerFrameSize, MALLOC_CAP_8BIT); // 帧数据大小缓冲，用于解析字符串为int uint8_t *frameSizeBuffer = (uint8_t *) heap_caps_malloc(headerFrameSize - 1, MALLOC_CAP_8BIT); // DMA 双缓冲模式 uint16_t dmaBuffer1[16 * 16]{}; // Toggle buffer for 16*16 MCU block, 512bytes uint16_t dmaBuffer2[16 * 16]{}; // Toggle buffer for 16*16 MCU block, 512bytes uint16_t *dmaBufferPtr = dmaBuffer1; // 当前使用的DMA缓冲 bool dmaBufferSel = 0; /** * 显示回调，用于Tjpeg * 2020-12-06 */ /** * 接收数据 * 2020-12-01 * size: 5222 bytes * cost: 16 ms */ void onReceiveData();};##endif 实现的核心在 onReceiveData()。在这个函数中,它首先等待 PREPAREOK，然后读取 10 字节的‘头部’，解析出帧大小（size），再发送 HEADEROK；然后它才开始接收那 size 字节的 JPG 图像，存入 wifiBuffer. StreamingComponent.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123##include &quot;StreamingComponent.h&quot;StreamingComponent::StreamingComponent(WiFiClient &amp;clt, TFT_eSPI &amp;tft) { this-&gt;client = &amp;clt; this-&gt;Tft = &amp;tft; Serial.println(&quot;StreamingComponent Constuctor&quot;);};void StreamingComponent::enter() { status = RUNNING; };void StreamingComponent::exit() { status = EXITING; };void StreamingComponent::loop() { if (status == RUNNING) { Serial.println(&quot;StreamingComponent loop&quot;); loopCost = millis(); onReceiveData(); Serial.printf(&quot;fps_avg:%f,loop cost:%d ms\\n&quot;, fps_avg, millis() - loopCost); Tft-&gt;drawString(String(fps_avg), 0, 0, 2); } else if (status == EXITING) { // 啥也不做 }};bool StreamingComponent::drawCallBack(int16_t x, int16_t y, uint16_t w, uint16_t h, uint16_t *bitmap) { if (status == RUNNING) { if (y &gt;= SCREEN_HEIGHT) return 0; if (dmaBufferSel) { dmaBufferPtr = dmaBuffer2; } else { dmaBufferPtr = dmaBuffer1; } dmaBufferSel = !dmaBufferSel; Tft-&gt;pushImageDMA(x, y, w, h, bitmap, dmaBufferPtr); } return true;}// ~StreamingComponent() {// Serial.printf(&quot;~StreamingComponent\\n&quot;);// free(wifiBuffer);// free(headerBuffer);// free(frameSizeBuffer);// };void StreamingComponent::onReceiveData() { Serial.println(&quot;StreamingComponent onReceiveData&quot;); StreamingComponent::client-&gt;write(PREPAREOK); Serial.println(&quot;StreamingComponent client.write(PREPAREOK);&quot;); cost = millis(); if (headerBuffer == nullptr) { Serial.printf(&quot;headerBuffer is null.\\n&quot;); } else { client-&gt;readBytes(headerBuffer, headerFrameSize); Serial.printf(&quot;receive header cost:%d ms\\n&quot;, millis() - cost); } int sum = checkSum((const char *)headerBuffer, 8); // Serial.printf(&quot;headerBuffer checkSum: %d\\n&quot;, sum); if ((sum &amp; 0xf) == c2i(headerBuffer[9]) &amp;&amp; (sum &gt;&gt; 4) == c2i(headerBuffer[8])) { // 有效头数据，准备接收帧数据 strncpy((char *)frameSizeBuffer, (char *)headerBuffer, 8); frameSizeBuffer[9] = '\\0'; size = atoi((char *)frameSizeBuffer); // Serial.printf(&quot;valid header frame size: %d bytes\\n&quot;, size); } else { // 无效头数据，丢弃 // Serial.printf(&quot;invalid header\\n&quot;); return; } client-&gt;write(HEADEROK); // // Serial.printf(&quot;send HEADEROK\\n&quot;); cost = millis(); bSize = 0; if (wifiBuffer == NULL) { Serial.printf(&quot;wifiBuffer is null.\\n&quot;); Serial.printf(&quot;MALLOC_CAP_8BIT heap_caps_get_largest_free_block: %d.\\n&quot;, heap_caps_get_largest_free_block(MALLOC_CAP_8BIT)); Serial.printf(&quot;MALLOC_CAP_32BIT heap_caps_get_largest_free_block: %d.\\n&quot;, heap_caps_get_largest_free_block(MALLOC_CAP_32BIT)); Serial.printf(&quot;MALLOC_CAP_SPIRAM heap_caps_get_largest_free_block: %d.\\n&quot;, heap_caps_get_largest_free_block(MALLOC_CAP_SPIRAM)); Serial.printf(&quot;MALLOC_CAP_8BIT: %d.\\n&quot;, heap_caps_get_free_size(MALLOC_CAP_8BIT)); Serial.printf(&quot;MALLOC_CAP_32BIT: %d.\\n&quot;, heap_caps_get_free_size(MALLOC_CAP_32BIT)); Serial.printf(&quot;MALLOC_CAP_SPIRAM: %d.\\n&quot;, heap_caps_get_free_size(MALLOC_CAP_SPIRAM)); } else { bSize = client-&gt;readBytes(wifiBuffer, size); Serial.printf(&quot;frame size: %d bytes, receive frame cost:%d ms\\n&quot;, bSize, millis() - cost); } if (bSize &gt; 64 &amp;&amp; bSize == size) { cost = millis(); Tft-&gt;startWrite(); TJpgDec.drawJpg(0, 0, wifiBuffer, bSize); Tft-&gt;endWrite(); frame_count++; sec = millis() / 1000; if (psec != sec) { psec = sec; fps = frame_count; fps_avg = (fps_avg + fps) / 2.0; frame_count = 0; } // 31ms Serial.printf(&quot;draw cost:%d ms\\n&quot;, millis() - cost); } else { // 无效帧，丢弃 // return; } client-&gt;write(FRAMEOK); // // Serial.printf(&quot;send FRAMEOK\\n&quot;);} utils.h1234567891011121314##ifndef LIB_UTILS_H_##define LIB_UTILS_H_##include &lt;stdint.h&gt;##include &quot;TFT_eSPI.h&quot;int checkSum(const char* src, int length);int c2i(char ch);int getTextWidth(const char* text, TFT_eSprite &amp;sprite);int getTextWidth(const char* text, TFT_eSprite *sprite);##endif utils.cpp1234567891011121314151617181920212223242526272829303132333435363738394041424344454647##include &quot;utils.h&quot;/** * @brief 计算16校验和计算 * @param src 待校验内容 * @param length 待校验内容长度 * @retval 校验和 * */int checkSum(const char *src, int length) { int16_t sum = 0; for (int i = 0; i &lt; length; i++) { sum += src[i]; } sum = (sum &amp; 0xff) + (sum &gt;&gt; 16); return ~sum &amp; 0xff;}/** * @brief 16进制字符转int * @param ch 待转换内容 * @retval 校验和 * */// https://www.cnblogs.com/lidabo/p/3995055.htmlint c2i(char ch) { // 如果是数字，则用数字的ASCII码减去48, 如果ch = '2' ,则 '2' - 48 = 2 if (isdigit(ch)) return ch - 48; // 如果是字母，但不是A~F,a~f则返回 if (ch &lt; 'A' || (ch &gt; 'F' &amp;&amp; ch &lt; 'a') || ch &gt; 'z') return -1; // 如果是大写字母，则用数字的ASCII码减去55, 如果ch = 'A' ,则 'A' - 55 = 10 // 如果是小写字母，则用数字的ASCII码减去87, 如果ch = 'a' ,则 'a' - 87 = 10 if (isalpha(ch)) return isupper(ch) ? ch - 55 : ch - 87; return -1;}int getTextWidth(const char* text, TFT_eSprite &amp;sprite){ return sprite.textWidth(text);}int getTextWidth(const char* text, TFT_eSprite *sprite){ return sprite-&gt;textWidth(text);} 在 PC（发送端），Python 脚本正好是 C++ 逻辑的‘反面’。它使用 mss 抓屏，用 cv2.imencode 将其压缩成 JPG（这是降低带宽的关键），然后等待 ESP32 的‘握手信号’，并相应地发送‘头部’和‘帧数据’. tiny_monitor.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960##pragma GCC optimize(&quot;O3&quot;)##include &lt;stdint.h&gt;##include &lt;TFT_eSPI.h&gt;##include &lt;TJpg_Decoder.h&gt;##include &lt;WiFi.h&gt;##include &lt;Wire.h&gt;##include &quot;StreamingComponent.h&quot;// 第三方基础组件// WiFi客户端实例WiFiClient client;// 显示屏驱动实例TFT_eSPI Tft = TFT_eSPI();// 自定义对象StreamingComponent *streaming;bool drawCallback(int16_t x, int16_t y, uint16_t w, uint16_t h, uint16_t *bitmap) { streaming-&gt;drawCallBack(x, y, w, h, bitmap); return true;}void main_setup() { // 配置串口 Serial.begin(115200); // 配置显示 Tft.init(); Tft.setRotation(1); Tft.fillScreen(TFT_BLACK); Tft.initDMA(); // 配置TJpeg TJpgDec.setJpgScale(1); TJpgDec.setSwapBytes(true); // 设置TJpg解码器回调函数 TJpgDec.setCallback(drawCallback); // 配置WiFi client.setTimeout(1); WiFi.begin(ssid, password); delay(1000); if (WiFi.status() == WL_CONNECTED) { const int httpPort = 715; client.connect(&quot;192.168.10.207&quot;, httpPort); Serial.println(&quot;Socket Connected&quot;); } // 用户自定义对象初始化区 streaming = new StreamingComponent(client, Tft); streaming-&gt;status = RUNNING;}void setup() { main_setup();}void loop() { streaming-&gt;loop();} tiny_monitor.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110import socketimport timefrom multiprocessing import Process, Queue,Value,Managerfrom multiprocessing.sharedctypes import Arrayimport ctypesfrom mss.tools import to_pngimport cv2import lzoimport mssimport numpy as npip = &quot;0.0.0.0&quot;port = 715fps = 0def main(): global fps # 1. 创建套接字 socket if True: tcp_server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM) # 2. 绑定本地信息 bind tcp_server_socket.bind((ip, port)) # 3. 让默认的套接字由主动变为被动 listen tcp_server_socket.listen(128) print(&quot;启动TCP服务器\\r\\n&quot; + f'启动在{ip}:{port}上') # 4. 等待客户端的链接 accept print(&quot;等待客户端的链接\\r\\n&quot;) new_client_socket, client_addr = tcp_server_socket.accept() print(f'当前链接：{client_addr}') frame_buffer = grab_screen_to_buffer(0, 0, 1920, 1080) start_time = time.time() while True: s = time.time() recv = new_client_socket.recv(1) if recv == b'\\x41': # 客户端就绪，发送头数据 start_time = time.time() header = len(frame_buffer.tobytes()) header = package_header(header) new_client_socket.sendall(header) end_time = time.time() cost = end_time - start_time # print(&quot;客户端就绪，发送头数据&quot;) elif recv == b'\\x02': # 客户端准备头部接收完成，发送帧数据 new_client_socket.sendall(frame_buffer.tobytes()) frame_buffer = grab_screen_to_buffer(0, 0, 1920, 1080) # print(&quot;客户端准备头部接收完成，发送帧数据&quot;) elif recv == b'\\x01': # pass # 客户端准备帧数据接收完成，等待客户端就绪 # print(&quot;客户端准备帧数据接收完成，等待客户端就绪&quot;) end_time = time.time() cost = end_time - start_time print(&quot;Backend FPS:{:.2f}&quot;.format(1.0 / cost))### grab screen by left top width heightdef grab_screen_to_buffer(l, t, w, h): monitor = {&quot;top&quot;: t, &quot;left&quot;: l, &quot;width&quot;: w, &quot;height&quot;: h} with mss.mss() as sct: sct_frame = sct.grab(monitor) img = np.array(sct_frame) img = cv2.resize(img, dsize=(240, 135)) # img = cv2.cvtColor(img, cv2.COLOR_BGR2BGR565) # print(&quot;bmp no comporess size:{}&quot;,len(img.tobytes())) # print(&quot;bmp lzo comporess size:{}&quot;,len(lzo.compress(img.tobytes(), 9, False))) quality = 60 encode_params = [cv2.IMWRITE_JPEG_QUALITY,quality,cv2.IMWRITE_JPEG_PROGRESSIVE,0] retval, img = cv2.imencode(&quot;.jpg&quot;, img, encode_params) # with open(&quot;write.jpg&quot;, &quot;wb&quot;) as f: # f.write(img.tobytes()) # img = img[..., ::-1] # print(&quot;jpg no comporess size:{}&quot;,len(img.tobytes())) # print(&quot;jpg lzo comporess size:{}&quot;,len(lzo.compress(img.tobytes(), 9, False))) return imgdef package_header(size): data = num_package(size) header = ''.join(data).encode() + hex(check_sum(data)).encode()[2:] return header## 校验和def check_sum(value): s = 0 for d in value: s += ord(d) s = (s &amp; 0xff) + (s &gt;&gt; 16) return ~s &amp; 0xff## 打包数字def num_package(num): if num &lt; 100000000: li_str = list(str(num)) result = ['0' for _ in range(8)] for index, item in zip(range(len(li_str)), li_str): result[-index + len(li_str) - 1] = item return result[::-1] else: return ['9' for _ in range(6)]if __name__ == '__main__': time.sleep(1) main() 预览 参考资料以下内容为实际开发中参考过的资料，有些资料中的方案已经舍弃，并未体现在上述代码中，特此列出，但俺仍要向他们表示由衷的感谢。 windows环境安装lzo和python-lzo https://github.com/lzfcc/LearnArduino ESP32 官方文档（五）严重错误 ESP32-CAM: 連接ILI9341液晶螢幕","link":"/ESP32-Streaming/"},{"title":"屏幕不够，算法来凑(一)：Ditherpunk 抖动算法原理与 JS 实时演示","text":"背景在嵌入式开发领域，我们经常会遇到色彩位数极低的显示设备： 经典的 SSD1306 (0.96寸 OLED)，仅支持黑白两色。 电子墨水屏 (E-Ink)，通常只有黑白，且刷新率极低。 如果直接将 24 位真彩图片进行量化处理，其结果往往如同烧焦的木炭，细节丢失殆尽。但若引入 抖动算法(Dithering)，这些 1-Bit 屏幕便能模拟出细腻的灰度感。 此前我曾尝试用 Rust 实现过一个版本，但作为博客演示，使用 JavaScript 与 Canvas 在浏览器中直接进行仿真最为直观。本文将介绍几种主流抖动算法的原理及其 JS 实现。 实验室控制台在此上传图片，下文的所有算法演示将同步生效。建议开启 Gamma 校正观摩图像暗部细节的差异。 📂 上传图片 / Upload Image * 图片将仅在本地处理，不会上传服务器 (function() { const Algos = { threshold: (val) => val > 0.5 ? 1 : 0, random: (val) => (val + Math.random() - 0.5) > 0.5 ? 1 : 0, bayer: (val, x, y) => { const m = [[0,8,2,10],[12,4,14,6],[3,11,1,9],[15,7,13,5]]; return val > (m[y%4][x%4] + 0.5) / 16 ? 1 : 0; }, blue: (val, x, y) => { const g = 1.32471795724474602596; const a1 = 1.0 / g; const a2 = 1.0 / (g * g); const threshold = (0.5 + a1 * x + a2 * y) % 1.0; return val > threshold ? 1 : 0; }, floyd: (pixels, w, h) => { const d = new Float32Array(pixels); for (let y = 0; y < h; y++) { for (let x = 0; x < w; x++) { let i = y * w + x; let oldV = d[i]; let newVal = oldV > 0.5 ? 1 : 0; d[i] = newVal; let err = oldV - newVal; if (x+1 < w) d[i+1] += err * 7/16; if (y+1 < h) { if (x > 0) d[i+w-1] += err * 3/16; d[i+w] += err * 5/16; if (x+1 < w) d[i+w+1] += err * 1/16; } } } return d; }, atkinson: (pixels, w, h) => { const d = new Float32Array(pixels); for (let y = 0; y < h; y++) { for (let x = 0; x < w; x++) { let i = y * w + x; let oldV = d[i]; let newVal = oldV > 0.5 ? 1 : 0; d[i] = newVal; let err = (oldV - newVal) / 8; if (x+1 < w) d[i+1] += err; if (x+2 < w) d[i+2] += err; if (y+1 < h) { if (x > 0) d[i+w-1] += err; d[i+w] += err; if (x+1 < w) d[i+w+1] += err; if (y+2 < h) d[i+w*2] += err; } } } return d; } }; const srgbToLinear = v => v { const algo = container.dataset.algo; const checkbox = container.querySelector('.local-gamma'); const canvas = container.querySelector('canvas'); // Generate unique ID if missing if (!canvas.id) canvas.id = 'canvas-' + algo + '-' + Math.random().toString(36).substr(2, 9); // Interaction: Lens Effect let isHovering = false; let mouseX = 0, mouseY = 0; const draw = () => { if (!canvasStates.has(canvas.id)) return; const ditheredData = canvasStates.get(canvas.id); const ctx = canvas.getContext('2d'); // Draw base dithered image ctx.putImageData(ditheredData, 0, 0); // Draw Lens if hovering if (isHovering && originalImageData) { const radius = 50; const diameter = radius * 2; ctx.save(); ctx.beginPath(); ctx.arc(mouseX, mouseY, radius, 0, Math.PI * 2); ctx.clip(); // Draw original grayscale image inside the circle // We need to draw the originalImageData at the correct position // create temp canvas/imagedata is slow, drawImage is better if we had an ImageBitmap/Canvas // Optimization: We can keep a global offscreen canvas for original image if (offscreenOriginalCanvas) { ctx.drawImage(offscreenOriginalCanvas, 0, 0); } // Draw border ring ctx.strokeStyle = 'rgba(255, 100, 100, 0.8)'; ctx.lineWidth = 2; ctx.stroke(); ctx.restore(); } }; canvas.addEventListener('mousemove', e => { const rect = canvas.getBoundingClientRect(); mouseX = e.clientX - rect.left; mouseY = e.clientY - rect.top; // Scale mouse coords if canvas display size differs from internal size const scaleX = canvas.width / rect.width; const scaleY = canvas.height / rect.height; mouseX *= scaleX; mouseY *= scaleY; if (!isHovering) { isHovering = true; } requestAnimationFrame(draw); }); canvas.addEventListener('mouseleave', () => { isHovering = false; requestAnimationFrame(draw); }); // Interaction: Gamma Toggle if (checkbox) { checkbox.addEventListener('change', () => { processCanvas(container); }); } // Attach draw function to container for external calls container._redraw = draw; }); // Load default image const defaultSample = '/images/archives/ditherpunk/sample.jpg'; const initialImg = new Image(); initialImg.onload = () => { processImage(initialImg); }; initialImg.src = defaultSample; upload.addEventListener('change', e => { const file = e.target.files[0]; if (!file) return; const reader = new FileReader(); reader.onload = evt => { const img = new Image(); img.onload = () => { processImage(img); }; img.src = evt.target.result; }; reader.readAsDataURL(file); }); } let offscreenOriginalCanvas = null; function processImage(img) { const displayMaxWidth = 600; let w = img.width, h = img.height; const scale = Math.min(1, displayMaxWidth / w); if (w > displayMaxWidth) { h *= scale; w = displayMaxWidth; } w = Math.floor(w); h = Math.floor(h); imgW = w; imgH = h; // Prepare Offscreen Canvas for Original Image (Lens Source) offscreenOriginalCanvas = document.createElement('canvas'); offscreenOriginalCanvas.width = w; offscreenOriginalCanvas.height = h; const ctx = offscreenOriginalCanvas.getContext('2d'); ctx.drawImage(img, 0, 0, w, h); // Extract Grayscale Data (sRGB 0-255) const rawData = ctx.getImageData(0, 0, w, h); originalImageData = ctx.createImageData(w, h); // Pre-calculate Linear and sRGB Normalized arrays linearPixels = new Float32Array(w * h); srgbPixels = new Float32Array(w * h); for (let i = 0; i < rawData.data.length; i += 4) { let r = rawData.data[i], g = rawData.data[i+1], b = rawData.data[i+2]; // Standard Luminance let grayScale = (0.2126 * r + 0.7152 * g + 0.0722 * b) / 255; srgbPixels[i/4] = grayScale; linearPixels[i/4] = srgbToLinear(grayScale); // For display (Lens), store grayscale sRGB let v = grayScale * 255; originalImageData.data[i] = originalImageData.data[i+1] = originalImageData.data[i+2] = v; originalImageData.data[i+3] = 255; } // Update the offscreen canvas with true grayscale for the lens to use ctx.putImageData(originalImageData, 0, 0); // Update all canvases document.querySelectorAll('.dither-demo-container').forEach(container => { processCanvas(container); }); } function processCanvas(container) { if (!linearPixels) return; const algo = container.dataset.algo; const checkbox = container.querySelector('.local-gamma'); const useGamma = checkbox ? checkbox.checked : true; // Default to true if no checkbox const canvas = container.querySelector('canvas'); canvas.width = imgW; canvas.height = imgH; canvas.style.imageRendering = 'pixelated'; // Select input source // Clone the array because Error Diffusion modifies it in-place const inputSource = useGamma ? linearPixels : srgbPixels; const input = new Float32Array(inputSource); // Clone let result; if (algo === 'floyd' || algo === 'atkinson') { result = Algos[algo](input, imgW, imgH); } else { result = new Float32Array(imgW * imgH); for(let y=0; y","link":"/Ditherpunk-The-Art-of-Dithering/"},{"title":"移植FFMPEG到安卓","text":"移植FFmpeg到Android上 因为Mix Music解码的需求,所以得选择合适的解码工具.尝试了4种解码方式,最后还是FFmpeg的效果最好 MediaCodec配合MediaExtractor进行解码操作 这样的话,默认情况下MediaExtractor每次只传输1KB左右的数据给MediaCodec,速度实在是太慢 MediaCodec不用MediaExtractor进行解码操作 在给Bytebuffer填充数据后,MediaCodec处理数据的时候总出错,大概是因为没有跳过非帧数据的部分 使用LAME进行解码操作 不幸的是LAME中的hip_decode()也是只能处理帧数据,需要手动跳过非帧数据.当手动跳过非帧数据后,最终发现速度并没有提升多少(尽管已经设置了不同大小的buffer) 使用FFmpeg进行解码操作 编译的时候真的是各种错误,头文件明明就在那里呆的好好的,编译器还是报找不到函数的错误.好在最终效果令人非常满意,3秒钟解码一个音频文件. 这是项目的[GitHub](https://github.com/chaosgoo/ffmpegNDK)地址,如果你的ffmpeg实在是编译不过去,可以去这里下载,然后再进行编译. 编译出ffmpeg的so文件要编译FFmpeg,第一步就是先获取源码.直接去官网就可以下载.解压后得到123456789101112131415161718└───ffmpeg ├───compat ├───doc ├───ffbuild ├───ffmpeg ├───fftools ├───libavcodec ├───libavdevice ├───libavfilter ├───libavformat ├───libavresample ├───libavutil ├───libpostproc ├───libswresample ├───libswscale ├───presets ├───tests └───tools 打开configure文件找到1234SLIBNAME_WITH_MAJOR='$(SLIBNAME).$(LIBMAJOR)' LIB_INSTALL_EXTRA_CMD='$$(RANLIB) &quot;$(LIBDIR)/$(LIBNAME)&quot;' SLIB_INSTALL_NAME='$(SLIBNAME_WITH_VERSION)' SLIB_INSTALL_LINKS='$(SLIBNAME_WITH_MAJOR) $(SLIBNAME)' 将内容修改为1234SLIBNAME_WITH_MAJOR='$(SLIBPREF)$(FULLNAME)-$(LIBMAJOR)$(SLIBSUF)' LIB_INSTALL_EXTRA_CMD='$$(RANLIB) &quot;$(LIBDIR)/$(LIBNAME)&quot;' SLIB_INSTALL_NAME='$(SLIBNAME_WITH_MAJOR)' SLIB_INSTALL_LINKS='$(SLIBNAME)' 这是因为默认生成的文件名称中版本号位于最后,不符合Android命名规范. 在ffmpeg目录下创建build.sh文件内容为12345678910111213141516171819202122232425262728293031323334353637383940414243444546NDK=F:/android-ndk-r14b## 指向你NDK的路径SYSROOT=$NDK/platforms/android-21/arch-arm/## 指定逻辑目录,按照自身需要进行修改TOOLCHAIN=$NDK/toolchains/arm-linux-androideabi-4.9/prebuilt/windows-x86_64## windows平台为windows-x86_64,linux为linux-x86_64CPU=armPREFIX=$(pwd)/android/$CPU ADDI_CFLAGS=&quot;-marm&quot;## build_one中,因为我只需要使用mp3的decode和pcm_s16le的encode,所以关闭了其他的decode和encode来实现压缩体积,集体配置参数可参考## https://www.cnblogs.com/azraelly/archive/2012/12/31/2840541.htmlfunction build_one{./configure \\--prefix=$PREFIX \\--enable-shared \\--disable-static \\--enable-asm \\--disable-doc \\--disable-gpl \\--enable-small \\--disable-encoders \\--disable-decoders \\--disable-ffmpeg \\--enable-encoder=pcm_s16le \\--enable-decoder=mp3 \\--disable-ffplay \\--disable-ffprobe \\--disable-ffserver \\--disable-doc \\--disable-symver \\--enable-jni \\--cross-prefix=$TOOLCHAIN/bin/arm-linux-androideabi- \\--target-os=android \\--arch=arm \\--enable-cross-compile \\--sysroot=$SYSROOT \\--extra-cflags=&quot;-Os -fpic $ADDI_CFLAGS&quot; \\--extra-ldflags=&quot;$ADDI_LDFLAGS&quot; \\$ADDITIONAL_CONFIGURE_FLAGmake cleanmakemake install}build_one更加不幸的是.sh文件现在还不能运行,得先下载MinGW,记得build.sh文件不编辑的时候,不要挂在后台处在打开状态下载好后,直接打开勾选上如图所示的选项 在左上角Installation菜单中点击Apply Changes,然后等待下载并自动安装(可能需要酸酸乳,因为网络质量不是很高) 下载完毕后,直接进度你的MinGW文件夹,找到msys文件夹并进入.双击msys.bat就会启动一个长的很像CMD的程序,至少在打开路径上都是使用cd命令 cd进入到之前build.sh的文件夹,输入./build.sh运行build.sh,它就会自动进行编译操作.如果遇到了各种奇怪问题,不要放弃,因为你的问题前人已经犯过,你只需要善用搜索引擎,踩着他们的脚印即可. 因为我在编译的时候也遇到了各种各样的问题,最后通过更换NDK版本解决了问题.等待一段时间后,在ffmpeg目录下就会多出android文件夹,我们需要用到的so文件就在这个ffmpeg/android/arm/lib文件夹内 编译完成后我们得到了12345678910includelib libavcodec.so libavdevice.so libavfilter.so libavformat.so libavutil.so libpostproc.so libswresample.so libswscale.so 编译安卓可以调用的so文件终于到了要调用FFmpeg的阶段了.和常规NDK编译的需求一样,需要创建一个jni文件夹.把上一步得到的include文件夹和那些so文件复制进来. 还需要把位于ffmpeg根目录中的 cmdutils.c和cmdutils.h ffmpeg.h和ffmpeg.c ffmpeg_opt.c ffmpeg_hw.c ffmpeg_filter.c va_copy.h config.h 这个文件只有你之前手动编译了ffmpeg才会得到也复制到jni文件夹内 创建Application.mk1234APP_ABI := armeabi-v7a armeabiAPP_MODULES := libffmpegjniAPP_CFLAGS += -DSTDC_HEADERS以及Android.mk123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566LOCAL_PATH:= $(call my-dir)include $(CLEAR_VARS)LOCAL_MODULE:= avcodec-prebuilt-armeabiLOCAL_SRC_FILES:= prebuilt/armeabi/libavcodec.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE:= avdevice-prebuilt-armeabiLOCAL_SRC_FILES:= prebuilt/armeabi/libavdevice.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE:= avfilter-prebuilt-armeabiLOCAL_SRC_FILES:= prebuilt/armeabi/libavfilter.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE:= avformat-prebuilt-armeabiLOCAL_SRC_FILES:= prebuilt/armeabi/libavformat.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := avutil-prebuilt-armeabiLOCAL_SRC_FILES := prebuilt/armeabi/libavutil.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := swresample-prebuilt-armeabiLOCAL_SRC_FILES := prebuilt/armeabi/libswresample.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := swscale-prebuilt-armeabiLOCAL_SRC_FILES := prebuilt/armeabi/libswscale.soinclude $(PREBUILT_SHARED_LIBRARY)include $(CLEAR_VARS)LOCAL_MODULE := libffmpegjniLOCAL_ARM_MODE := armLOCAL_SRC_FILES := ffmpegJni.c \\ ffmpeg.c \\ cmdutils.c \\ ffmpeg_opt.c \\ ffmpeg_filter.c \\ ffmpeg_hw.cLOCAL_LDLIBS := -L$(SYSROOT)/usr/lib -llog -lzLOCAL_SHARED_LIBRARIES:= avcodec-prebuilt-armeabi \\ avdevice-prebuilt-armeabi \\ avfilter-prebuilt-armeabi \\ avformat-prebuilt-armeabi \\ avutil-prebuilt-armeabi \\ swresample-prebuilt-armeabi \\ swscale-prebuilt-armeabiLOCAL_C_INCLUDES += -L$(SYSROOT)/usr/includeLOCAL_C_INCLUDES += $(LOCAL_PATH)/includeLOCAL_CFLAGS := -DUSE_ARM_CONFIGinclude $(BUILD_SHARED_LIBRARY)在ffmpeg.c中有些东西需要我们修改下,因为正常情况下ffmpeg执行一条命令,它就会自动退出,我们当然不希望这样.所以需要对他的推出操作进行处理.打开ffmpeg.c,找到如下内容并修改1234567891011121314151617181920212223242526/* parse options and open all input/output files */ ret = ffmpeg_parse_options(argc, argv); if (ret &lt; 0){ // exit_program(1); return 1; } if (nb_output_files &lt;= 0 &amp;&amp; nb_input_files == 0) { show_usage(); av_log(NULL, AV_LOG_WARNING, &quot;Use -h to get full help or, even better, run 'man %s'\\n&quot;, program_name); // exit_program(1); return 1; } /* file converter / grab */ if (nb_output_files &lt;= 0) { av_log(NULL, AV_LOG_FATAL, &quot;At least one output file must be specified\\n&quot;); //exit_program(1); return 1; } if (nb_input_files == 0) { av_log(NULL, AV_LOG_FATAL, &quot;At least one input file must be specified\\n&quot;); //exit_program(1); return 1; }把下面的内容,添加到static void ffmpeg_cleanup(int ret)函数末尾123456ffmpeg_exited = 1;nb_filtergraphs = 0;nb_output_files = 0;nb_output_streams = 0;nb_input_files = 0;nb_input_streams = 0;为了获取到ffmpeg的处理进度修改log_callback_null函数内容为12345678910111213141516static void log_callback_null(void *ptr, int level, const char *fmt, va_list vl){ static int print_prefix = 1; static int count; static char prev[1024]; char line[1024]; static int is_atty; av_log_format_line(ptr, level, fmt, vl, line, sizeof(line), &amp;print_prefix); strcpy(prev, line); if (level &lt;= AV_LOG_WARNING){ XLOGE(&quot;%s&quot;, line); }else{ XLOGD(&quot;%s&quot;, line); callJavaMethod(line);// 调用java方法,反馈进度 }}并再main函数的开始处添加1av_log_set_callback(log_callback_null); 再打开cmdutils.c,对exit_program进行修改,别忘记修改头文件中的exit_program1234int exit_program(int ret){ return ret;}然后创建一个名为ffmpegJni.c的文件和它的头文件ffmpegJni.h1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374##include &quot;logjni.h&quot;##include &quot;ffmpegJni.h&quot;##include &lt;stdlib.h&gt;##include &lt;stdbool.h&gt;int main(int argc, char **argv);static JavaVM *jvm = NULL;static jclass m_clazz = NULL;static jclass m_jobj = NULL;static JNIEnv *m_env = NULL;// 注意这里的Java_com_chaosgoo_ffmpegproject_ffmpegJni_main,请按照你的项目名称进行修改JNIEXPORT jint JNICALL Java_com_chaosgoo_ffmpegproject_ffmpegJni_main(JNIEnv *env, jclass obj, jobjectArray commands){ (*env)-&gt;GetJavaVM(env, &amp;jvm); //获取JVM虚拟机 jclass clazz = (*env)-&gt;GetObjectClass(env,obj); //获取调用此方法的java类 m_jobj = obj; m_clazz = (*env)-&gt;NewGlobalRef(env, clazz); //将这个类赋值给m_clazz m_env = env; //复制到全局变量m_env int argc = (*env)-&gt;GetArrayLength(env, commands); char *argv[argc]; int i; int result = 0; for (i = 0; i &lt; argc; i++) { jstring js = (jstring)(*env)-&gt;GetObjectArrayElement(env, commands, i); argv[i] = (char *)(*env)-&gt;GetStringUTFChars(env, js, 0); } LOGD(&quot;----------begin---------&quot;); int ret = main(argc, argv); ffmpegJniDone(1); return ret;}void callJavaMethod(char *ret){ int ss = 0; char *q = strstr(ret, &quot;time=&quot;); if (q != NULL) { //LOGE(&quot;遇到time=&quot;); char str[14] = {0}; strncpy(str, q, 13); int h = (str[5] - '0') * 10 + (str[6] - '0'); int m = (str[8] - '0') * 10 + (str[9] - '0'); int s = (str[11] - '0') * 10 + (str[12] - '0'); ss = s + m * 60 + h * 60 * 60; } else { return; } if (m_clazz == NULL) { LOGE(&quot;---------------m_clazz isNULL---------------&quot;); return; } //获取方法ID (I)V指的是方法签名 通过javap -s -public FFmpegCmd 命令生成 jmethodID methodID = (*m_env)-&gt;GetMethodID(m_env, m_clazz, &quot;onProgress&quot;, &quot;(I)V&quot;); if (methodID == NULL) { LOGE(&quot;---------------methodID isNULL---------------&quot;); return; } LOGE(&quot;---------------Call Method---------------&quot;); //调用该java方法 (*m_env)-&gt;CallVoidMethod(m_env,m_jobj, methodID, ss);}void ffmpegJniDone(int i){ jmethodID methodID = (*m_env)-&gt;GetMethodID(m_env, m_clazz, &quot;onFinish&quot;, &quot;(I)V&quot;); (*m_env)-&gt;CallVoidMethod(m_env,m_jobj, methodID, i); // 完成任务后的调用java方法,告知其已经完成}logjni.h是为了将ffmpeg自身的输出变为Android Log输出的一个头文件,内容为12345678910111213141516##ifdef ANDROID##include &lt;android/log.h&gt;##ifndef LOG_TAG##define MY_TAG &quot;MYTAG&quot;##define AV_TAG &quot;AVLOG&quot;##endif##define LOGE(format, ...) __android_log_print(ANDROID_LOG_ERROR, MY_TAG, format, ##__VA_ARGS__)##define LOGD(format, ...) __android_log_print(ANDROID_LOG_DEBUG, MY_TAG, format, ##__VA_ARGS__)##define XLOGD(...) __android_log_print(ANDROID_LOG_INFO,AV_TAG,__VA_ARGS__)##define XLOGE(...) __android_log_print(ANDROID_LOG_ERROR,AV_TAG,__VA_ARGS__)##else##define LOGE(format, ...) printf(MY_TAG format &quot;\\n&quot;, ##__VA_ARGS__)##define LOGD(format, ...) printf(MY_TAG format &quot;\\n&quot;, ##__VA_ARGS__)##define XLOGE(format, ...) fprintf(stdout, AV_TAG &quot;: &quot; format &quot;\\n&quot;, ##__VA_ARGS__)##define XLOGI(format, ...) fprintf(stderr, AV_TAG &quot;: &quot; format &quot;\\n&quot;, ##__VA_ARGS__)##endif 到这一步就可以执行ndk-build命令进行编译了.cmd 进入之前创建的jni文件夹,输入ndk-build (别忘记配置好ndk的环境变量)后,就会自动的进行编译操作, 如依然提示各种缺少文件,可以到之前解压出的ffmpeg文件夹里面去寻找到他们,然后复制到对应的文件夹中最后,编译完成后,就会多出一个libffmpegjni.so文件接下来就是Android端进行调用了创建一个FFmpegJni类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class FFmpegJni { private float totalDecodeTime = 0f; private ProgressBar progressBar; private String fileInPath; private String fileOutPath; MediaPlayer mediaPlayer = new MediaPlayer(); public FFmpegJni(String inPath, String outPath, ProgressBar progressBar){ fileInPath = inPath; fileOutPath = outPath; this.progressBar = progressBar; } // 初始化相关设定 public void init(){ try{ mediaPlayer.setDataSource(fileInPath); mediaPlayer.prepare(); totalDecodeTime = mediaPlayer.getDuration()/1000; Log.d(&quot;ffmpeg&quot;, &quot;init: &quot;+totalDecodeTime); }catch (Exception e){ e.printStackTrace(); } } //执行解码操作 public void decode(){ new Thread(new Runnable() { @Override public void run() { String[] cmd = {&quot;ffmpeg&quot;, &quot;-i&quot;,fileInPath, &quot;-f&quot;, &quot;s16be&quot; ,&quot;-ar&quot; ,&quot;44100&quot; ,&quot;-acodec&quot;,&quot;pcm_s16le&quot;, fileOutPath}; main(cmd); } }).start(); } // 更新进度条 public void onProgress(int second) { Log.d(&quot;ffmpeg&quot;, &quot;onProgress: &quot;+ ((second/this.totalDecodeTime) * 100)); progressBar.setProgress((int)((second/this.totalDecodeTime) * 100)); } // NDK 函数 public native int main(String[] commands); // 导入so文件 static { System.loadLibrary(&quot;avutil&quot;); System.loadLibrary(&quot;swresample&quot;); System.loadLibrary(&quot;avcodec&quot;); System.loadLibrary(&quot;avformat&quot;); System.loadLibrary(&quot;swscale&quot;); System.loadLibrary(&quot;avfilter&quot;); System.loadLibrary(&quot;avdevice&quot;); System.loadLibrary(&quot;ffmpegjni&quot;); }}然后再mainacitivity中调用即可,FFmpegJni的main函数接收命令. 参考资料 FFmpeg 官方文档 Android NDK 官方指南","link":"/FFmpeg-on-Android/"},{"title":"在LVGL中实现可变字体(Variable Font)-第一章","text":"在LVGL中实现可变字体(Variable Font)-第一章 在LVGL中实现可变字体(Variable Font)-第二章 在LVGL中实现可变字体(Variable Font)-第三章 前言 (2025年11月 重制版说明):这篇文章的初版我曾发布于第三方平台（简书+Bilibili），并累计获得了50,000+ 次阅读 和大量开发者的反馈。为了提供更好的阅读体验，我对文章排版和部分内容进行了优化，并将其独家发布在此个人博客 不知道多久前看到了MIUI更新了”动态字体系统“功能,不过当时没太在意(毕竟我用的也不是MIUI,哈哈哈,不过确实挺方便的),演示视频里面展示了随意调节字体粗细的功能,后来知道这个参数叫做字重(zhong第四声). 然后又有一次去Material.io时候,看见了首页的Material You概念视频手机解锁以后,系统时间的字体由细变粗.和上面MIUI动态字体系统调节字重的时候效果十分相似. 老早就听说了LVGL的大名,但是一直没有行动起来. 后来看见稚晖君的Peak和FASTSHIFT的X-Track, 羡慕极了.于是决定这次一定要试试LVGL,看看用起来到底是啥感觉. 之前自己搁那瞎捣鼓过一阵子的GUI,结果嘛,结果就是就弃坑了. 这次打算直接上LVGL这种成熟的GUI方案了,而恰好LVGL是支持FreeType的,借助FreeType就可以相对轻松的实现上面的字重动画. 什么是FreeTypeFreeType库是一个完全免费（开源）的、高质量的且可移植的字体引擎 目前主流的屏幕均都是由像素点构成,不能直接显示矢量图,所以就需要字体引擎将字体的矢量数据转换为位图数据,然后在屏幕上显示 “点灯” 出来. Variable Font又是什么储存轮廓变化数据的可变字体，在初始字形轮廓的基础上自动生成丰富的变化造型，使用户可以自由调整文字的外观。枯燥的描述不如直接上手体验一下,V-Fonts是一个在线体验可变字体的网站,拖动滑块就可以修改字体在对应轴上的值,即上述的自由调整文字的外观. 准备工作准备工作的准备工作之先把Visual Studio装了再说 下载LVGL模拟器本打算再开一篇文章说模拟器安装的,重装的时候才发现原来一键就能安装. (可能需要科学上网)直接复制git命令就完事了,下完点击LVGL.Simulator.sln直接启动.1git clone --recurse-submodules https://github.com/lvgl/lv_sim_visual_studio.git启动以后看到lvgl自带的lv_demo_widgets()运行效果. 为LVGL配置FreeType得益于lv_sim_visual_studio的完整性,刚才git clone —recurse-submodules时候freetype被一并下载了.所以现在暂时不需要额外配置什么内容,但是在其他情况下还是需要手动的配置一下LVGL的FreeType支持.(比如在板子上跑freetype的时候) LVGL内置的FreeType Demo将LVGL.Simulator.cpp内12345678910111213// ----------------------------------// Demos from lv_examples// ----------------------------------lv_demo_widgets(); // ok// lv_demo_benchmark();// lv_demo_keypad_encoder(); // ok// lv_demo_music(); // removed from repository// lv_demo_printer(); // removed from repository// lv_demo_stress(); // ok// ----------------------------------// LVGL examples// ----------------------------------修改为1234567891011121314// ----------------------------------// Demos from lv_examples// ----------------------------------// lv_demo_widgets(); // ok// lv_demo_benchmark();// lv_demo_keypad_encoder(); // ok// lv_demo_music(); // removed from repository// lv_demo_printer(); // removed from repository// lv_demo_stress(); // oklv_example_freetype_1();// ----------------------------------// LVGL examples// ----------------------------------如果一切顺利,点击运行.会看见下图 下面则是lv_example_freetype_1的内容,我已经为他添加了详luo细suo的中文注释lv_example_freetype_1.c1234567891011121314151617181920212223242526272829303132333435363738394041/** * 使用FreeType加载字体 */void lv_example_freetype_1(void){ /* 创建字体结构体 info */ static lv_ft_info_t info; /* FreeType 使用 C standard 文件系统, 所以不需要盘符 */ /* 目前程序在Windows上运行, 根目录为LVGL.Simulator.c所在文件夹 */ // 希望使用的字体的所在位置,即它的路径 info.name = &quot;./lvgl/examples/libs/freetype/arial.ttf&quot;; // 希望生成字体的高度, 这里叫作weight感觉挺奇怪的,weight应该是字重的英文 // [update-2021.12.17] 作者这里是一个失误,但是为了兼容性就没更正 // [Issues](https://github.com/lvgl/lv_lib_freetype/issues/17) info.weight = 24; // 字体的风格 info.style = FT_FONT_STYLE_NORMAL; // 字体文件指针 info.mem = NULL; // 初始化字体 if(!lv_ft_font_init(&amp;info)) { LV_LOG_ERROR(&quot;create failed.&quot;); } // 为上面的新字体创建一个style static lv_style_t style; // 初始化style lv_style_init(&amp;style); // 应用刚才创建的字体到style上 lv_style_set_text_font(&amp;style, info.font); // 设置style的align为居中 lv_style_set_text_align(&amp;style, LV_TEXT_ALIGN_CENTER); // 为上面的style创建一个label以展示 lv_obj_t * label = lv_label_create(lv_scr_act()); // 为label添加刚才创建的style lv_obj_add_style(label, &amp;style, 0); // 设置label的内容为Hello world\\nI'm a font created with FreeType lv_label_set_text(label, &quot;Hello world\\nI'm a font created with FreeType&quot;); // 居中label lv_obj_center(label);} 迫于arial.ttf不是可变字体,所以我们趁此机会修改一下lv_example_freetype_1中用到的字体,熟悉下使用其他字体的方式. Archivo-VF.ttf是一款Open Font License的字体点击这里可以下载Archivo-VF.ttf 将其复制到arial.ttf同级目录,然后修改1info.name = &quot;./lvgl/examples/libs/freetype/arial.ttf&quot;;为1info.name = &quot;./lvgl/examples/libs/freetype/Archivo-VF.ttf&quot;; 运行结果如下 字体在线展示点击这里在线体验ArchivoVF字体的可变属性 ArchivoVF的可变属性如下 最小字重100 最大字重900 最小宽度62 最大宽度125 拓展LVGL的FreeType支持由于LVGL目前版本(8.10-dev)还没有内置可变字体参数控制,所以需要我们手动的为其添加这部分内容. 添加支持前,速览下修改可变参数的方式及其啰嗦的注释(需要使用可变字体进行操作,否则无法正常运行(包括不限于崩溃以及崩溃),测试用的字体文件为Archivo-VF,可在前面一节末尾获取到) foo.c1234567891011121314151617181920212223242526272829303132333435363738394041// face的类型为FT_FaceFT_Error error;FT_MM_Var *amaster = nullptr;// 获取可变参数error = FT_Get_MM_Var(face, &amp;amaster);printf(&quot;error %d\\n&quot;, error);// 可变参数数量(每一个可变参数被称为一个axis(轴)))printf(&quot;amaster-&gt;axis=%d\\n&quot;, (amaster)-&gt;num_axis);// 注意:上面提供的Archivo-VF文件只有2个可变轴Weight和Width// 而amaster-&gt;axis是一个指向可变轴数组首位数据的指针// 可变参数的名称id,在font文件内表'name'的idprintf(&quot;amaster-&gt;axis-&gt;strid=%u\\n&quot;, amaster-&gt;axis-&gt;strid);// 可变参数的内置标签printf(&quot;amaster-&gt;axis-&gt;tag=%lu\\n&quot;, amaster-&gt;axis-&gt;tag);// 可变参数的名称printf(&quot;amaster-&gt;axis-&gt;name=%s\\n&quot;, amaster-&gt;axis-&gt;name);// 可变参数的默认值printf(&quot;amaster-&gt;axis-&gt;def=%ld\\n&quot;, amaster-&gt;axis-&gt;def);// 可变参数的最大值 16.16的定点数 amaster-&gt;axis-&gt;maximum / 65536; // 除以65536转化printf(&quot;amaster-&gt;axis-&gt;maximum=%ld\\n&quot;, amaster-&gt;axis-&gt;maximum);// 可变参数的最小值 16.16的定点数 amaster-&gt;axis-&gt;minimum / 65536; // 除以65536转化printf(&quot;amaster-&gt;axis-&gt;minimum=%ld\\n&quot;, amaster-&gt;axis-&gt;minimum);// 以前为了获得不同粗细的字体,就需要准备字重Thin,Bold,Normal这样不同字重的文件// 而引入可变字体后,一个字体文件就内置了这些Thin Bold Normal的对应字重.// 此处储存了当前轴内置默认值的数量printf(&quot;amaster-&gt;num_namedstyles=%d\\n&quot;, amaster-&gt;num_namedstyles); // 此处打印2// 可变参数的内置num_namedstyle值的数组,以字重为例,里面可能存有(100,200,300,400,500,600,700,800,900)printf(&quot;amaster-&gt;namedstyle-&gt;coords=%ld\\n&quot;, (signed long) amaster-&gt;namedstyle-&gt;coords);FT_Fixed coords[2] = { (amaster-&gt;axis)-&gt;maximum ,(amaster-&gt;axis + 1)-&gt;maximum};printf(&quot;amaster-&gt;(axis)-&gt;maximum=%ld\\n&quot;, (amaster-&gt;axis)-&gt;maximum /65536); // 此处打印900,符合前一节的图中字重最大值printf(&quot;amaster-&gt;(axis+1)-&gt;maximum=%ld\\n&quot;, (amaster-&gt;axis+1)-&gt;maximum /65536); // 此处打印125,符合前一节的图中字宽最大值// 调整可变参数的值,此处将字重和字宽都设置为最大值error = FT_Set_Var_Design_Coordinates(face, 2, coords);printf(&quot;FT_Set_Var_Design_Coordinates error %d\\n&quot;, error);printf(&quot;face num_faces: %ld\\n&quot;, face-&gt;num_faces);// 使用可变参数的内置num_namedstyle// styleIndex需要小于上述num_namedstyles// error = FT_Set_Named_Instance(m_face, styleIndex);// printf(&quot;FT_Set_Named_Instance error %d\\n&quot;, error);FT_Done_MM_Var(m_library, amaster); 由于目前版本的lvgl(8.1.0-dev)还没有提供相应的API,所以需要手动修改一些地方.打开lv_freetype.h,修改lv_ft_info_t内容,如下所示lv_freetype.h1234567typedef struct { const char * name; /* The name of the font file */ lv_font_t * font; /* point to lvgl font */ uint16_t weight; /* font weight */ uint16_t height; /* font size */ uint16_t style; /* font style */} lv_ft_info_t; 请注意: lv_ft_info_t本身就有一个名为weight的uint16_t属性,但是后续被用到了字体的宽高尺寸上,所以现在我们需要添加height取代原来的weight,让weight成为名副其实的weight 推荐先把weight重命名为height,再把后续用到weight的地方改成height,当lv_example_freetype_1又能够成功运行的时候再添加”uint16_t weight;” lv_font_fmt_ft_dsc_t也要添加字重(weight)打开lv_freetype.c,修改lv_font_fmt_ft_dsc_t内容,如下所示lv_freetype.c1234567891011typedef struct {##if LV_FREETYPE_CACHE_SIZE &gt;= 0 void *face_id;##else FT_Size size;##endif lv_font_t *font; uint16_t style; uint16_t height; uint16_t weight;} lv_font_fmt_ft_dsc_t;这里直接添加”uint16_t weight;”即可 将修改字重的代码添加到lv_freetype.c内get_glyph_dsc_cb_cache中lv_freetype.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116static bool get_glyph_dsc_cb_cache(const lv_font_t * font, lv_font_glyph_dsc_t * dsc_out, uint32_t unicode_letter, uint32_t unicode_letter_next){ LV_UNUSED(unicode_letter_next); if(unicode_letter &lt; 0x20) { dsc_out-&gt;adv_w = 0; dsc_out-&gt;box_h = 0; dsc_out-&gt;box_w = 0; dsc_out-&gt;ofs_x = 0; dsc_out-&gt;ofs_y = 0; dsc_out-&gt;bpp = 0; return true; } lv_font_fmt_ft_dsc_t * dsc = (lv_font_fmt_ft_dsc_t *)(font-&gt;dsc); FTC_FaceID face_id = (FTC_FaceID)dsc-&gt;face_id; FT_Size face_size; struct FTC_ScalerRec_ scaler; scaler.face_id = face_id; scaler.width = dsc-&gt;height; scaler.height = dsc-&gt;height; scaler.pixel = 1; if(FTC_Manager_LookupSize(cache_manager, &amp;scaler, &amp;face_size) != 0) { return false; } FT_Face face = face_size-&gt;face; FT_MM_Var* amaster = NULL; FT_Error err = FT_Get_MM_Var(face, &amp;amaster); if (err) { LV_LOG_ERROR(&quot;FT_Get_MM_Var error:%d\\n&quot;, err); return err; } // 别忘记左移16位,还有一件事,我只修改了字重,没修改字宽,所以数组大小是1 FT_Fixed coords[1] = { dsc-&gt;weight&lt;&lt;16 }; err = FT_Set_Var_Design_Coordinates(face, 1, coords); if (err) { LV_LOG_ERROR(&quot;FT_Set_Var_Design_Coordinates error:%d\\n&quot;, err); return err; } FT_Done_MM_Var(library, amaster); FT_UInt charmap_index = FT_Get_Charmap_Index(face-&gt;charmap); FT_UInt glyph_index = FTC_CMapCache_Lookup(cmap_cache, face_id, charmap_index, unicode_letter); dsc_out-&gt;is_placeholder = glyph_index == 0; if(dsc-&gt;style &amp; FT_FONT_STYLE_ITALIC) { FT_Matrix italic_matrix; italic_matrix.xx = 1 &lt;&lt; 16; italic_matrix.xy = 0x5800; italic_matrix.yx = 0; italic_matrix.yy = 1 &lt;&lt; 16; FT_Set_Transform(face, &amp;italic_matrix, NULL); } if(dsc-&gt;style &amp; FT_FONT_STYLE_BOLD) { current_face = face; if(!get_bold_glyph(font, face, glyph_index, dsc_out)) { current_face = NULL; return false; } goto end; } FTC_ImageTypeRec desc_type; desc_type.face_id = face_id; desc_type.flags = FT_LOAD_RENDER | FT_LOAD_TARGET_NORMAL; desc_type.height = dsc-&gt;height; desc_type.width = dsc-&gt;height;##if LV_FREETYPE_SBIT_CACHE FT_Error error = FTC_SBitCache_Lookup(sbit_cache, &amp;desc_type, glyph_index, &amp;sbit, NULL); if(error) { LV_LOG_ERROR(&quot;SBitCache_Lookup error&quot;); return false; } dsc_out-&gt;adv_w = sbit-&gt;xadvance; dsc_out-&gt;box_h = sbit-&gt;height; /*Height of the bitmap in [px]*/ dsc_out-&gt;box_w = sbit-&gt;width; /*Width of the bitmap in [px]*/ dsc_out-&gt;ofs_x = sbit-&gt;left; /*X offset of the bitmap in [pf]*/ dsc_out-&gt;ofs_y = sbit-&gt;top - sbit-&gt;height; /*Y offset of the bitmap measured from the as line*/ dsc_out-&gt;bpp = 8; /*Bit per pixel: 1/2/4/8*/##else FT_Error error = FTC_ImageCache_Lookup(image_cache, &amp;desc_type, glyph_index, &amp;image_glyph, NULL); if(error) { LV_LOG_ERROR(&quot;ImageCache_Lookup error&quot;); return false; } if(image_glyph-&gt;format != FT_GLYPH_FORMAT_BITMAP) { LV_LOG_ERROR(&quot;Glyph_To_Bitmap error&quot;); return false; } FT_BitmapGlyph glyph_bitmap = (FT_BitmapGlyph)image_glyph; dsc_out-&gt;adv_w = (glyph_bitmap-&gt;root.advance.x &gt;&gt; 16); dsc_out-&gt;box_h = glyph_bitmap-&gt;bitmap.rows; /*Height of the bitmap in [px]*/ dsc_out-&gt;box_w = glyph_bitmap-&gt;bitmap.width; /*Width of the bitmap in [px]*/ dsc_out-&gt;ofs_x = glyph_bitmap-&gt;left; /*X offset of the bitmap in [pf]*/ dsc_out-&gt;ofs_y = glyph_bitmap-&gt;top - glyph_bitmap-&gt;bitmap.rows; /*Y offset of the bitmap measured from the as line*/ dsc_out-&gt;bpp = 8; /*Bit per pixel: 1/2/4/8*/##endifend: if((dsc-&gt;style &amp; FT_FONT_STYLE_ITALIC) &amp;&amp; (unicode_letter_next == '\\0')) { dsc_out-&gt;adv_w = dsc_out-&gt;box_w + dsc_out-&gt;ofs_x; } return true;} 初始化的时候,别忘了lv_ft_font_init_cache时候传递字重信息lv_freetype.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263static bool lv_ft_font_init_cache(lv_ft_info_t * info){ lv_font_fmt_ft_dsc_t * dsc = lv_mem_alloc(sizeof(lv_font_fmt_ft_dsc_t)); if(dsc == NULL) return false; dsc-&gt;font = lv_mem_alloc(sizeof(lv_font_t)); if(dsc-&gt;font == NULL) { lv_mem_free(dsc); return false; } lv_memset_00(dsc-&gt;font, sizeof(lv_font_t)); lv_face_info_t * face_info = NULL; face_info = lv_mem_alloc(sizeof(lv_face_info_t) + strlen(info-&gt;name) + 1); if(face_info == NULL) { goto Fail; } face_info-&gt;mem = info-&gt;mem; face_info-&gt;size = info-&gt;mem_size; face_info-&gt;name = ((char *)face_info) + sizeof(lv_face_info_t); strcpy(face_info-&gt;name, info-&gt;name); dsc-&gt;face_id = face_info; dsc-&gt;height = info-&gt;height; dsc-&gt;weight = info-&gt;weight; dsc-&gt;style = info-&gt;style; /* use to get font info */ FT_Size face_size; struct FTC_ScalerRec_ scaler; scaler.face_id = (FTC_FaceID)dsc-&gt;face_id; scaler.width = info-&gt;height; scaler.height = info-&gt;height; scaler.pixel = 1; FT_Error error = FTC_Manager_LookupSize(cache_manager, &amp;scaler, &amp;face_size); if(error) { lv_mem_free(face_info); LV_LOG_ERROR(&quot;Failed to LookupSize&quot;); goto Fail; } lv_font_t * font = dsc-&gt;font; font-&gt;dsc = dsc; font-&gt;get_glyph_dsc = get_glyph_dsc_cb_cache; font-&gt;get_glyph_bitmap = get_glyph_bitmap_cb_cache; font-&gt;subpx = LV_FONT_SUBPX_NONE; font-&gt;line_height = (face_size-&gt;face-&gt;size-&gt;metrics.height &gt;&gt; 6); font-&gt;base_line = -(face_size-&gt;face-&gt;size-&gt;metrics.descender &gt;&gt; 6); FT_Fixed scale = face_size-&gt;face-&gt;size-&gt;metrics.y_scale; int8_t thickness = FT_MulFix(scale, face_size-&gt;face-&gt;underline_thickness) &gt;&gt; 6; font-&gt;underline_position = FT_MulFix(scale, face_size-&gt;face-&gt;underline_position) &gt;&gt; 6; font-&gt;underline_thickness = thickness &lt; 1 ? 1 : thickness; /* return to user */ info-&gt;font = font; return true;Fail: lv_mem_free(dsc-&gt;font); lv_mem_free(dsc); return false;} 效果预览不出意外的话,需要修改的地方已经修改完了,现在回到lv_example_freetype_1上来.初始化info的时候把weight也给初始化了.12// 由于已经知道了要使用的Archivo-VF最大字重900;info.weight = 900 ;然后运行就可以看到字重900的Archivo-VF 下图是在LVGL模拟器上的运行效果。 下集预告 环境1234Windows 10 Pro 18363.1556Microsoft Visual Studio Community 2019 16.6.2LVGL 8.1.1-devFreeType 2.11.0 参考资料 http://www.cppblog.com/cokecoffe/archive/2011/09/07/155264.html https://mingplusplus.com/tech/2014/09/13/freetype/ https://baike.baidu.com/item/freetype/6281493?fr=aladdin https://www.arphic.com.cn/2017/09/28/variable-font-%E5%8F%AF%E5%8F%98%E5%AD%97%E4%BD%93/ https://zh.wikipedia.org/wiki/FreeType 附件","link":"/FreeType-and-LVGL/"},{"title":"让你的ESP32显示一张公网图片吧","text":"让你的ESP32显示一张公网图片吧这篇文章写于 4 年前，但其核心原理（手动解析 HTTP 报文）在今天依然完全有效。请注意，AsyncTCP-esphome 库现在可能已有更新版本，但本教程中关于‘onData’分块处理和‘Content-Length’解析的逻辑，是您理解嵌入式网络编程的基础。 众所周知，ESP32它是能联网的，而配上屏幕，它就可以显示一张图片，那么它可以显示一张互联网上的图片吗？当然可以！虽然之前已经做过了视频的传输，而视频不过是很多图片的集合，但是那篇文章中的传输都是建立在局域网之中，通信建立在Socket上。而这次要突破局域网，使用HTTP协议来传输数据，所以会比之前复杂一些。 序使用的网络请求库为AsyncTCP-esphome，所以将以下内容添加到你的platformio.ini中123lib_deps = ottowinter/AsyncTCP-esphome@^1.1.1 ottowinter/ESPAsyncWebServer-esphome@^1.2.7这里先介绍一下HTTP协议吧，引用百度百科的原文超文本传输协议（Hypertext Transfer Protocol，HTTP）是一个简单的请求-响应协议，它通常运行在TCP之上。它指定了客户端可能发送给服务器什么样的消息以及得到什么样的响应。在这个通信过程中，客户端和服务端以报文的形式通信，客户端发送的报文叫做请求报文，服务端发送的报文叫做应答报文。其中请求报文的格式结构如下请求行 － 通用信息头 － 请求头 － 实体头 － 报文主体应答报文结构如下状态行 － 通用信息头 － 响应头 － 实体头 － 报文主体知道报文格式后，解析报文，就能获取我们想要的内容。下面通过一次演习来研究下报文有什么内容，然后再做后续开发。 演习为了此次演习，我在阿里云OSS中上传了一张很小的JPG图片，借助阿里云OSS，这张图片就有了一个固定的公网地址， 下面打开Postman，把图片地址填进去，请求头参数保持默认，然后发送请求，直接查看Postman的控制台，点击Show raw log查看原始请求日志。 请求报文如下1234567GET /response.jpg HTTP/1.1User-Agent: PostmanRuntime/7.26.10Accept: */*Postman-Token: 8f142c2a-1547-40df-a07e-637450e576c4Host: chaosgoo-pic.oss-cn-shanghai.aliyuncs.comAccept-Encoding: gzip, deflate, brConnection: keep-alive请求报文的结构如图所示请求报文中需要关注的内容有 内容 备注 GET /response.jpg HTTP/1.1 请求行，由方法字段、URL字段和HTTP协议版本字段组成 … … Host: chaosgoo-pic.oss-cn-shanghai.aliyuncs.com 请求的主机名和端口号 … … 可以发现，表中内容就是由图片的链接构造出来的。 再看一眼应答报文，应答报文的结构如图所示 应答报文如下123456789101112131415161718HTTP/1.1 200 OKServer: AliyunOSSDate: Thu, 04 Mar 2021 08:52:28 GMTContent-Type: image/jpegContent-Length: 2544Connection: keep-alivex-oss-request-id: 60409FCC0EF7D03534F4A1F5Accept-Ranges: bytesETag: &quot;C6C67E44834D62DC1FC9729C94E74CCB&quot;Last-Modified: Wed, 03 Mar 2021 18:04:44 GMTx-oss-object-type: Normalx-oss-hash-crc64ecma: 18170594484795111235x-oss-storage-class: StandardContent-Disposition: attachmentx-oss-force-download: trueContent-MD5: xsZ+RINNYtwfyXKclOdMyw==x-oss-server-time: 27##The console does not support viewing response bodies with media files. 有很多现在不需要关注的内容，只需要关心下表中的内容 内容 备注 HTTP/1.1 200 OK 状态行,由协议版本、状态码与原因短语组成 … … Content-Type: image/jpeg 实体的媒体类型 Content-Length: 2544 实体的长度，此处即为JPG图片的大小 … … 有了状态行，我们就可以知道此次请求是否成功；有了Content-Length，我们就知道目标图片的尺寸。后续操作就是先解析报文，然后根据请求行判断请求是否成功，如果成功，就继续解析应答首部，获取图片的尺寸，如果不成功，那就慢慢Debug吧。一切就绪后，那可以开始读取剩下的内容吧。由于传输过程中可能无法一次性将实体传输过来，所以实体会被分割成很多小块发送，使用extractBodyChunkFromResponseRaw提取实体并返回提取到的长度。前面client-&gt;onData([&amp;] (void arg, AsyncClient c, void *data, size_t len)会被调用很多次。在onData中的data就是每一数据帧去掉帧头和帧尾的部分，即为实体被分成的小块。由于是通过TCP传输的，所以这个大小存在上限,采用Arduino方式开发ESP32的话，MSS的值会被设置成1436。很荣幸的能够观察到这个现象，感觉摸到MTU了 代码时间请求部分代码关于网络请求操作的代码，参阅ESP32异步网络请求，本文只关注应答报文处理函数 main.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235##include &lt;Arduino.h&gt;##include &lt;AsyncTCP.h&gt;##include &lt;TFT_eSPI.h&gt;##include &lt;TJpg_Decoder.h&gt;##include &lt;WiFi.h&gt;##include &lt;Wire.h&gt;##define ssid &quot;XXXX&quot;##define password &quot;XXXX&quot;// 显示sprite的内容TFT_eSPI tft;// 图片绘制的SpriteTFT_eSprite imageSprite = TFT_eSprite(&amp;tft);// 应答报文的SpriteTFT_eSprite headerSprite = TFT_eSprite(&amp;tft);WiFiClient client;// 待显示图片尺寸uint16_t imageSize;// 已经下载的实体尺寸uint16_t readBytesSize = -1;// 图片缓存, 限制大小为16KB，你也可以设置成其他尺寸。uint8_t *imageBuffer = (uint8_t *)heap_caps_malloc(16 * 1024, MALLOC_CAP_8BIT);// 两张sprite的偏移int16_t headerSpriteOffset = 0;String header;enum ParseState { PARSE_REQ_START, PARSE_REQ_HEADERS, PARSE_REQ_BODY, PARSE_REQ_END, PARSE_REQ_FAIL, PARSE_REQ_PENDING};ParseState _parseState;/** * @brief 从初次原始报文中提取Content-Length * @param responseBody 原始报文 * @param bodyBeginIndex body起始索引 * @return 无 **/uint16_t extractContentLengthFromResponseRaw(String &amp;responseBody, uint16_t &amp;bodyBeginIndex) { int index = responseBody.indexOf(&quot;Content-Length:&quot;); int eIndex = responseBody.indexOf('\\n', index); String value = responseBody.substring(index + 16, eIndex); bodyBeginIndex = responseBody.indexOf(&quot;\\r\\n\\r\\n&quot;) + 4; return atoi(value.c_str());}/** * @brief 深度复制bytes * @param buffer 目标的容器 * @param source 原始内容 * @param length 数据长度 * @param SrcOffset 原始内容的读取偏移 * @param bufferOffset 目标的容器的写入偏移 * @return 处理的数据长度 **/size_t copyBytes(uint8_t *source, uint8_t *buffer, size_t length, size_t SrcOffset, size_t bufferOffset) { size_t count = 0; while (count + SrcOffset &lt; length) { *(buffer + count + bufferOffset) = source[count + SrcOffset]; count++; } return count;}/** * @brief 从初次原始报文中提取Content-Length * @param frameData 原始报文 * @param bodyData body数据容器 * @param length body数据长度 * @param offset body数据起始索引 * @return 处理的body长度 **/uint16_t extractBodyChunkFromResponseRaw(uint8_t *frameData, uint8_t *bodyData, uint16_t length, uint16_t srcOffset, size_t bufferOffset) { copyBytes(frameData, bodyData, length, srcOffset, bufferOffset); return length - srcOffset;}void asyncReqeust() { static AsyncClient *aClient; if (aClient) { // aClient already exists // aClient 繁忙 return; } aClient = new AsyncClient(); if (!aClient) { // could not allocate aClient // aClient 无法创建 return; } aClient-&gt;onError( [&amp;](void *arg, AsyncClient *client, int error) { Serial.println(&quot;getImageAsync:Connect Error&quot;); aClient = NULL; delete client; }, NULL); // 请求的回调 aClient-&gt;onConnect( [&amp;](void *arg, AsyncClient *client) { Serial.println(&quot;getImageAsync:Connected&quot;); aClient-&gt;onError(NULL, NULL); // 连接断开的动作 client-&gt;onDisconnect( [&amp;](void *arg, AsyncClient *c) { // status = 3; aClient = NULL; delete c; Serial.printf(&quot;getImageAsync:Disconnected\\n&quot;); _parseState = PARSE_REQ_START; }, NULL); // 接收到服务器数据时候的动作 client-&gt;onData( [&amp;](void *arg, AsyncClient *c, void *data, size_t len) { uint8_t *d = (uint8_t *)data; // _parseState为解析状态枚举类型 if (_parseState == PARSE_REQ_START) { String content = String((char *)data); _parseState = PARSE_REQ_HEADERS; uint16_t bodyBeginIndex = 0; // 从响应头中获取长度 imageSize = extractContentLengthFromResponseRaw(content, bodyBeginIndex); Serial.printf(&quot;Content-Length:%d\\n&quot;, imageSize); header = content.substring(0, bodyBeginIndex); if (imageSize &gt; 0) { _parseState = PARSE_REQ_BODY; readBytesSize = extractBodyChunkFromResponseRaw( d, imageBuffer, len, bodyBeginIndex, 0); } } else if (_parseState == PARSE_REQ_BODY) { readBytesSize += extractBodyChunkFromResponseRaw( d, imageBuffer, len, 0, readBytesSize); Serial.printf(&quot;extract size:%d\\n&quot;, readBytesSize); } if (readBytesSize == imageSize) { // 接收完成 Serial.printf(&quot;Body Received Done.received %d bytes\\n&quot;, readBytesSize); // for (int i = 0; i &lt; imageSize; i++) { // Serial.write(*buffer + i); // } // Serial.println(); _parseState = PARSE_REQ_END; } }, NULL); // 发送请求 client-&gt;write( &quot;GET /response.jpg HTTP/1.1\\r\\n&quot; &quot;Host: chaosgoo-pic.oss-cn-shanghai.aliyuncs.com\\r\\n&quot; &quot;Accept: */*\\r\\n&quot; &quot;Accept-Encoding: gzip, deflate, br&quot; &quot;Connection: keep-alive&quot; &quot;User-Agent: PostmanRuntime/7.26.10\\r\\n\\r\\n&quot;); }, NULL); if (!aClient-&gt;connect(&quot;chaosgoo-pic.oss-cn-shanghai.aliyuncs.com&quot;, 80)) { Serial.println(&quot;Connect Fail&quot;); AsyncClient *client = aClient; aClient = NULL; delete client; }}// JPG解码绘制回调bool drawCallback(int16_t x, int16_t y, uint16_t w, uint16_t h, uint16_t *bitmap) { if (imageSize == readBytesSize) { if (y &gt;= 135) { return true; } imageSprite.pushImage(x, y, w, h, bitmap); } return true;}// 推送到屏幕void pushToTFT(int offset) { headerSprite.pushSprite(0, offset); imageSprite.pushSprite(0, offset + 135);}void setup() { Serial.begin(115200); client.setTimeout(1); WiFi.begin(ssid, password); WiFi.setAutoReconnect(true); // 初始化屏幕 tft.init(); // 旋转屏幕方向，从竖变为横向 tft.setRotation(1); // 清空屏幕内容 tft.fillScreen(TFT_BLACK); // 创建Sprite imageSprite.createSprite(240, 32); headerSprite.createSprite(240, 135); // 配置TJpeg TJpgDec.setJpgScale(1); TJpgDec.setSwapBytes(true); // 设置TJpg解码器回调函数 TJpgDec.setCallback(drawCallback); delay(3000); asyncReqeust();}void loop() { if (_parseState == PARSE_REQ_END) { TJpgDec.drawJpg(0, 0, imageBuffer, imageSize); _parseState = PARSE_REQ_PENDING; headerSprite.setTextFont(1); headerSprite.setTextColor(TFT_WHITE); for (int i = 0; i &lt; header.length(); i++) { headerSprite.print(header[i]); Serial.print(header[i]); headerSprite.pushSprite(0, 0); } } pushToTFT(headerSpriteOffset); delay(100); if (headerSpriteOffset &gt; -32) { headerSpriteOffset -= headerSprite.fontHeight(1); }} platformio.ini123456789101112[env:pico32]platform = espressif32board = pico32framework = arduinomonitor_speed = 115200lib_deps = adafruit/Adafruit BusIO@^1.6.0 adafruit/Adafruit GFX Library@1.10.3 bodmer/TFT_eSPI@^2.3.41 ottowinter/AsyncTCP-esphome@^1.1.1 ottowinter/ESPAsyncWebServer-esphome@^1.2.7 bodmer/TJpg_Decoder@^0.1.0 参考资料 HTTP Web服务其二HTTP报文格式说明 MTU 和 MSS 区别 arduino-esp32/tools/sdk/include/config/sdkconfig.h","link":"/ESP32-display-remote-JPG/"},{"title":"Friday Ink 今天是周五吗","text":"今天是周五吗 2025年11月29日更新：根据读者的反馈和长达一年的实测，我补充了关于 SSD1607 与 SSD1681 屏幕驱动的功耗对比细节，以及 Rust 固件开发的更多背景。 前言这是一个拖了很久的项目, 有很多废案. 隔一段时间想起来有这回事情,于是缝缝补补, 推倒很多次. 旧设计回顾MCU从最开始使用的是ESP32, 也用过ESP32C3, 最后使用是CH582F. 起初他有很多功能,比如移植了一个lua解析器, 这样就可以动态的加载lua脚本, 以显示不同的内容. 也引入过FreeType, 用来解析.ttf字体, 以具有显示不同尺寸文字的效果. 尽管废案的完成度已经相当高了.但是实测续航表现十分糟糕. 一想到他要充电就让我感到无奈. 终于有一天看到了CH582F这款芯片. 唤起了重新实现Friday Ink的念头. 查了一些资料后, 那一刻我觉得这就是我要找的芯片. QFN28封装, 纽扣电池就能驱动, 二话不说斥巨资12元买入开发板着手开发. 基础参数硬件参数 主控为CH582F 32KB Ram + 448KB Flash 时钟芯片是PCF8563T 屏幕为1.54英寸墨水屏 SSD1607 DCDC芯片选用SGM6603-3.3YN6G CR2032电池提供电源 注: 当使用屏幕驱动IC为SSD1607时候, 需要焊接SGM6603, 因为需要借助SGM6603来彻底断开墨水屏供电 这块屏幕是我从闲鱼上捡来的, 买回来发现和合宙9.9块钱的墨水屏丝印一样, 驱动IC也一样. 在实际使用时候,休眠状态下功耗始终降低不下来. 于是我一怒之下怒一下了, 加了个DCDC来管理墨水屏的供电. 有效的将他的休眠电流从70μA降低到了3μA 当使用屏幕驱动IC为SSD1681时候, 不需要焊接SGM6603, 此时使用0欧电阻短接SGM6603的Pin5和Pin6, 并且无需焊接SGM6603下方4.7μH的电感 这是目前中景园在售的黑白双色电子墨水屏, 显示效果比我在咸鱼上买的效果好很多. 虽然分辨率同为200x200,但就是效果清晰, 对比度也好, 缺点就是比我咸鱼上5块钱买的贵. 由于能够正常休眠,所以不需要DCDC了, 功耗表现稍微比SSD1607版本好一丢丢 尺寸 34mm×39mm×8mm 耗电信息 休眠状态下≈3μA 刷新 10~20mA, 刷新完毕后会立刻进入休眠 用纽扣电池作为输入,然后接上合宙的电流表, 110小时后统计信息如下: Rust固件开发固件最开始是使用C开发的, 而且完成度也是很高, 只差休眠和蓝牙部分了. 结果这时候莫名其妙的加了一个Rust嵌入式的群, 群里面有个佬又正好做了CH582F的Rust适配.于是决定试试Rust来开发.显示部分直接用了bindgen把u8g2绑过来, bind就完事.休眠部分, ch58x-hal没有封装, 所以这次只能手搓寄存器, 于是对着官方的休眠代码, 人肉翻译了起来. 好在最后能工作(当然能工作, 毕竟我只是翻译了一下) Friday Ink的核心功能只要启动时候检测一下有没有按下按钮,按下就显示一张图片, 再去扫描周边的蓝牙广播,扫描到符合时间协议的就设置本地RTC执行重启.如果没有按下按钮就检测今天是不是星期五, 执行刷屏, 此时设备立刻休眠. 直到第二天00:00唤醒. 附加说明:在315天后的2025年6月24日, 我手上使用SSD1607版本的Friday Ink没电了, 理论上SSD1681版本功耗表现更加优异, 经过反馈续航大概在400天. Q&amp;AQ: 时间校准时候卡在校准页怎么办A: 推荐提前发送时间广播, 让手机和装置足够接近. 然后装置进入校准, 并在发现20S后未能自动退出校准或按钮无法强制退出校准时, 取下电池, 重新安装电池.Q: 小程序已经无法使用A: 时间校准协议已经公开, 还请各位复刻者使用蓝牙开发板发布符合协议的广播进行时间同步社区复刻展示很高兴在项目开源之后有小伙伴做了出来, 还加上了一个麦金塔的外壳. 项目链接GitHub项目地址立创开源广场","link":"/Friday-Ink/"},{"title":"HomeKit ESP32 Control Light II","text":"快把你家的灯接入HomeKit吧其二（舵机篇）上一篇文章中已经熟悉了如何烧录程序到ESP32，并且成功的点亮了一盏LED灯，如果你动手能力强的话。那么上一节就是教会了你做了一个支持HomeKit的灯。 本篇会将上一篇中的LED替换成一个舵机。至于为什么使用舵机，是因为我不想破坏开关的原有结构，想使用一种非侵入式的方法去拓展现有的灯开关。 重新启用环境变量如果你看完上一篇文章后重启了电脑，或者关闭了子系统，那么就得重新配置一下ESP-IDF的环境变量，也可能还需要重新将设备挂载到子系统上。使用命令1. $HOME/esp/esp-idf/export.sh即可 控制舵机0x01 控制信号要想控制舵机，就得发送正确的指令。我使用的舵机长这个样子：信号频率为50Hz.所谓的指令就是每个周期内，高电平脉冲的持续时间（宽度/长度）。 您的浏览器不支持播放该视频！视频中红色为实际信号，可以看到，随着高电平的持续时间变长，舵机的角度也越来越大。 持续时间 对应角度 0.50ms 0° 1.50ms 90° 2.50ms 180° 0x02控制相关代码对于这种由脉冲信号控制的舵机，可以使用PWM来进行控制。查阅官方的指南，可以很容易的找到相关例子，甚至直接有现成的Demo可以使用（不得不说官方的例子真的很详细）。好了，这下子也不用自己写了（还好不用，不然就得用for循环+延时，手动的凑出脉冲信号来控制了）直接到mcpwm_servo_control_example.c。复制或者下载即可，为了方便，可以复制到上一篇文章中的led.c中去，不过要记得先把之前所有的内容注释掉，因为以后还要使用到那些代码。其中123##define SERVO_MIN_PULSEWIDTH 1000 //Minimum pulse width in microsecond##define SERVO_MAX_PULSEWIDTH 2000 //Maximum pulse width in microsecond##define SERVO_MAX_DEGREE 90 //Maximum angle in degree upto which servo can rotate需要修改一下，依据我的舵机参数，将其修改为123##define SERVO_MIN_PULSEWIDTH 500 //Minimum pulse width in microsecond##define SERVO_MAX_PULSEWIDTH 2500 //Maximum pulse width in microsecond##define SERVO_MAX_DEGREE 180 //Maximum angle in degree upto which servo can rotate又因为我的板子没有引出18号引脚，所以还是修改为上篇文章中的2号引脚吧12345static void mcpwm_example_gpio_initialize(void){ printf(&quot;initializing mcpwm servo control gpio......\\n&quot;); mcpwm_gpio_init(MCPWM_UNIT_0, MCPWM0A, 18); //Set GPIO 18 as PWM0A, to which servo is connected}改为123456static void mcpwm_example_gpio_initialize(void){ printf(&quot;initializing mcpwm servo control gpio......\\n&quot;); mcpwm_gpio_init(MCPWM_UNIT_0, MCPWM0A, 2); //Set GPIO 2 as PWM0A, to which servo is connected}至此，代码就修改完成了。 0x03 烧录进去吧烧录过程没什么好说的，就是和之前大差不差。 编译好项目以后1make -C examples/esp32/led all先进行earse_flash1make -C examples/esp32/led erase_flash再进行flash。1make -C examples/esp32/led flash 0x04 看看效果吧由于烧录进去的代码只是为了控制舵机，所以是无法被添加到HomeKit里面的。当烧录完成后，舵机就会缓慢的从0度转到180度，然后快速的回到0度，再次从0度转到180度，然后无限循环。 注：控制具体转到多少度的代码如下，建议眼熟一下，下篇文章会用到。1234// 先计算出目标角度对应的高电平持续时间angle = servo_per_degree_init(count);// 设置PWM信号mcpwm_set_duty_in_us(MCPWM_UNIT_0, MCPWM_TIMER_0, MCPWM_OPR_A, angle); 下期预告:快把你家的灯接入HomeKit吧其三（整合篇）参考资料: ESP-IDF 编程指南 Espressif IoT Development Framework","link":"/HomeKit-ESP32-Control-Light-Part_One/"},{"title":"HomeKit ESP32 Control Light","text":"快把你家的灯接入HomeKit吧其一（LED篇）由于我住的地方没有床头没有灯的开关，每次都得下床才可以关灯。碰巧上次多买了一块ESP32，再碰巧的是大黄猫不久前给我发了个通过HomeKit控制他家ESP8266的视频。于是就有了这篇文章。目标很明确，那就是ESP32接入HomeKit然后通过Siri控制我的开关。 准备工作 *环境 环境 环境，配置好环境才可以开始工作，本质上最繁琐的还是配置环境。 我使用的操作系统是Windows 10 18363.719 但是真正的开发环境是位于Windows Subsystem for Linux上的Ubuntu 18.04 LTS(该操作系统可以到Windows 10自带的MicroSoft Store上进行下载)没错，我套了一层娃。 0x01 下载esp-homekit-demohttps://github.com/maximkulkin/esp-homekit-demo.git 打开终端，进入你喜欢的文件夹，使用命令1git clone https://github.com/maximkulkin/esp-homekit-demo.git下载esp-homekit-demo 0x02 下载esp32开发环境cd到~并使用mkdir创建esp文件夹并cd进入这里是由于我已经创建过了这个文件了，所以创建失败 下载esp-idf1git clone --recursive https://github.com/espressif/esp-idf.git 0x03 设置工具执行命令,整个过程都是自动的，缺少的依赖工具也会自动下载，可能最大的阻碍来自网络，所以可以考虑使用代理。12cd ~/esp/esp-idf./install.sh该过程很耗时，请耐心等待。 0x04 设置环境变量执行命令1. $HOME/esp/esp-idf/export.sh现在一切就绪，让我们使用一个LED来进行开发环境验证以及练手吧。Here we go. 点亮你的LED0x01 初始化并同步项目回到esp-homekit-demo文件夹，并使用命令1git submodule update --init --recursive 0x02 配置wifi在esp-homekit-demo文件夹下，有一个wifi.h.sample文件，内容为12##define WIFI_SSID &quot;mywifi&quot;##define WIFI_PASSWORD &quot;mypassword&quot;将其中的mywifi替换成目标Wi-Fi的SSID，mypassword替换为目标Wi-Fi的密码。然后将文件重命名为wifi.h 0x04 挂载设备到子系统上由于Ubuntu只是我们的子系统，所以它并不能直接检测到插在电脑上的ESP32，需要将其挂载到子系统上才可以检测到。别担心，操作很简单，只需复制命令即可。首先要做的是把你的ESP32插在主机上，然后到Windows的设备管理器中查看端口号，这里以我的电脑为例子可以看到我的ESP32是在COM3口上的，所以在终端里面执行命令123sudo chmod 666 /dev/ttyS3stty -F /dev/ttyS3 -astty -F /dev/ttyS3 sane 115200这样，我的ESP32就接入了子系统的ttyS3接口上 0x03 配置开发板相关参数在终端里，回到之前的esp-homekit-demo文件夹，并使用命令1make -C examples/esp32/led menuconfig选择Serial flasher config，并将端口号改为ttyS3使用esc退出并保存 0x04 编译工程使用命令1make -C examples/esp32/led all该过程也很耗时，还请耐心等待。当出现说明构建顺利完成 0x05 烧录程序为了防止之前烧录的程序产生影响，所以在每次烧录之前需要擦除flash 使用命令1make -C examples/esp32/led erase_flash当出现Serial port /dev/ttyS3 Connecting……. 时候可能需要按住ESP32板子上的boot键几秒然后松手才可以正常清除和烧录 执行烧录命令1make -C examples/esp32/led flash同样可能需要按下boot键几秒 0x06接入外设查看效果LED的demo工程里面，启用的GPIO为2号，所以我们需要将LED接入2号引脚。由于我手上没有单独的LED，所以使用一块LED灯板进行演示。2号引脚接在LED的正极，LED的负极接在GND上。 打开你的iPhone，然后启动”家庭”，点击添加配件，选择我没有或无法扫描代码。此时可以在附近的配件里面查看到Sample LED，选中它。虽然会提示未认证的配件，但是不用理会，电机仍然添加。然后输入代码11111111。稍等片刻即可添加成功。现在就可以对着手机说”嘿，Siri，开灯”或者”嘿，Siri， 关灯”。 下期预告:快把你家的灯接入HomeKit吧其二（舵机篇）参考资料:在Win10的Linux子系统下搭建ESP32的开发环境 ESP-IDF 编程指南 Espressif IoT Development Framework Build instructions ESP32","link":"/HomeKit-ESP32-Control-Light-Part_Two/"},{"title":"HomeKit ESP32 Control Light III","text":"快把你家的灯接入HomeKit吧其三（整合篇）我的回合，抽卡。发动魔法卡—融合！ 第一篇文章中介绍了如何控制LED的亮灭，而第二篇文章中介绍了如何控制舵机旋转到指定的角度，那么现在让它们融合起来了吧！ 融合前的检测在LED的Demo中，每次开灯关灯操作都会调用led_write(bool status)函数，所以我们只需要根据传进来的status值，旋转舵机到对应的角度即可。 先让我们从mcpwm_servo_control_example.c中提取出需要的方法， 内容如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889// 引入的头文件##include &quot;driver/mcpwm.h&quot;##include &quot;soc/mcpwm_periph.h&quot;##include &quot;esp_attr.h&quot;// 舵机参数的宏定义##define SERVO_MIN_PULSEWIDTH 500 // 最小脉冲时间ms##define SERVO_MAX_PULSEWIDTH 2500 // 最大脉冲时间ms##define SERVO_MAX_DEGREE 180 // 舵机最大可旋转角度// 初始化2号端口为PWMstatic void mcpwm_example_gpio_initialize(void){ printf(&quot;initializing mcpwm servo control gpio......\\n&quot;); mcpwm_gpio_init(MCPWM_UNIT_0, MCPWM0A, 18); //Set GPIO 2 as PWM0A, to which servo is connected}// 该方法输入目标角度，输出对应高电平脉冲宽度单位usstatic uint32_t servo_per_degree_init(uint32_t degree_of_rotation){ uint32_t cal_pulsewidth = 0; cal_pulsewidth = (SERVO_MIN_PULSEWIDTH + (((SERVO_MAX_PULSEWIDTH - SERVO_MIN_PULSEWIDTH) * (degree_of_rotation)) / (SERVO_MAX_DEGREE))); return cal_pulsewidth;}// 开灯函数void turn_on(void *arg){ uint32_t angle; //1. mcpwm gpio 初始化 mcpwm_example_gpio_initialize(); //2. 初始化 mcpwm 配置 printf(&quot;Configuring Initial Parameters of mcpwm......\\n&quot;); mcpwm_config_t pwm_config; pwm_config.frequency = 50; // 舵机信号频率为50Hz,每个周期时长20ms pwm_config.cmpr_a = 0; //duty cycle of PWMxA = 0 pwm_config.cmpr_b = 0; //duty cycle of PWMxb = 0 pwm_config.counter_mode = MCPWM_UP_COUNTER; pwm_config.duty_mode = MCPWM_DUTY_MODE_0; mcpwm_init(MCPWM_UNIT_0, MCPWM_TIMER_0, &amp;pwm_config); //应用上面配置到 PWM0A &amp; PWM0B // 旋转角度 printf(&quot;Angle of rotation: %d\\n&quot;, 0); // 计算60度对应的脉冲宽度 angle = servo_per_degree_init(60); printf(&quot;pulse width: %dus\\n&quot;, angle); mcpwm_set_duty_in_us(MCPWM_UNIT_0, MCPWM_TIMER_0, MCPWM_OPR_A, angle); vTaskDelay(10); //Add delay, since it takes time for servo to rotate, generally 100ms/60degree rotation at 5V vTaskDelete(NULL);}// 关灯函数void turn_off(void *arg){ uint32_t angle; //1. mcpwm gpio 初始化 mcpwm_example_gpio_initialize(); //2. 初始化 mcpwm 配置 printf(&quot;Configuring Initial Parameters of mcpwm......\\n&quot;); mcpwm_config_t pwm_config; pwm_config.frequency = 50; //frequency = 50Hz, i.e. for every servo motor time period should be 20ms pwm_config.cmpr_a = 0; //duty cycle of PWMxA = 0 pwm_config.cmpr_b = 0; //duty cycle of PWMxb = 0 pwm_config.counter_mode = MCPWM_UP_COUNTER; pwm_config.duty_mode = MCPWM_DUTY_MODE_0; mcpwm_init(MCPWM_UNIT_0, MCPWM_TIMER_0, &amp;pwm_config); //ConfigurePWM0A &amp; PWM0B with above settings printf(&quot;Angle of rotation: %d\\n&quot;, 0); // 计算120度对应的脉冲宽度 angle = servo_per_degree_init(120); printf(&quot;pulse width: %dus\\n&quot;, angle); mcpwm_set_duty_in_us(MCPWM_UNIT_0, MCPWM_TIMER_0, MCPWM_OPR_A, angle); vTaskDelay(10); //Add delay, since it takes time for servo to rotate,generally 100ms/60degree rotation at 5V vTaskDelete(NULL);}// 最后修改led_write函数为void led_write(bool on){ if (on) { // 接收到开灯命令，执行开灯任务 xTaskCreate(turn_on, &quot;turn_on&quot;, 4096, NULL, 5, NULL); } else { // 接收到关灯命令，执行关灯任务 xTaskCreate(turn_off, &quot;turn_off&quot;, 4096, NULL, 5, NULL); }}完整的文件位于HomeKitServoLight.c 来瞅一瞅效果吧。现在舵机就听我们的指令了哦！ 您的浏览器不支持播放该视频！ 再配合上一个简陋的结构，就可以控制开关了。 您的浏览器不支持播放该视频！ 老实说，我本来还计划了第四部分的“结构设计篇”，但没想到这个项目…居然烂尾了。所以，就让这个“简陋”的结构成为我们这个系列的最终成品吧！它虽然丑，但它工作得很好！ 参考资料:ESP-IDF 编程指南 Espressif IoT Development Framework","link":"/HomeKit-ESP32-Control-Light-Part_Three/"},{"title":"Other 训练一个自己的YOLO-tiny模型","text":"训练一个自己的YOLO-tiny模型0x01 YOLO是什么YOLO是一个实时目标检测系统，通俗点说就是在输入数据(图片或者视频)中查找特定的目标。举个例子，如果让一个专门识别龙的YOLO模型观看《权力的游戏》，在理想情况下，一旦画面中出现了龙，YOLO系统就会激动地用框框标记出画面中的龙。 为什么是YOLO-tiny大概是贫穷限制了我的运算速度吧，YOLO-tiny用精确度换来了速度快和性能要求低的优点，适合练手和学习或者像我一样玩一玩的用户。 0x02 事前准备的准备首先你可能需要一台电脑吧（可能有些用户会使用树莓派甚至是装了linux模拟器的安卓用户来虐待自己吧）。我的CPU是不知道应该叫啥四代ES版本的i7,显卡是上古时代的GTX860M，内存只有8G，名副其实的低配置用户了。顺便一提，这台电脑一天会绿屏N次，我会从现在开始记录绿屏次数，直到这篇文章写完，再顺带一提，这是二奶机，因为大奶机用的AMD矿卡，所以不能使用GPU来加速TensorFlow训练。再再顺带一提，旁边的室友虽然是1070Ti，但是他需要用他的电脑玩欢乐斗地主，所以不能帮我跑训练模型。回到主线上来，你还得具有一些常识…会使用搜索引擎的那种常识。 0x03 事前准备这里假设你已经安装好了Python，并且具备了一些”常识”后，你就可以继续往下看了。为了方便演示，我使用了Python的虚拟环境，并且安装了如下库 下载 https://github.com/qqwweee/keras-yolo3 页面中的文件，你可以使用git clone或者直接点击下载，然后解压。 下载 yolo-tiny的weights文件 https://pjreddie.com/media/files/yolov3-tiny.weights, 并放到上一步解压后的文件夹中进行到这里，我们接下来需要用到的文件已经准备了一半了，另外一半就是跑模型需要用到的数据。 0x04 配置相关文件首先，我们需要对yolov3-tiny.cfg进行编辑，在这个文件里，我们需要关注[yolo]和[yolo]前的一个[convolutional]首先将所有[yolo]里面classes修改为1得到classes=1classes的含义是有多少种需要被识别的物体，这里我只训练yolo识别一种物体，所以设置为1 对所有[yolo]的前一个[convolutional]中的filters进行修改其取值为filters = 3 * ( classes + 5 ),由于上一步中classes=1所以这里filters取18到这里，yolov3-tiny.cfg就修改完毕了然后是修改model_data中的coco_classes.txt和voc_classes.txt，将待检测物体的标签填写进去，每种标签占一行。因为我只有一种待识别物体，所以这两个文件中都只有一个单词进入到yolo所在目录，运行1python convert.py -w yolov3-tiny.cfg yolov3-tiny.weights model_data/tiny_yolo_weights.h5转换完成后可以看见如图所示内容 0x05 当然是制作数据啦,DIO怎么制作数据呢…我写了ImgTag去标注数据，并且在训练过程中使用ImgTag产生的数据 0x06 训练模型在训练自己的模型之前，我们还需要编辑一下train.py中的内容 anchors_path = ‘model_data/tiny_yolo_anchors.txt’ 指定anchors为tiny-yolo版本 因为我已经明确知道我训练的是yolo-tiny模型，所以在27行，修改为is_tiny_version = True此时就可以执行1python train.py 漫长的等待之后，模型就跑完了.跑完以后会显示类似内容 0x07 使用模型使用模型，就是指定yolo在检测目标时候，使用我们刚刚（可能并不是刚刚）产生的权重文件。进入到yolo的目录，编辑yolo.py其中需要重点关注的内容就是123456789_defaults = {&quot;model_path&quot;: 'model_data/yolo.h5', # 指定使用的模型&quot;anchors_path&quot;: 'model_data/yolo_anchors.txt',&quot;classes_path&quot;: 'model_data/coco_classes.txt',&quot;score&quot; : 0.3, # 当评估出的得分大于0.3时候，就标记出来&quot;iou&quot; : 0.45,&quot;model_image_size&quot; : (416, 416),&quot;gpu_num&quot; : 1,}我们需要修改以下model_path的值，因为..某些特殊的原因，我在运行的时候指定模型并不能正常进行，所以我使用这种方法。model_path那一行修改为1&quot;model_path&quot;: 'logs/000/trained_weights_final.h5',我一共标注了200张图片，相对而言图片数量可能还不够，但是已经可以看到目前模型已经可以正常识别部分浣熊了。比如银河护卫队中的火箭浣熊哦","link":"/ImgTag%E6%95%99%E7%A8%8B/"},{"title":"联想拯救者 R720 键盘矩阵分析与改造","text":"联想拯救者R720 键盘矩阵分析与改造序朋友托我帮他的R720笔记本改装成KVM.于是便有了此文. 键盘介绍主流键盘基本上都是矩阵键盘.这种方式比较节省IO.这块R720也不例外.R720的键盘一共有96个键,用矩阵键盘的方式,理论上需要(6+16=22)个IO.(其实还是挺多的)为了避免鬼键,实际的接线比理想情况下复杂.而且相较于很多DIY机械键盘的直来直去线路:R720这块键盘的内部Wiring就显得很乱了:刚测出结果的时候,总感觉自己一定是弄错了什么地方.直到后来搜到了一款名叫Framework Laptop的笔记本,有着类似的KeyMap才放下心来. KeyMap测绘搜到一篇教人把笔记本改装为KVM的文章,文章里面提到了矩阵键盘驱动控制模块Monkey.我一看这不和ATMEGA32U4差不多吗,应该是同一个系列的产品,淘宝上这东西卖50.这不是要了我的命吗.自从去年单片机涨价后,Atmel的产品到现在也没恢复过去的价格,觉得自己现在要是买了就是纯纯大冤种.况且完全可以自己做一个类似的东西,当时手上有这么多IO的板子就一个Raspberry Pi Pico,而QMK也支持了Pico,于是先借助Pico对KeyMap进行测绘.得到如下结果 你问我怎么知道Row Pin和Col Pin的,这不是巧了吗,Google一下找到了同模具笔记本的原理图(网站).顺便还知道了触摸板引脚定义,后面直接开启QMK的PS/2鼠标支持顺便把触摸板一起驱动了. Schematic得到Key Map后,就可以开始画板子的工作了.迫于当时无法使用Pico编译出支持PS/2 Mouse的固件,所以把主控换成了常见的ATMEGA32U4.换主控后,IO开始紧缺了,不过没关系.可以使用拓展IO的芯片来应付这种情况.看了一眼QMK仓库里面的方案,大部分都是使用的输出IO拓展来解决问题.非常不巧的是,这块键盘的扫描方向和常规键盘相反,所以不出意外的话我就要出意外了.于是购入74HC595对输出IO进行拓展并完美的踩了坑.重新检查才意识到我得使用74HC165拓展输入IO才行. 拖拉好久并且又踩到了PS/2 Mouse必须使用指定的IO驱动等好几个坑,最终绘制出下面使用74HC165原理图的方案(沉痛浪费很多次JLC免费打板机会.) QMK Pin Map参考测绘出的Key Map,再借助网页工具得到最终QMK固件所需的KeyMap为了让多媒体键工作正常,于是设置了两层Key Map. 12345678910111213141516171819202122const uint16_t PROGMEM keymaps[][MATRIX_ROWS][MATRIX_COLS] = { LAYOUT_pa( KC_PMNS, KC_PSLS, KC_P0, KC_LALT, KC_SPC, KC_Z, KC_B, KC_N, KC_DOWN, KC_LSFT, KC_PAST, KC_LCTL, KC_UP, KC_ENT, KC_F8, KC_C, KC_Q, KC_RALT, KC_X, KC_V, KC_M, KC_DOT, KC_RSFT, KC_COMM, KC_RCTL, KC_SLSH, KC_QUOT, KC_PPLS, KC_P9, MO(1), KC_E, KC_F2, KC_G, KC_H, KC_BSLS, KC_F7, KC_P8, KC_MINS, KC_RGHT, KC_P2, KC_LGUI, KC_TAB, KC_F4, KC_F1, KC_T, KC_Y, KC_O, KC_F6, KC_F9, KC_F12, KC_PSLS, KC_P3, KC_P7, KC_GRV, KC_CAPS, KC_S, KC_5, KC_6, KC_F10, KC_F5, KC_0, KC_EQL, KC_DEL, KC_PDOT, KC_1, KC_3, KC_2, KC_4, KC_7, KC_9, KC_8, KC_P, KC_BSPC, KC_P4, KC_P1, KC_F3, KC_W, KC_R, KC_U, KC_F11, KC_I, KC_LEFT, KC_LBRC, KC_RBRC, KC_P5, KC_NUM, KC_A, KC_ESC, KC_F, KC_J, KC_L, KC_K, KC_APP, KC_SCLN, KC_D, KC_P6), LAYOUT_pa( KC_PAUS, KC_MNXT, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_PGDN, KC_TRNS, KC_TRNS, KC_TRNS, KC_PGUP, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_MPRV, KC_TRNS, KC_TRNS, KC_VOLD, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_MPLY, KC_TRNS, KC_END, KC_PSCR, KC_TRNS, KC_TRNS, KC_TRNS, KC_MUTE, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_DEL, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_INS, KC_VOLU, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_HOME, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS, KC_TRNS),}; 实物 遗憾背光的电压是5V,但是我没有适配.我已经过了那个喜欢背光的年纪了. More笔记本主板的那个叫啥BoardView也下载到了,再对着这玩意人肉Convert(测量,然后手动绘制)一下就得到了DWG图.知道了精确的开孔,再画板子就方便固定了 参考资料老旧笔记本改造成便携KVMFramework Laptop Key MatrixQMK FirmwareLaptop Bios &amp; Schematics","link":"/Lenovo-R720-Keyboard-Matrix/"},{"title":"做个桌面像素小屏幕吧","text":"给自己做个桌面像素小屏幕吧展示一下自己制作迷你版本的像素显示屏的过程 背景之前疫情期间(2020-02~2020-03)做过一个大号的像素屏幕作为生日礼物送人了，当时使用的芯片是ESP32，开发语言是micropython。那个初号机的性能表现不是很好，所以计划做一个使用C/C++的版本，能够更高帧率运行。 如果只是纯粹的重写固件，那么和大多数人做的AWatrix就没多大区别了，所以决定做一个迷你版本的像素显示屏出来。 很多地方是参考了AWatrix的代码，因为AWatrix除了必须连接服务器才可以使用以外，真的是非常优秀的一个固件。AWatrix使用到的一些库很具有参考价值，比FastLED_NexPixel如它把LED点阵当作一块”屏幕”来使用，可以很方便的绘制出一些基础图形。开发工具为PlantformIO,也是一个很方便的工具了，VSCode装上插件就好了。 开始整活0x01 绘制电路板万能的某宝上能够找到的内置WS2812的LED贴片灯最小的就是2020LED，长宽各为2mm，比常规AWatrix使用的5050或者3535小很多。奈何没有现成品，就只能自己画一个电路板了，好在电路非常简单，就是一个接一个，然后绕成S型就好啦。 这次选择的PCB绘制软件为Eagle PCB，因为免费小巧。（但是我打算以后用KiCad画电路图了，因为开源强大）磨磨唧唧的画完了电路图。 然后提交Gerber文件到厂家，等待3天后就收到了成品。 0x02 焊接LED贴片灯这一步没什么好说的，我用的是锡膏，熔点在182度，于是先涂抹在板子上，然后风枪对着就是一阵吹。 大概花费了半天时间才焊完所有的贴片灯，因为实在是太麻烦了啊，不小心就碰掉了一个，然后发生一系列连锁反应。 0x03 获取代码，修改参数代码位于Github下载以后，使用PlantformIO导入工程。 修改位于gmatrix_config.h中的B站ID和城市以及天气的Key 123##define SUNING_TIME_URL &quot;http://quan.suning.com/getSysTime.do&quot;##define BILIBILI_SUBSCRIPTION_URL &quot;http://api.bilibili.com/x/relation/stat?vmid=哔哩哔哩UID&quot;##define WEATHER_URL &quot;http://api.openweathermap.org/data/2.5/weather?q=城市的拼音&amp;appid=天气api&quot; 修改位于Gmartix.cpp中的WiFi名称和密码。1234// WiFi名称const char *ssid = &quot;CloseWrt_9.6G_D96AS5&quot;;// WiFi密码const char *pwd = &quot;have5seeds&quot;; 然后直接使用PlantformIO的编译或者下载到板子 0x04 烧录固件使用PlantformIO可以直接下载到板子上，也可也Build以后使用其他烧录工具烧录。我使用的烧录软件是NodeMCU Firmware Programmer 插上板子选择对应的端口号，然后点击Flash就可以进行烧录了。 0x05 接线&amp;组装材料清单 序号 名称 数量 备注 1 WeMos D1 mini 1 无 2 LED板 1 自制 3 htu01d 1 温湿度传感器 4 导线 ? 无 5 3D打印外壳 1 无 6 亚克力光栅 1 无 7 A4纸 1 无 8 深色半透亚克力 1 无 9 后盖 1 可以采用任意材料自制 接线 WeMos D1 mini引脚名称 htu01d 5V VCC GND GND D3 SDA D1 SCL WeMos D1 mini引脚名称 LED屏幕 不接 正面从上至下第2个孔 GND 正面从上至下第2个孔 5V 正面从上至下第3个孔 D2 正面从上至下第4个孔 WeMos D1 mini引脚名称 散热风扇 5V 红线 GND 黑线 光栅制作使用的是定制亚克力，而外壳使用的3D打印，按照下图的顺序组装，需要注意的是光栅与深色半透亚克力之间需要加一层A4纸进行柔光。 0x06成品展示 参考资料:AWatrix materialpalette","link":"/Make%20A%20Tiny%20Pixel%20Screen/"},{"title":"ESP32并口屏幕和串口屏幕下帧率的对比","text":"前言在嵌入式开发中，屏幕刷新率是用户体验的“第一生命线”。我一直好奇，为了追求高帧率，我们是应该把 60MHz 的 SPI“优化到极致”，还是应该直接“升维打击”，采用 8 位并口？为了搞清楚这个问题，我决定自费购买硬件来进行一次“原始对决” 测试项目我特意选了两个‘不同维度’的测试： TFT_eSPI 的 graphicstest 是一个‘原始I/O’测试，它只测量‘总线’的吞吐速度。 lv_demo_music 是一个‘真实世界’测试，它测量的是‘CPU渲染 + 总线I/O’的‘综合性能’ 测试结果运行LVGL自带的lv_demo_music 对照组序号 屏幕参数 ESP32运行频率 LVGL缓冲参数 SPI速率 TFT_eSPI版本 LVGL版本 帧率 1 240x240 1.54寸 SPI LCD 240MHz 240*120 启用DMA,未使用双缓冲 60MHz 2.3.70 8.1.1-dev 26帧 2 240x240 1.33寸 8位并口 LCD 240MHz 240*120 未使用双缓冲 \\ 2.3.70 8.1.1-dev 28帧 感觉帧率差异不是很大的样子. 运行TFT_eSPI自带的Viewport_graphicstest 对照组序号 屏幕参数 ESP32运行频率 SPI速率 TFT_eSPI版本 1 240x240 1.54寸 SPI LCD 240MHz 60MHz 2.3.70 2 240x240 1.33寸 8位并口 LCD 240MHz \\ 2.3.70 运行时候明显感觉到并口的绘制速度更快,不过还是得数据说话,于是有如下Log 8位并口结果123456789101112131415TFT_eSPI library test!Benchmark Time (microseconds)Screen fill 53073Text 21126Lines 36424Horiz/Vert Lines 10469Rectangles (outline) 5918Rectangles (filled) 122742Circles (filled) 28151Circles (outline) 22372Triangles (outline) 14111Triangles (filled) 46193Rounded rects (outline) 16475Rounded rects (filled) 127122Done! 串口结果123456789101112131415TFT_eSPI library test!Benchmark Time (microseconds)Screen fill 102725Text 12506Lines 38321Horiz/Vert Lines 9293Rectangles (outline) 6594Rectangles (filled) 234378Circles (filled) 30350Circles (outline) 16884Triangles (outline) 12893Triangles (filled) 79688Rounded rects (outline) 11730Rounded rects (filled) 240258Done! 并口驱动情况下绘制时间几乎是串口驱动绘制时间的一半. 果然还是有提升的. 至于为什么在LVGL中拉不开差距,经过群友Principle点拨后意识到,运行LVGL时候CPU性能方面出现了瓶颈,我的ESP32是初代版本,如果换成最新的ESP32 S3则会拉开差距. 结论分析：CPU 瓶颈 vs I/O 瓶颈从 TFT_eSPI（原始I/O）的日志看，结果一目了然：并口几乎快了一倍（例如 Screen fill 53,073μs vs 102,725μs）。这证明了‘并口总线’存在明显的物理优势。那么，为什么在‘真实世界’（LVGL）中，差距却微乎其微（26 vs 28 帧）? 这正揭示了 ESP32（初代）的真正瓶颈：CPU 渲染速度。LVGL 的‘lv_demo_music’效果需要 CPU 大量计算，导致 CPU 100% 满载，而屏幕总线（无论是 SPI 还是并口）其实都在‘空闲等待’。 总结: 所以如果您的项目是‘重渲染’的，盲目升级屏幕接口是没用的，那就应该首先升级MCU（例如 ESP32-S3）.拓展阅读后来我刷到过P佬的文章, 他从芯片维度去对比lvgl效果. 深入分析了一些CPU, Flash相关的内容, 受益匪浅.推荐各位读者也去拜读一下((注：P佬博客的图床似乎挂了，但不影响文字的含金量))AT32F403A试玩-移植LVGL并与ESP32-S3对比","link":"/Parallel-LCD-VS-SPI-LCD/"},{"title":"做个暗金计数器吧：CS:GO StatTrak 硬件复刻全记录","text":"暗金计数器 (StatTrak) 复刻实战在 CS:GO 中，有些武器具有一个名为 StatTrak 的装置，这个装置可以记录玩家在游戏内的杀敌数量。觉得这个装置很有意思，于是想做一个出来。 为了近距离观察这个装置，我斥 8.8 元巨资购买了一把 格洛克18型(StatTrak™)|烈焰天使，并在人机对战中大杀四方。 方案迭代历程由于只是个计数器，本质就是个可以自定义显示内容的显示屏。但要做到「形神兼备」，选型和细节设计非常关键。 方案 1：OLED 12832 + Arduino谷歌一番后，发现 YouTube 上有位老哥干过类似的事情，他使用的方案正是 12832 OLED + Arduino。 问题：OLED 只有白色和蓝色，那么如何实现游戏里的橙色效果呢？ 解决方案：添加一层橙色滤膜。这位老哥使用的滤膜价格起飞，还只有小小的一块。不就是个橙色塑料片吗？窗户用的就不行吗？于是我斥巨资购买了老大一张橙色半透明塑料膜，贴到了 OLED 上，效果还挺好的。 我当时觉得这个太小了，不好微型化。（2020-11-21 现在回想一下，已经没有太大难度了） 方案 2：LED 点阵屏 + MAX7219在某宝畅游一番以后，发现并没有找到合适的点阵屏幕。不过有个 30mm 高的倒是符合一些要求，遂决定等比放大做出实物。 技术要点 详情 驱动芯片 MAX7219（SPI 接口级联） 点阵规格 8x8 LED 模块 x N PCB 设计 KiCad 绘制 焊接好以后就是这样，至于为啥看起来不一样……因为我第一次失败了。点阵屏卖家给的资料是错的，自己测是测出来了，结果画原理图的时候又搞错了。 加上一层黑色滤镜后，显示效果还凑合的样子。然而觉得外观实在是太丑了，就放弃了。 真的丑啊，我是在什么情况下才会有要使用黑色记号笔涂黑的念头啊。 方案 3：HDSP2072 古董屏 + 自制核心板有次逛闲鱼，发现了有个屏幕的参数挺符合要求的，一问价格 72，打扰了。不过咬咬牙还是买了下来。 这块屏幕是上个世纪的库存了，原来是用于大哥大上的。 硬件规格 详情 屏幕型号 HDSP-2072 主控芯片 ATmega32U4（从 Pro Micro 上拆下） 接口 Type-C（16P） PCB 工艺 JLC 5元24小时加急顺丰包邮 好在这个世纪的 Arduino 也可以正常驱动 然后觉得这次可以直接画一块完整的板子，不使用外接的 Arduino 了，是练手的好机会。就照着 SparkFun 提供的 Pro Micro 原理图一顿抄（精简），一天时间总算是画的差不多了。 然后找 JLC 24小时加急。24小时后，板子就到家了。 不得不说，Type-C 接口比 QFN44 还难焊。 由于我是从 Pro Micro 上拆下来的 ATmega32U4 芯片（掏芯窝子），所以不需要烧写 bootloader。 外壳设计迭代这个方案内部电路部分还是挺满意的，于是就开始着手于外壳制作。 外壳 V1：BB 机风格（失败） 屏幕宽度占了整体宽度的一半，直接加壳子就像一个 BB 机一样了，或者说好像一个收音机。 或许我可以让 PCB 斜着放…… 或者就让他有这个大下巴了，我是救不了了…… 不行，不可以在这里妥协啊！于是被迫想出了第二个方案。 外壳 V2：ID 无边框设计让我们致敬乐视的 ID 无边框吧！ 只要不点亮屏幕，你就永远无法知道我的实际显示区域是多少。 技术要点总结 阶段 踩坑点 经验教训 方案 1 OLED 尺寸过小 先做尺寸验证再决定方案 方案 2 点阵屏引脚资料错误 永远自己测量验证，不要盲信卖家资料 方案 2 外观过于粗糙 外观设计应与电路设计同步进行 方案 3 Type-C 焊接困难 准备助焊剂和细尖头烙铁 方案 3 外壳比例失调 考虑「ID 无边框」等视觉欺骗手法 项目开源本项目的所有设计文件（原理图、PCB、固件代码）均已开源，欢迎参考和改进。 参考资料 Pro Micro - 5V/16MHz SparkFun Qwiic Pro Micro - USB-C (ATmega32U4) Real life StatTrak - YouTube MAX7219LedMatrix - GitHub HDSP2000_Display - GitHub","link":"/StatTrak/"},{"title":"Android 进阶：如何在安卓中实现像 LVGL 一样的&quot;实体&quot;Border？","text":"做嵌入式的时候用过 LVGL，它的样式系统给我留下了深刻印象。LVGL 的 Border 是”实体”的——会占据布局空间，把内容往里挤。 安卓这边就没这么痛快了。ShapeDrawable 和 MaterialCardView 的边框更像是”装饰品”，想让边框、圆角、内边距各自独立可控？原生组件做起来挺别扭。 所以我干脆手搓了一个 BorderFrameLayout，把 LVGL 那套逻辑搬过来。图中不同的颜色代表真实占用的空间。绿色代表Border, 红色代表内部Padding, 蓝色代表Child可使用空间. 原生方案的几个坑给 View 加边框，常规做法是写个 shape XML 设成 background。但实际用起来会遇到这些问题： 圆角被子 View 盖住：容器有圆角，子 View 颜色不同时会直接覆盖掉圆角。OutlineProvider 和 clipToOutline 能用，但效果不稳定。 Padding 和 Border 混在一起：想实现”Border 占 2dp，Padding 占 10dp”，得自己算加法。逻辑一复杂就容易出错。 各边独立控制麻烦：只想要底部边框？想要虚线？XML 方案得写一堆文件。 思路：继承 FrameLayout 重写绘制既然原生不好使，那就自己来。 BorderFrameLayout 把容器边界分成两层： Background Path：整个控件的外轮廓（含圆角） Child Draw Area：扣掉边框后，子 View 实际可用的区域 Border 就画在这两层中间。 效果展示为了方便演示效果, 我在BorderFrameLayout内部放置了一个对齐底部的Button. 这个Button的位置会受到Border的尺寸和位置变化的影响产生偏移. 只有底部边框可以看到Button的底部是底部Border,而不是常规的容器底部. 右侧和底部边框（L型）引入右侧Border, Button理所应当的相左产生了些许偏移. 上右下三边虚线边框虚线Border效果展示 极端圆角当Border圆角设置的十分巨大的并且缺少一条边的Border的时候, 就得到了这个看上去十分诡异的效果, 但这确实是LVGL里能够设置出来的样式. 单边、多边、虚线、极端圆角都能正确处理。 实现细节1. 让 Border 参与布局计算重载 onLayout 和 layoutChildren，把 mBorderWidth 算进子 View 的可用空间： 1234567891011121314private fun layoutChildren(left: Int, top: Int, right: Int, bottom: Int) { // parentLeft 等边界基于 (padding + border) 计算 val parentLeft: Int = getPaddingLeftWithForeground() val parentRight: Int = right - left - getPaddingRightWithForeground() val parentTop: Int = getPaddingTopWithForeground() val parentBottom: Int = bottom - top - getPaddingBottomWithForeground() for (i in 0 until count) { val child = getChildAt(i) // 子 View 会被&quot;挤&quot;到 Border 内部 child.layout(childLeft, childTop, childLeft + width, childTop + height) }} getPadding 返回的是 mRealPadding + mBorder，让安卓系统以为这就是正常的 Padding： 123override fun getPaddingLeft(): Int { return (mRealPaddingLeft + mBorderLeft).roundToInt()} 2. 用遮罩绘制 Border一开始我试过用 Path + Stroke 的方式内缩边框，但在多边 + 极端圆角场景下，内外轮廓很难保持一致，虚线在拐角处尤其明显。 而直接画 Stroke 矩形的话，圆角内外弧度很难对齐。所以最终用的是 PorterDuffXfermode 遮罩方案： 画一个全黑的圆角外轮廓 用 DST_OUT 扣掉中间内容区 得到只有边框形状的 Mask 用 SRC_IN 把 Border 颜色填进去 12345678910111213141516171819val maskBitmap = Bitmap.createBitmap(width, height, Bitmap.Config.ALPHA_8)val maskCanvas = Canvas(maskBitmap)// 填充外轮廓maskCanvas.drawPath(mBackgroundPath, mBorderPaint.apply { style = Paint.Style.FILL color = Color.BLACK})// 扣掉内部区域mBorderPaint.xfermode = PorterDuffXfermode(PorterDuff.Mode.DST_OUT)maskCanvas.drawPath(generateChildDrawAreaPath(), mBorderPaint)// 用 Mask 限制 Border 绘制范围canvas.drawBitmap(maskBitmap, 0f, 0f, mBorderPaint)mBorderPaint.xfermode = PorterDuffXfermode(PorterDuff.Mode.SRC_IN)canvas.drawRect(0f, 0f, width.toFloat(), height.toFloat(), mBorderPaint.apply { this.color = mBorderColor}) 不管 Border 多宽、圆角多夸张，边缘都能对齐。 3. 虚线边框在 Mask 阶段加一层 DashPathEffect： 12345678910if (mBorderStyle == 1) { counterPath.addRoundRect(/* 中间轮廓 */) maskCanvas.drawPath(counterPath, mBorderPaint.apply { style = Paint.Style.STROKE pathEffect = DashPathEffect( floatArrayOf(maxDashIntervals, maxDashIntervals * 3), 0f ) })} 4. 内容裁剪防止子 View 覆盖圆角： 12345678910override fun dispatchDraw(canvas: Canvas) { drawBorderAndBackground(canvas) canvas.save() if (clipContent) { canvas.clipPath(mBackgroundPath) canvas.clipPath(generateChildDrawAreaPath()) } super.dispatchDraw(canvas) canvas.restore()} 这种方案在 Border 高频变化时会有一定 Bitmap 重建开销，更适合样式稳定的容器类组件。 XML 声明式用法定义自定义属性后可以直接在布局里用： attrs.xml123456789101112131415161718192021222324&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;&lt;resources&gt; &lt;declare-styleable name=&quot;BorderFrameLayout&quot;&gt; &lt;attr name=&quot;borderRadius&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;borderWidth&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;borderLeft&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;borderTop&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;borderRight&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;borderBottom&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;borderColor&quot; format=&quot;color&quot; /&gt; &lt;attr name=&quot;borderStyle&quot; format=&quot;enum&quot;&gt; &lt;enum name=&quot;solid&quot; value=&quot;0&quot; /&gt; &lt;enum name=&quot;dash&quot; value=&quot;1&quot; /&gt; &lt;/attr&gt; &lt;attr name=&quot;backgroundGradientAngle&quot; format=&quot;float&quot; /&gt; &lt;attr name=&quot;backgroundGradientColor&quot; format=&quot;color&quot; /&gt; &lt;attr name=&quot;realPaddingLeft&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;realPaddingTop&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;realPaddingRight&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;realPaddingBottom&quot; format=&quot;dimension&quot; /&gt; &lt;attr name=&quot;backgroundColor&quot; format=&quot;color&quot; /&gt; &lt;attr name=&quot;clipContent&quot; format=&quot;boolean&quot; /&gt; &lt;/declare-styleable&gt;&lt;/resources&gt; 12345678910111213&lt;io.serialflow.editor.ui.BorderFrameLayout android:layout_width=&quot;200dp&quot; android:layout_height=&quot;200dp&quot; app:borderRadius=&quot;24dp&quot; app:borderWidth=&quot;8dp&quot; app:borderColor=&quot;#FF0000&quot; app:borderStyle=&quot;dash&quot; app:backgroundColor=&quot;#FFEEEE&quot; app:clipContent=&quot;true&quot;&gt; &lt;!-- 子 View 会被自动挤到边框内部 --&gt;&lt;/io.serialflow.editor.ui.BorderFrameLayout&gt; 完整代码BorderFrameLayout.kt12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182package io.serialflow.editor.uiimport android.content.Contextimport android.graphics.*import android.util.AttributeSetimport android.view.Gravityimport android.widget.FrameLayoutimport kotlin.math.PIimport kotlin.math.cosimport kotlin.math.roundToIntimport kotlin.math.sinimport io.serialflow.editor.Rclass BorderFrameLayout : FrameLayout { private val DEFAULT_CHILD_GRAVITY = Gravity.TOP or Gravity.START protected var clipContent: Boolean = true private var mBackgroundPath = Path() private var mBorderInnerContourPath = Path() private var mBorderRadius = 0f private var mBorderWidth: Float = 0f private var mBorderLeft: Float = 0f private var mBorderTop: Float = 0f private var mBorderRight: Float = 0f private var mBorderBottom: Float = 0f private var mRealPaddingLeft: Float = 0f private var mRealPaddingTop: Float = 0f private var mRealPaddingRight: Float = 0f private var mRealPaddingBottom: Float = 0f private val mBorderPaint = Paint().apply { isAntiAlias = true style = Paint.Style.FILL } private var mBorderColor: Int = Color.TRANSPARENT private var mBorderStyle: Int = 0 private var mBackgroundColor: Int = Color.TRANSPARENT private var mBackgroundGradientAngle = 0f private var mBackgroundGradientColor = Color.TRANSPARENT private val counterPath = Path() constructor(context: Context) : this(context, null) constructor(context: Context, attrs: AttributeSet?) : this(context, attrs, 0) constructor(context: Context, attrs: AttributeSet?, defStyle: Int) : super( context, attrs, defStyle ) { val typedArray = context.obtainStyledAttributes(attrs, R.styleable.BorderFrameLayout, defStyle, 0) mBorderRadius = typedArray.getDimension(R.styleable.BorderFrameLayout_borderRadius, 0f) mBorderColor = typedArray.getColor(R.styleable.BorderFrameLayout_borderColor, Color.TRANSPARENT) if (mBorderColor != Color.TRANSPARENT) { mBorderColor = mBorderColor or 0xff000000.toInt() } mBorderStyle = typedArray.getInt(R.styleable.BorderFrameLayout_borderStyle, 0) mBackgroundColor = typedArray.getColor(R.styleable.BorderFrameLayout_backgroundColor, Color.TRANSPARENT) mBackgroundGradientAngle = typedArray.getFloat(R.styleable.BorderFrameLayout_backgroundGradientAngle, 0f) mBackgroundGradientColor = typedArray.getColor(R.styleable.BorderFrameLayout_backgroundGradientColor, Color.TRANSPARENT) clipContent = typedArray.getBoolean(R.styleable.BorderFrameLayout_clipContent, true) mRealPaddingLeft = typedArray.getDimension(R.styleable.BorderFrameLayout_realPaddingLeft, 0f) mRealPaddingTop = typedArray.getDimension(R.styleable.BorderFrameLayout_realPaddingTop, 0f) mRealPaddingRight = typedArray.getDimension(R.styleable.BorderFrameLayout_realPaddingRight, 0f) mRealPaddingBottom = typedArray.getDimension(R.styleable.BorderFrameLayout_realPaddingBottom, 0f) val borderWidth = typedArray.getDimension(R.styleable.BorderFrameLayout_borderWidth, 0f) val borderLeft = typedArray.getDimension(R.styleable.BorderFrameLayout_borderLeft, borderWidth) val borderTop = typedArray.getDimension(R.styleable.BorderFrameLayout_borderTop, borderWidth) val borderRight = typedArray.getDimension(R.styleable.BorderFrameLayout_borderRight, borderWidth) val borderBottom = typedArray.getDimension(R.styleable.BorderFrameLayout_borderBottom, borderWidth) typedArray.recycle() setBorderWidth(borderLeft, borderTop, borderRight, borderBottom) } // ... 完整代码见项目源码 ...} 源码可见BorderFrameLayout.kt","link":"/android-lvgl-style-border/"},{"title":"如何从零开始：用 CH592F 制作 CS2 同人生命值胸章并实现 GSI 联动","text":"免责声明 (Disclaimer)本项目仅为作者出于技术探索和个人兴趣进行的非商业同人创作 (Fan-made Project)。所有设计资源（PCB/代码）仅供电子技术交流与学习参考，严禁用于任何商业用途或批量生产销售。 关于权属：文中提及的 “Counter-Strike 2” (CS2) 及其相关素材权属归 Valve Corporation 所有。本站与 Valve 无任何关联，亦未获得官方授权，本项目是对游戏机制在硬件层面的同步技术验证。 背景在CS2中(CS:GO里面也有)中有一个叫做生命值胸章的饰品第一次看到时候就觉得这个很适合使用LED做出来.而且还可以通过CSGO GSI同步游戏中生命值状态. 补充说明有不少人指出胸章出自半条命:Alyx,以前只在朋友家玩过开头, 对这个装置在半条命中的印象不是很深了.观看了一些Alyx的实况视频后了解到这个装置的更为具体的一些信息, 或许将来可以制作三个完整的爱心版本,然后像Alyx中的一样, 每颗心都有大小的变化, 极大的提高了丰富表现力. 元件选型MCU选型由于胸章的尺寸较小(60mmx20mm), 而且我也不希望成品太厚无法佩戴,还不想拖着一根线,所以主控得是一个支持无线(乐鑫:有人叫我?)的芯片.虽然我很喜欢乐鑫家的芯片(我之前写过很多关于 ESP32 串流 和 ESP32 显示公网图片 的教程）),但是抱歉, 这次真的对不起,你的功耗实在是太高了. 之前在制作Friday Ink时候,用的芯片是CH582F, 使我对WCH王翠花家的芯片略有好感,不仅便宜够用,功耗还低. 结合成本和开发量评估后, 最终选择WCH王翠花家的CH592F作为主控, 和之前的CH582F对比, 只是RAM略有些减少, 但是对于当前的HealthPin是绝对足够的. LDO选型之前爱用的LDO是AP2112K-3.3TRG, 源自多年前抄Arduino Pro micro时候形成的习惯. 为了进一步压缩成本, LDO换成了更容易购买到而且仅需0.18元的ME6211. 锂电池充电芯片选型在之前的罗盘设计中, 锂电池充电管理芯片用的是MCP73831, 这款IC我首次购买时候4元,后来居然涨价到了8元(不过最近有所回落,但还是让我有所忌惮).因此充电管理芯片换成了仅需0.45元的TP4057, 二者外围器件差异不大,仅需注意引脚定义. 灯珠和MOS选择你知道的, RGB可以提升300%性能,所以灯珠毫不犹豫的选择了内置WS2812B的1mm x 1mm RGB灯珠. 考虑到WS2812B的静态功耗有点大, 对于我们本来就不大的电池来说雪上加霜, 所以三颗心分为三组, 除了最小的那颗心无法主动关闭供电外, 其余两颗心都会使用MOS管控制电源开关,达到不用时候彻底关闭省电的目的.对于灯泡、电机这类无源负载，通常使用驱动简单的NMOS作为下管来控制其地线回路。而对于WS2812B这类需要与MCU进行精确数字通信的有源器件，为了确保通信信号的完整性以及两者之间的稳定共地，优选使用PMOS作为上管来控制其电源，而不是控制其地线。为了节省空间, 选择一个SOT23-6封装的BRCS4953提供双PMOS. 关于 WS2812 的驱动原理，我最终采用了 SPI+DMA 零 CPU 占用方案。详细的实现原理和代码解析，请参阅本项目的深度分析文章：《CH592F利用SPI+DMA驱动WS2812灯珠》。 PCB设计尝试过把灯珠和主控分别放在两张板子上, 再焊接方式粘在一起, 但是这样会增加一个板子的厚度,成本也会因此上升.遂放弃这个方案, 继而使用传统的双面元件方式实现.PCBA最终渲染如下:其中电池外围则印有BOMB HAS BEEN PLANTED HANDLE WITH CARE字样彩蛋. 实物焊接效果展示由于没有外壳, 而且阻焊是白色,所以看上去和游戏原设计有所出入. 程序StatTrak项目回顾在CS:GO还没升级成为CS2的时候,我就在现实中制作过一个可以和游戏联动的StatTrak.当时方案是直接编写一个python脚本和CS:GO GSI通信, 再借助pyserial向装置发送击杀数据. Auraro我记得罗技的GHUB是能够控制自家设备和游戏的联动, 于是就在想是否有类似的开源方案来做到类似的统一管理. 一方搜索后得知了Project Aurora这个开源项目. 最最令人激动的是, Aurora不仅仅适配了很多知名厂商的设备, 他甚至还有一套Device Script来供第三方设备实现对接. Device Script编写在Aurora的仓库下有一个example_script.cs提供了简单的示例.HealthPin的通信方式是使用蓝牙HID, 而蓝牙HID装置在连接电脑后会被视作一个普通的HID装置, 只需要使用标准HID通信API向装置发送数据即可. 协议拟定和实现我们的装置有LED和蜂鸣器, 所以协议中在将装置这些能力暴露出来. 初步定义如下类型的协议结构和Command, 并且着重介绍SetHeartColor命令1234567891011121314151617181920212223242526272829303132333435363738394041424344// 命令 ID 枚举enum class HidCommand : uint8_t { Ping = 0x01, Reboot = 0x0F, SetAllLEDs = 0x11, ShowLEDs = 0x12, ClearAllLEDs = 0x13, SetSingleLED = 0x14, SetHeartColor = 0x15, SetLEDRange = 0x16, PlayBeep = 0x21, BuzzerOn = 0x22, BuzzerOff = 0x23};// CMD 0x15 (Set Heart)struct Payload_SetHeart { uint8_t heart_id; uint8_t r; uint8_t g; uint8_t b; uint8_t reserved[3];};// Payload 的 Unionunion HidPayloadUnion { uint8_t raw[7]; // 原始 7 字节 Payload_SetAll setAll; Payload_SetSingle setSingle; Payload_SetHeart setHeart; Payload_SetRange setRange; Payload_PlayBeep playBeep; Payload_BuzzerOn buzzerOn; Payload_NoArgs noArgs;};/** * @brief HID 命令包结构体 * HID 堆栈已经消费了 Report ID，所以不包含 Report ID， */struct HidCommandPacket { uint8_t cmd; // Byte 0 (命令 ID) HidPayloadUnion payload; // Bytes 1-7 (负载)}; Device Script完善Aurora下发颜色配置时候, 会触发Script Device的UpdateDevice(object keyColors, bool forced)函数, 这个函数里面我们可以查询到所有键位颜色信息. 而HealthPin三颗心分别被映射到了键盘的7,8,9三个键,所以只关注这三个键的数据即可. 当然如果你想关注F1,F2,F3的配置也没问题, 只是需要注意在调整Profiles时候要设置对应的按键.123456789101112131415161718192021222324Color targetHeart1 = Color.Black;Color targetHeart2 = Color.Black;Color targetHeart3 = Color.Black;var dict = keyColors as IDictionary;foreach (DictionaryEntry entry in dict){ string key = entry.Key?.ToString(); if (string.IsNullOrEmpty(key)) continue; if (key.Equals(&quot;NUM_SEVEN&quot;, StringComparison.OrdinalIgnoreCase)) { targetHeart1 = ParseColorObject(entry.Value); hasUpdate = true; } else if (key.Equals(&quot;NUM_EIGHT&quot;, StringComparison.OrdinalIgnoreCase)) { targetHeart2 = ParseColorObject(entry.Value); hasUpdate = true; } else if (key.Equals(&quot;NUM_NINE&quot;, StringComparison.OrdinalIgnoreCase)) { targetHeart3 = ParseColorObject(entry.Value); hasUpdate = true; }} 获取到颜色数据,只需要使用HidD_SetFeature函数发送数据即可.1234private static extern bool HidD_SetFeature( SafeFileHandle HidDeviceObject, byte[] ReportBuffer, uint ReportBufferLength); 下位机程序当初选择CH592F有大原因就是有很多人用它做键盘, 而且官方的例子中就有一个基于蓝牙的HID_Keyboard example. 在构思本项目时候, 就像好了要伪装成为一个HID设备, 再和电脑走HID进行通信. 这个方案不用考虑串口驱动或者其他USB驱动的麻烦事情了. 驱动WS2812B具体可以参考WCH官方实现, 巧妙地使用了SPI来模拟WS2812时序,这里不做赘述. HID命令解析这部分和上位机反着处理即可, 在hidEmuRptCB函数中, 处理HID_DEV_OPER_WRITE的情况,然后区分是否是我们需要关注的事件.123456789101112131415161718192021222324252627282930313233343536373839404142434445464748// 解析自定义的HID灯光协议HidCommandPacket *packet = reinterpret_cast&lt;HidCommandPacket *&gt; (pData);// USB_Printf(&quot; -&gt; Received Command ID: %d\\n&quot;, packet-&gt;cmd);switch (static_cast&lt;HidCommand&gt; (packet-&gt;cmd)) {case HidCommand::ShowLEDs: { extern NeoPixelController *g_pLeds; if (g_pLeds) { g_pLeds-&gt;show(); } break;}case HidCommand::SetHeartColor: { uint8_t heart_id = packet-&gt;payload.setHeart.heart_id; uint8_t r = packet-&gt;payload.setHeart.r; uint8_t g = packet-&gt;payload.setHeart.g; uint8_t b = packet-&gt;payload.setHeart.b; extern NeoPixelController *g_pLeds; if (g_pLeds) { switch (heart_id) { case 0: g_pLeds-&gt;heart1 (r &lt;&lt; 16 | g &lt;&lt; 8 | b); break; case 1: g_pLeds-&gt;heart2 (r &lt;&lt; 16 | g &lt;&lt; 8 | b); break; case 2: g_pLeds-&gt;heart3 (r &lt;&lt; 16 | g &lt;&lt; 8 | b); break; default: // 无效的 heart_id，忽略 break; } } break;}case HidCommand::PlayBeep: case HidCommand::BuzzerOff:case HidCommand::SetSingleLED:case HidCommand::SetAllLEDs: { // 省略其余具体实现 break;}default: // 收到未知命令 break;} 然后享受Aurora对大量游戏的支持,以及丰富的灯光配置. 视频 法律及版权说明 软件协议：本项目中涉及的代码部分仅供学习研究。 商标声明：Valve, Counter-Strike, Steam, Half-Life 及其对应的徽标均为 Valve Corporation 的商标及/或注册商标。 不诚实行为合规：本项目不涉及对游戏的修改、破解或作弊，仅通过官方允许的 GSI (Game State Integration) 接口读取只读数据展示呼吸灯效果。","link":"/Real-life-HealthPin/"},{"title":"CH592F利用SPI+DMA驱动WS2812灯珠","text":"前言 在上一篇《从零开始：用CH592F制作CS2生命值胸章》的文章中，我展示了如何利用CH592F这颗蓝牙芯片制作一个和游戏联动的生命值指示器. 而本文将介绍生命值计数器的一个技术细节:如何使用CH592F驱动WS2812.虽然WS2812的时序要求比较严格，通常可以使用GPIO翻转配合精准延时来实现，但那样会占用大量的CPU资源，导致蓝牙协议栈或其他中断任务受阻.为了实现“零”CPU占用的炫酷灯效，我决定利用CH592F的SPI外设配合DMA来模拟WS2812的时序. 原理分析WS2812的通讯协议大家都烂熟于心了，核心就是通过高低电平的占空比来区分0码和1码. 0码：高电平时间短（~0.4us），低电平时间长. 1码：高电平时间长（~0.8us），低电平时间短. 整个周期大约在1.25us左右，即频率约为800kHz. 如果我们将SPI的时钟频率设定为WS2812频率的4倍（约3.2MHz），那么发送一个字节（8位）的SPI数据所占用的时间，刚好对应2个WS2812的位周期（因为这里我们用4个SPI位来表示1个WS2812位）. 模拟0码：发送二进制 1000 (0x8)，即1个高电平+3个低电平. 模拟1码：发送二进制 1110 (0xE)，即3个高电平+1个低电平. 这样，我们只需要在内存中开辟一块缓存，将RGB颜色数据“膨胀”转化为对应的SPI数据，然后通过DMA一键发送，即可彻底解放CPU. 核心代码实现1. 初始化SPI首先需要配置SPI0为主机模式.CH592F的系统主频通常为48MHz，为了凑出3.2MHz的SPI时钟，我们需要设置分频系数.48MHz / 15 = 3.2MHz. NeoPixel.cpp - init12345678910111213141516void NeoPixelController::begin() { // 配置GPIO，PA12/13/14通常对应SPI0 GPIOA_ResetBits (GPIO_Pin_12); GPIOA_ModeCfg (GPIO_Pin_12 |GPIO_Pin_13 | GPIO_Pin_14, GPIO_ModeOut_PP_5mA); // 初始化SPI0 SPI0_MasterDefInit(); // 设置分频，15分频得到3.2MHz // 注意：实际调试中可能需要根据示波器微调 SPI0_CLKCfg (15); // 发送复位信号（WS2812需要 &gt;50us 的低电平复位） // 这里发送一段全0数据即可 memset (_spiBuffer, 0, 24); SPI0_MasterDMATrans (_spiBuffer, 24);} 2. 数据转换 (GRB -&gt; SPI)这是最关键的一步.我们需要将内存中紧凑的RGB（实际是GRB顺序）数据，展开为SPI总线需要的波形数据.这里定义了两个宏来代表SPI发送的4位数据片段： GRB_CODE_0: 0x8 (对应二进制 1000) GRB_CODE_1: 0xE (对应二进制 1110) 为了节省空间，我们一个字节的SPI buffer存储两个WS2812位. NeoPixel.cpp - convert12345678910111213141516171819202122232425262728// 补充宏定义，用于生成波形##define GRB_CODE_0 0x8##define GRB_CODE_1 0xEvoid NeoPixelController::convertGRBtoSPI (const uint8_t *grb, uint8_t *spi, uint16_t len) { // len 是LED的数量 // 每个LED 3个字节颜色，每个颜色位需要4位SPI数据 // 所以SPI buffer长度 = len * 3 * 4 (bytes) memset (spi, 0, len * 3 * 4); for (uint16_t i = 0; i &lt; len; i++) { for (uint8_t j = 0; j &lt; 3; j++) { // R, G, B 三个通道 for (uint8_t k = 0; k &lt; 4; k++) { // 每个字节8位，分为4组，每组2位 for (uint8_t m = 0; m &lt; 2; m++) { // 处理每组中的2位 // 检查GRB颜色数据的特定位是否为1 // 逻辑比较绕，本质就是从高位到低位通过掩码取值 if (grb[3 * i + j] &amp; (0x80 &gt;&gt; (2 * k + m))) { // 如果是1，SPI buffer填入 1110 (高位) 或 1110 (低位) spi[3 * 4 * i + 4 * j + k] |= (GRB_CODE_1 &gt;&gt; (m * 4)); } else { // 如果是0，SPI buffer填入 1000 (高位) 或 1000 (低位) spi[3 * 4 * i + 4 * j + k] |= (GRB_CODE_0 &gt;&gt; (m * 4)); } } } } }} 3. DMA 发送数据转换完成后，发送过程就非常简单了.直接调用CH592F的DMA传输函数，CPU就可以去处理蓝牙连接或者睡觉了. NeoPixel.cpp - show1234567void NeoPixelController::show() { // 1. 将颜色数据转换为SPI波形数据 convertGRBtoSPI (_grbBuffer, _spiBuffer, _numLeds); // 2. 启动DMA传输 // 长度计算：LED数量 * 3(RGB) * 4(膨胀系数) SPI0_MasterDMATrans (_spiBuffer, _numLeds * 3 * 4);} 封装与调用为了方便使用，我将其封装成了一个NeoPixelController类，模仿了Arduino Adafruit_NeoPixel的接口风格. 头文件 NeoPixel.h:NeoPixel.h1234567891011121314151617181920212223242526272829303132333435##ifndef NEOPIXEL_H##define NEOPIXEL_H##include &quot;CH59x_common.h&quot;class NeoPixelController {public: // 构造函数，需要指定LED数量和SPI buffer大小 // 注意：_spiBuffer 最好在外部申请或者在类中动态申请 NeoPixelController (uint16_t numLeds, uint8_t spiInstance = 0); void begin(); void show(); void setPixelColor(uint16_t index, uint32_t color); void setPixelHSV(uint16_t index, uint8_t hue, uint8_t sat, uint8_t val); void clear(); void setBrightness(uint8_t brightness); // 简单的颜色工具 static uint32_t Color(uint8_t r, uint8_t g, uint8_t b);private: uint16_t _numLeds; uint8_t _spiInstance; uint8_t _brightness; // 这里为了演示方便，假设最大支持一定数量，实际应动态分配 uint8_t _grbBuffer[100 * 3]; uint8_t _spiBuffer[100 * 3 * 4]; void convertGRBtoSPI(const uint8_t *grb, uint8_t *spi, uint16_t len); uint32_t colorHSV(uint8_t hue, uint8_t sat, uint8_t val);};##endif 在主程序 Main.c 中调用： 123456789101112131415NeoPixelController strip(32); // 控制32颗灯珠int main() { SetSysClock(CLK_SOURCE_PLL_48MHz); strip.begin(); strip.setBrightness(50); while(1) { // 跑个彩虹特效 static uint8_t hue = 0; strip.rainbow(hue++, 255, 255); strip.show(); DelayMs(10); }} 总结通过SPI+DMA的方式驱动WS2812，最大的优势在于时序极其稳定，且不消耗CPU算力.这对于CH592F这种单核蓝牙SoC来说非常重要，避免了因为关闭中断写时序而导致蓝牙连接不稳定的问题. 唯一的代价就是内存占用稍微大了一些（每个LED需要12字节的SPI buffer），但对于几十颗灯珠的装饰应用来说，CH592F的RAM绰绰有余. 补充说明代码不仅仅可以运行在CH592系列芯片, 还可以运行在CH582系列芯片.","link":"/ch58x-dma-spi-ws2812-driver/"},{"title":"复刻 Stack Overflow 愚人节“神作”：3 键机械键盘实战指南","text":"背景2021 年愚人节，Stack Overflow 搞了一个非常有意思的彩蛋：限制用户的复制次数，并“推销”了一款只有三个键的定制键盘。 这个小巧精致的键盘激发了我的创作欲。思考了一下，实现逻辑其实非常简单，基本上把我之前做的“原神自动弹琴装置”稍加修改即可，核心代码甚至在百行以内。 随后我打开 KiCad 直接开干，从原理图到 3D 渲染一气呵成。 🛠️ 核心设计思路：为什么是 ATMega32u4？在开始制作之前，选型是关键。Stack Overflow 官方彩蛋中的键盘只有三个键：Ctrl、C、V。 为了实现这个功能，我选择了 ATMega32u4 作为主控： 原生 HID 支持： 与普通的 ESP32 或 ATMega328P 不同，32u4 自带硬件 USB 支持，可以直接被电脑识别为标准键盘（HID 终端），无需额外的串口转 USB 芯片。 成熟的固件库： 利用 Arduino 的 Keyboard.h 库，可以极速实现组合键逻辑。 📐 硬件开发：KiCad 流程与 PCB 细节在 KiCad 中，我设计了一块极简的 3% 配列 线路板。 渲染效果 关键电路特性 热插拔支持： 引入了凯华热插拔轴座（1511 系列），这意味着你可以随时更换青轴、红轴或静音轴。 电源管理： 使用了 AP2112K-3.3 LDO 芯片，确保 32u4 在稳定的电压下工作，并加入肖特基二极管防止 Type-C 接口反向供电。 模式切换： 增加了一个 2 位拨码开关。这不仅可以用来切换不同的按键映射（如 Mac/Win 切换），还能开启或关闭“连发模式”。 💻 软件实现：组合键逻辑固件的核心逻辑是将物理按键的电平变化映射为标准的 HID 编码。实现 Ctrl + C 的逻辑如下： 1234567// 示例：实现 Ctrl + C 的伪代码if (digitalRead(KEY_C_PIN) == LOW) { Keyboard.press(KEY_LEFT_CTRL); // 先按下 Ctrl Keyboard.press('c'); // 再按下 C delay(100); // 保持一小段时间 Keyboard.releaseAll(); // 释放所有按键} 材料清单 (BOM) 序号 名称 数量 备注 1 ATMega32u4 1 主控芯片 QFN44封装 2 AP2112K-3.3 1 5V转3.3V芯片 SOT-23-5 3 16Mhz晶振 1 2.0*1.6 4 1uF电容 1 0603 5 22pf电容 2 0603 6 10uf电容 2 0603 7 1KΩ电阻 5 0805 8 10KΩ电阻 1 0805 9 22Ω电阻 2 0805 10 凯华热插拔轴座 3 1511系列 11 轴体 3 任意轴体 12 2位拨码开关 1 1.27mm 13 Type-C接口 1 16p 14 肖特基二极管 1 BAT60JFILM SOD-323 15 微动开关 1 3x4x2.5 四脚贴片 焊接与组装焊接心得： QFN44 封装虽然引脚密集，但在涂抹适量锡膏后，配合热风枪（建议 350°C，中等风速）可以实现自动对准吸附。 组装： 简单的画了个方盒子作为外壳，然后从我的旧键盘上扣下来三个键帽装上去。 进阶特性与开源这把键盘虽然源于彩蛋，但具备很强的实用性： 连发模式： 通过拨码开关开启，适合某些需要快速重复操作的场景。 全平台兼容： 基于标准 HID 协议，插上即用，无需安装驱动。 开源地址： https://github.com/chaosgoo/HairsPP 附：HID 扫描码速查表 (部分)为了方便自定义按键，我整理了常用的非标准按键编码。你可以通过修改固件，实现 F13-F24 等宏功能。 控制与修饰键 (Modifier Keys) 定义 编码 (Hex) 功能描述 KEY_LEFT_CTRL 0x80 左侧 Ctrl 键 KEY_LEFT_SHIFT 0x81 左侧 Shift 键 KEY_LEFT_ALT 0x82 左侧 Alt 键 KEY_LEFT_GUI 0x83 左侧 Win / Command 键 KEY_RIGHT_CTRL 0x84 右侧 Ctrl 键 KEY_RIGHT_SHIFT 0x85 右侧 Shift 键 KEY_RIGHT_ALT 0x86 右侧 Alt 键 KEY_RIGHT_GUI 0x87 右侧 Win / Command 键 系统与导航键 (System &amp; Navigation) 定义 编码 (Hex) 功能描述 KEY_UP_ARROW 0xDA 方向键：上 KEY_DOWN_ARROW 0xD9 方向键：下 KEY_LEFT_ARROW 0xD8 方向键：左 KEY_RIGHT_ARROW 0xD7 方向键：右 KEY_BACKSPACE 0xB2 退格键 (Backspace) KEY_TAB 0xB3 制表键 (Tab) KEY_RETURN 0xB0 回车键 (Enter) KEY_ESC 0xB1 退出键 (Esc) KEY_INSERT 0xD1 插入键 (Insert) KEY_DELETE 0xD4 删除键 (Delete) KEY_PAGE_UP 0xD3 上翻页键 (Page Up) KEY_PAGE_DOWN 0xD6 下翻页键 (Page Down) KEY_HOME 0xD2 起始键 (Home) KEY_END 0xD5 结束键 (End) KEY_CAPS_LOCK 0xC1 大写锁定键 (Caps Lock) 功能键 (Function Keys) 定义 编码 (Hex) 功能描述 KEY_F1 - KEY_F12 0xC2 - 0xCD 标准功能键 F1 至 F12 KEY_F13 - KEY_F24 0xF0 - 0xFB 扩展功能键（常用于绑定宏命令，不会与系统快捷键冲突） 总结与展望这把复刻自 Stack Overflow 愚人节彩蛋的 3 键宏键盘，虽然初衷是为了好玩，但在实际制作过程中，它涵盖了 原生 USB-HID 通信、硬件电路设计以及人体工程学按键映射等多个核心知识点。 通过本项目，我们不仅实现了一个极简的生产力工具，更深入理解了： 主控选型的重要性：ATMega32u4 的硬件 USB 支持是实现低延迟、高兼容性 HID 设备的关键。 模块化设计的优势：引入热插拔轴座和拨码开关，让一个小巧的硬件具备了极高的自定义程度。 软硬结合的魅力：简单的几行代码，配合精准的硬件触发，就能大幅提升日常办公中高频操作（如剪贴、代码重构、宏命令执行）的效率。","link":"/diy-stackoverflow-3-key-macro-keyboard-with-atmega32u4/"},{"title":"告别AT指令：ESP32通过PPPoS驱动4G模块上网","text":"前言 在之前的文章中，我们都是利用ESP32自带的WiFi进行网络连接。但在户外或者没有WiFi覆盖的角落，想要让设备联网，就得请出“4G模块”了。 通常大家驱动4G模块（比如SIM800, Air724, EC20等）最原始的方法是用UART发送AT指令。比如 AT+HTTPINIT、AT+HTTPPARA… 这种方式不仅繁琐，而且解析返回字符串简直是噩梦，写出来的代码全是状态机，一旦模块吐点乱码，程序直接暴毙。手动解析AT指令简直是坏文明！ 为了优雅地使用4G模块，我决定使用 PPPoS(Point-to-Point Protocol over Serial)。简单来说，就是把串口“伪装”成一个网卡。这样底层的TCP/IP协议栈（LwIP）就能直接接管网络，我们写上层代码时，完全不用关心是在用WiFi还是4G，直接调标准的Socket接口就完事了。 准备工作1. 硬件连接找一个支持PPP拨号的模块（市面上绝大多数Cat.1/Cat.4模块都支持）。我用的是合宙的Air780EG, 这个模块属于4G+GNSS二合一模块, 在制作需要定位的设备很方便.将模块的 TX/RX 接到 ESP32C3 的串口引脚上（记得共地） PS: 模块进入PPPOS状态以后GPS就不能走主串口输出好消息是我们可以使用ESP32C3的另外一个串口和GPS串口对接, 这样就可以同时使用GPS和4G PPPOS拨号了比如说我用的是GPIO8和GPSTX连接, TXD0和RXD0接4G模块的主串口 核心代码实现示例项目可以通过下面命令创建1idf.py create-project-from-example &quot;espressif/esp_modem=1.0.3:pppos_client&quot; 接下来会基于 ESP-IDF 的 pppos_client 示例解析解析并补充说明. 整个过程其实就分三步：定义事件、初始化DCE/DTE、切换到数据模式。 1. 事件处理 (Event Handler)PPPoS 的运行依赖于事件驱动。我们需要监听 IP 层面的事件，当拿到 IP 地址时，才算真正联网成功。 modem_event.c123456789101112131415161718192021222324static EventGroupHandle_t event_group = NULL;static const int CONNECT_BIT = BIT0;static const int DISCONNECT_BIT = BIT1;// 监听 IP 获取事件static void on_ip_event(void *arg, esp_event_base_t event_base, int32_t event_id, void *event_data){ if (event_id == IP_EVENT_PPP_GOT_IP) { ip_event_got_ip_t *event = (ip_event_got_ip_t *)event_data; // 打印一下获取到的IP信息，看着就舒服 ESP_LOGI(TAG, &quot;Modem Connect to PPP Server&quot;); ESP_LOGI(TAG, &quot;IP : &quot; IPSTR, IP2STR(&amp;event-&gt;ip_info.ip)); ESP_LOGI(TAG, &quot;Netmask : &quot; IPSTR, IP2STR(&amp;event-&gt;ip_info.netmask)); ESP_LOGI(TAG, &quot;Gateway : &quot; IPSTR, IP2STR(&amp;event-&gt;ip_info.gw)); // 通知主任务：我们连上网了！ xEventGroupSetBits(event_group, CONNECT_BIT); } else if (event_id == IP_EVENT_PPP_LOST_IP) { ESP_LOGW(TAG, &quot;Modem Disconnect from PPP Server&quot;); xEventGroupSetBits(event_group, DISCONNECT_BIT); }} 2. 初始化与拨号这一步是重头戏。我们需要初始化 Netif（网络接口），配置 DTE（数据终端设备，即ESP32C3端的UART），然后初始化 DCE（数据通信设备，即4G模块）。 main.c12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455void app_main(void){ // 1. 初始化网络接口和事件循环 ESP_ERROR_CHECK(esp_netif_init()); ESP_ERROR_CHECK(esp_event_loop_create_default()); ESP_ERROR_CHECK(esp_event_handler_register(IP_EVENT, ESP_EVENT_ANY_ID, &amp;on_ip_event, NULL)); event_group = xEventGroupCreate(); // 1.5 重启模块, 我的模块Reset脚接的GPIO7 gpio_config_t io_config = {.pin bit mask = BIT64(7), .mode = GPIO MODE OUTPUT}; gpio_config(&amp;io_config); gpio_set_level(7，0); TaskDelay(pdMS_TO_TICKS(500)); gpio_set_level(7，1); // 2. 配置 PPP 网络接口 esp_modem_dce_config_t dce_config = ESP_MODEM_DCE_DEFAULT_CONFIG(&quot;cmnet&quot;); // APN通常是cmnet esp_netif_config_t netif_ppp_config = ESP_NETIF_DEFAULT_PPP(); esp_netif_t *esp_netif = esp_netif_new(&amp;netif_ppp_config); // 3. 配置串口 (DTE) esp_modem_dte_config_t dte_config = ESP_MODEM_DTE_DEFAULT_CONFIG(); dte_config.uart_config.tx_io_num = 21; // TX引脚 dte_config.uart_config.rx_io_num = 20; // RX引脚 dte_config.uart_config.flow_control = ESP_MODEM_FLOW_CONTROL_NONE; // 没接流控线就选NONE // 4. 创建 Modem 对象 (这里根据实际型号选择, 由于没有Air780eg的配置,所以使用的ESP_MODEM_DCE_CUSTOM) ESP_LOGI(TAG, &quot;Initializing esp_modem...&quot;); esp_modem_dce_t *dce = esp_modem_new_dev(ESP_MODEM_DCE_CUSTOM, &amp;dte_config, &amp;dce_config, esp_netif); // 5. 检查信号质量, 如果没有信号, 很大概率会有问题, 4G模块可能没有正常工作 int rssi, ber; if (esp_modem_get_signal_quality(dce, &amp;rssi, &amp;ber) == ESP_OK) { ESP_LOGI(TAG, &quot;Signal quality: rssi=%d, ber=%d&quot;, rssi, ber); } // 6. 关键步骤：切换到 DATA 模式！ // 这一步之后，串口就变成了透明传输的网卡通道，不能再发AT指令了 ESP_LOGI(TAG, &quot;Switching to Data Mode...&quot;); esp_err_t err = esp_modem_set_mode(dce, ESP_MODEM_MODE_DATA); if (err != ESP_OK) { ESP_LOGE(TAG, &quot;Failed to enter data mode!&quot;); return; } // 7. 等待获取 IP ESP_LOGI(TAG, &quot;Waiting for IP address...&quot;); xEventGroupWaitBits(event_group, CONNECT_BIT, pdFALSE, pdFALSE, portMAX_DELAY); // 到这里，你已经连上网了！ // 可以尝试 Ping 一下 ESP_LOGI(TAG, &quot;Pinging example.com...&quot;); esp_console_run(&quot;ping example.com&quot;, NULL);} 尤其要注意初始化之前进行模块的重启, 官方例子已经没有这部分代码了.所以我们手动补充在初始化之前 如果一切顺利就会看到下图ping成功的输出 踩坑小记在调试过程中遇到过几个坑，顺便记录一下： 供电问题：4G模块瞬时电流很大，普通的3.3V LDO通常扛不住，导致模块会反复重启, 建议单独给模块供电。我用了一个DCDC提供3.9V电压给模块. 流控：如果你的线没接 RTS/CTS，一定要在配置里把 flow_control 设为 ESP_MODEM_FLOW_CONTROL_NONE，否则数据发不出去。 APN：虽然现在很多卡都能自动识别APN，但最好还是显式指定一下（移动通常是 cmnet，联通 3gnet）。 4G模块初始化： RESET脚也得用ESP32 GPIO控制, 用于4G模块初始化重启 总结使用 PPPoS 后，4G 模块的使用体验和 WiFi 几乎没有区别。配合我在《ESP32异步网络请求》中介绍的 AsyncHTTP 或者 MQTT 库，就可以轻松地把设备部署到野外了。 那么，古尔丹，代价是什么呢?答案是功耗爆炸.由于4G模块一直处于数据模式, 如果需要发送一些功耗优化的AT指令, 比如飞行模式, 休眠. 那么会异常麻烦, 每次都需要切换回Command模式再发送指令.如果和我一样是自带的GPS功能的4G模块, 那么功耗更是爆炸, 想要独立控制GPS电源必须通过AT指令, 来回切换失败风险很高. 参考资料 ESP-IDF Modem Component LwIP PPPoS Interface","link":"/esp32-pppos-4g-modem/"},{"title":"在LVGL中实现可变字体(Variable Font)-第三章","text":"在LVGL中实现可变字体(Variable Font)-第一章 在LVGL中实现可变字体(Variable Font)-第二章 在LVGL中实现可变字体(Variable Font)-第三章 前言 (2025年11月 重制版说明):这篇文章的初版我曾发布于第三方平台（简书+Bilibili），并累计获得了50,000+ 次阅读 和大量开发者的反馈。为了提供更好的阅读体验，我对文章排版和部分内容进行了优化，并将其独家发布在此个人博客 第二章中介绍了如何在ESP32上运行LVGL,现在终于可以开始奔着第一章文章末尾的效果去了. 准备工作软件准备访问https://download.savannah.gnu.org/releases/freetype/下载源码,解压后重命名为freetype并复制到项目lib文件夹下我下载的是目前(2021.12.11)最新版本freetype-2.11.1.tar.gz(较老的版本不支持可变字体操作)然后去这个Repo获取SD和SPI库,复制到项目lib文件夹下12345678910111213141516171819.├── include│ └── README├── lib│ └── README│ └── lvgl_freetype│ └── lvgl│ └── freetype│ └── SD│ └── SPI│ └── TFT_eSPI├── platformio.ini├── src│ └── main.cpp│ └── Port│ └── lv_port_disp.cpp│ └── lv_port_disp.h└── test └── README 到freetype文件夹下,创建FreeType的library.json和library.properties文件library.properties内容如下1234567891011name=FreeTypeversion=2.11.1author=David Turner, Robert Wilhelm, Werner Lembergmaintainer=Werner Lembergsentence=A freely available software library to render fonts.paragraph=It is written in C, designed to be small, efficient, highly customizable, and portable while capable of producing high-quality output (glyph images) of most vector and bitmap font formats.documentation.category=Fonturl=https://freetype.org/architectures=*repository=https://gitlab.freedesktop.org/freetype/freetypelicense=GNU library.json内容如下1234567891011121314151617181920212223242526272829303132333435{ &quot;name&quot;:&quot;freetype&quot;, &quot;version&quot;: &quot;2.11.1&quot;, &quot;description&quot;:&quot;Software library to render fonts&quot;, &quot;keywords&quot;:&quot;freetype&quot;, &quot;license&quot;: &quot;FreeType License&quot;, &quot;repository&quot;: { &quot;type&quot;: &quot;git&quot;, &quot;url&quot;: &quot;https://gitlab.freedesktop.org/freetype&quot; }, &quot;frameworks&quot;: &quot;*&quot;, &quot;platforms&quot;: &quot;*&quot;, &quot;build&quot;: { &quot;srcFilter&quot;: [ &quot;+&lt;base/ftsystem.c&gt;&quot;, &quot;+&lt;base/ftmm.c&gt;&quot;, &quot;+&lt;base/ftinit.c&gt;&quot;, &quot;+&lt;base/ftdebug.c&gt;&quot;, &quot;+&lt;base/ftbase.c&gt;&quot;, &quot;+&lt;base/ftbbox.c&gt;&quot;, &quot;+&lt;base/ftglyph.c&gt;&quot;, &quot;+&lt;base/ftbdf.c&gt;&quot;, &quot;+&lt;bdf/bdf.c&gt;&quot;, &quot;+&lt;cff/cff.c&gt;&quot;, &quot;+&lt;truetype/truetype.c&gt;&quot;, &quot;+&lt;sfnt/sfnt.c&gt;&quot;, &quot;+&lt;smooth/smooth.c&gt;&quot;, &quot;+&lt;cache/ftcache.c&gt;&quot;, &quot;+&lt;gzip/ftgzip.c&gt;&quot;, &quot;+&lt;base/ftbitmap.c&gt;&quot; ], &quot;flags&quot;: [ &quot;-DFT2_BUILD_LIBRARY&quot;, &quot;-I include&quot; ], &quot;includeDir&quot;: &quot;devel&quot; }} 硬件准备和上篇相比,多了一个SD卡模块. 起初也尝试了直接把字体文件存在SPIFFS里面,减少涉及到的硬件,奈何速度慢的感人,于是回到这里重新写了SD卡版本. 2022.02.08: 发现LVGL自8.1.1-dev(正式版为8.2.0)开始,内置的lv_freetype模块已经支持FT_New_Memory_Face方式创建字体了.如果没有内存卡的话,请将字体文件命名为Lite.ttf放到源码src文件夹内,在platformio.ini内添加12board_build.embed_txtfiles = src/Lite.ttf并在main.cpp中添加123extern const uint8_t font_start[] asm(&quot;_binary_src_Lite_ttf_start&quot;);extern const uint8_t font_end[] asm(&quot;_binary_src_Lite_ttf_end&quot;);extern const size_t size = font_end - font_end - 1;创建字体时候额外添加如下内容12345static lv_ft_info_t info;/**/info.mem = font_start;info.mem_size = size;/**/有SD卡的情况下 名称 数量 备注 图例 ESP32 开发板 1 \\ 1.54寸LCD 1 驱动ST7789,分辨率240x240 杜邦线若干 N \\ Micro SD卡模块和卡 1 \\ 接线和点亮屏幕请去参考LVGL配合FreeType为可变字体设置字重-ESP32篇(上) Micro SD卡模块的接线如下 ESP32引脚名称 Micro SD卡模块引脚名称 GND GND G26 MISO G13 MOSI G14 SCK G15 CS 5V(Vin) VCC 准备完毕,开干启用LVGL的FreeType将lv_conf.h内的宏定义内容, 并启用FTC_SBitCache_Lookup1234567891011121314151617/*FreeType library*/##define LV_USE_FREETYPE 0##define LV_USE_FREETYPE 1##if LV_USE_FREETYPE /*Memory used by FreeType to cache characters [bytes] (-1: no caching)*/ #define LV_FREETYPE_CACHE_SIZE (16 * 1024) #if LV_FREETYPE_CACHE_SIZE &gt;= 0 /* 1: bitmap cache use the sbit cache, 0:bitmap cache use the image cache. */ /* sbit cache:it is much more memory efficient for small bitmaps(font size &lt; 256) */ /* if font size &gt;= 256, must be configured as image cache */ #define LV_FREETYPE_SBIT_CACHE 1 /* Maximum number of opened FT_Face/FT_Size objects managed by this cache instance. */ /* (0:use system defaults) */ #define LV_FREETYPE_CACHE_FT_FACES 0 #define LV_FREETYPE_CACHE_FT_SIZES 0 #endif##endif0设置为1 配置FreeType的文件系统创建一个命为ft_fs_port.cpp的文件,内容为123456789101112131415161718192021222324252627282930313233343536373839404142434445##include &quot;FS.h&quot;##include &quot;SD.h&quot;##include &quot;SPIFFS.h&quot;extern &quot;C&quot; {typedef void lvbe_FILE;lvbe_FILE *lvbe_fopen(const char *filename, const char *mode) { File f = SD.open(filename, mode); if (f) { File *f_ptr = new File(f); // copy to dynamic object *f_ptr = f; // TODO is this necessary? return f_ptr; } return nullptr;}int lvbe_fclose(lvbe_FILE *stream) { File *f_ptr = (File *)stream; f_ptr-&gt;close(); delete f_ptr; return 0;}size_t lvbe_fread(void *ptr, size_t size, size_t count, lvbe_FILE *stream) { File *f_ptr = (File *)stream; int32_t ret = f_ptr-&gt;read((uint8_t *)ptr, size * count); if (ret &lt; 0) { // error ret = 0; } return ret;}int lvbe_fseek(lvbe_FILE *stream, long int offset, int origin) { File *f_ptr = (File *)stream; fs::SeekMode mode = fs::SeekMode::SeekSet; if (SEEK_CUR == origin) { mode = fs::SeekMode::SeekCur; } else if (SEEK_END == origin) { mode = fs::SeekMode::SeekEnd; } bool ok = f_ptr-&gt;seek(offset, mode); return ok ? 0 : -1;}int lvbe_ftell(lvbe_FILE *stream) { File *f_ptr = (File *)stream; return f_ptr-&gt;position();}} 打开位于freetype文件夹下的devel\\ft2build.h并添加12345678910##ifndef FT2BUILD_H_##define FT2BUILD_H_##define FT_CONFIG_MODULES_H &lt;ftmodule.h&gt;##define FT_CONFIG_OPTIONS_H &lt;ftoption.h&gt;##define FT_CONFIG_STANDARD_LIBRARY_H &lt;ftstdlib.h&gt;##include &lt;freetype/config/ftheader.h&gt;##endif /* FT2BUILD_H_ */在同级目录下创建ftstdlib.h(文末Repo内有完整版)文件,内容从freetype\\include\\freetype\\config\\ftstdlib.h复制 修改file handling部分的内容为1234567891011121314151617181920 /************************************************************************** * * file handling * */##include &lt;stdio.h&gt;typedef void lvbe_FILE;extern lvbe_FILE * lvbe_fopen(const char * filename, const char * mode );extern int lvbe_fclose(lvbe_FILE * stream);extern size_t lvbe_fread(void * ptr, size_t size, size_t count, lvbe_FILE * stream);extern int lvbe_fseek(lvbe_FILE * stream, long int offset, int origin );extern int lvbe_ftell(lvbe_FILE * stream);##define FT_FILE lvbe_FILE##define ft_fclose lvbe_fclose##define ft_fopen lvbe_fopen##define ft_fread lvbe_fread##define ft_fseek lvbe_fseek##define ft_ftell lvbe_ftell##define ft_sprintf sprintf 在同级目录下创建ftmodule.h,启用所需模块内容为123FT_USE_MODULE( FT_Driver_ClassRec, tt_driver_class )FT_USE_MODULE( FT_Module_Class, sfnt_module_class )FT_USE_MODULE( FT_Renderer_Class, ft_smooth_renderer_class ) 在同级目录下创建ftoption.h, 内容从freetype\\include\\freetype\\config\\ftoptions.h复制,详细的配置过长,故此处省略,见文末Repo内 此时FreeType的基本功能配置完成 主要的涉及到freetype\\devel下的4个文件123456│ └── freetype│ └── devel│ └── ft2build.h│ └── ftmodule.h│ └── ftoption.h│ └── ftstdlib.h 测试FreeType移植结果打开main.cpp 随便写点内容,烧录到ESP32上运行查看效果. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081##include &lt;Arduino.h&gt;##include &quot;./Port/lv_port_disp.h&quot;##include &quot;SD.h&quot;##include &quot;SPI.h&quot;// 初始化SD卡bool SD_Init() { pinMode(22, INPUT); SPIClass *sd_spi = new SPIClass(HSPI); // another SPI if (!SD.begin(15, *sd_spi, 12000000, &quot;&quot;)) // SD-Card SS pin is 15 { Serial.println(&quot;Card Mount Failed&quot;); return false; } uint8_t cardType = SD.cardType(); if (cardType == CARD_NONE) { Serial.println(&quot;No SD card attached&quot;); return false; } Serial.print(&quot;SD Card Type: &quot;); if (cardType == CARD_MMC) { Serial.println(&quot;MMC&quot;); } else if (cardType == CARD_SD) { Serial.println(&quot;SDSC&quot;); } else if (cardType == CARD_SDHC) { Serial.println(&quot;SDHC&quot;); } else { Serial.println(&quot;UNKNOWN&quot;); } uint64_t cardSize = SD.cardSize() / (1024 * 1024); Serial.printf(&quot;SD Card Size: %lluMB, used size:%llu\\n&quot;, cardSize, SD.usedBytes()); return true;}void setup() { Serial.begin(115200); // Set to a high rate for fast image transfer to a PC Port_Init(); if (!SD_Init()) { Serial.println(&quot;SPIFFS Mount Failed&quot;); }; /*创建字体*/ static lv_ft_info_t info; /*在SD卡根目录下放置前一节中的可变字体文件,重命名为archivo.ttf*/ info.name = &quot;/archivo.ttf&quot;; info.weight = 18; info.style = FT_FONT_STYLE_NORMAL; if (!lv_ft_font_init(&amp;info)) { LV_LOG_ERROR(&quot;create failed.&quot;); } else { LV_LOG_ERROR(&quot;create done.&quot;); } /*为新字体创建Style*/ static lv_style_t style; lv_style_init(&amp;style); lv_style_set_text_font(&amp;style, info.font); lv_style_set_text_color(&amp;style, lv_color_black()); /*应用Style到Label*/ lv_obj_t *altria = lv_label_create(lv_scr_act()); lv_obj_t *shirou = lv_label_create(lv_scr_act()); // lv_obj_add_style(altria, &amp;style, 0); lv_label_set_text(altria, &quot;Toou.\\nAnata wa watashi no masuta ka?&quot;); lv_label_set_text(shirou, &quot;Master?&quot;); lv_obj_set_style_text_font(shirou, info.font, 0); lv_obj_center(shirou); // 一切就绪, 启动LVGL任务 xTaskNotifyGive(handleTaskLvgl);}void loop() {} 运行效果如下 拓展LVGL的FreeType就像前篇内容中的一样,需要手动地为当前版本LVGL添加可变字体支持. lv_freetype.h内的lv_ft_info_t修改为123456789typedef struct { const char * name; /* The name of the font file */ const void * mem; /* The pointer of the font file */ size_t mem_size; /* The size of the memory */ lv_font_t * font; /* point to lvgl font */ uint16_t height; /* font size */ uint16_t weight; /* font weight */ uint16_t style; /* font style */} lv_ft_info_t; 然后去lv_freetype.c里添加可变字体操作代码12345678910111213141516FT_MM_Var *amaster = NULL;FT_Error err = FT_Get_MM_Var(face, &amp;amaster);if (err) { LV_LOG_ERROR(&quot;FT_Get_MM_Var error:%d\\n&quot;, err); return err;}FT_Fixed w = dsc-&gt;weight &lt;&lt; 16;if (w &gt; amaster-&gt;axis-&gt;maximum) { w = amaster-&gt;axis-&gt;maximum;}err = FT_Set_Var_Design_Coordinates(face, 1, &amp;w);if (err) { LV_LOG_ERROR(&quot;FT_Set_Var_Design_Coordinates error:%d\\n&quot;, err); return err;}FT_Done_MM_Var(library, amaster); 别忘记我们已经修改了weight的含义,此时字体大小已经由height决定了 回到main.cpp,在创建字体初时候,设置weight为100 12345static lv_ft_info_t info;info.name = &quot;/archivo.ttf&quot;;info.height = 18;info.weight = 100;info.style = FT_FONT_STYLE_NORMAL; 然后烧录到ESP32,可以看到字重已经降低了. 动起来吧,字重利用LVGL的lv_timer_t或者lv_anim_t动态的修改字重 1234567891011121314151617181920212223242526272829303132typedef struct _VF_Label { lv_obj_t *label; lv_ft_info_t *font;} VF_Label;static void onTimer(lv_timer_t *timer) { static uint16_t weight = 100; static uint16_t size = 18; VF_Label *vfl = (VF_Label *)(timer-&gt;user_data); if (vfl == nullptr) { printf(&quot;vfl == nullptr\\n&quot;); } if (vfl == nullptr) { printf(&quot;vfl-&gt;font-&gt;font == nullptr\\n&quot;); } lv_ft_font_destroy(vfl-&gt;font-&gt;font); printf(&quot;lv_ft_font_destroy\\n&quot;); vfl-&gt;font-&gt;name = &quot;/archivo.ttf&quot;; vfl-&gt;font-&gt;height = size; vfl-&gt;font-&gt;weight = weight; vfl-&gt;font-&gt;style = FT_FONT_STYLE_NORMAL; lv_ft_font_init(vfl-&gt;font); printf(&quot;lv_ft_font_init\\n&quot;); size = 48; weight += 100; if (weight &gt; 600) { weight = 100; } lv_obj_set_style_text_font(vfl-&gt;label, vfl-&gt;font-&gt;font, 0);} 123lv_timer_t *weightTimer = lv_timer_create(onTimer, 50, &amp;label);// 一切就绪, 启动LVGL任务xTaskNotifyGive(handleTaskLvgl); 效果图 环境:1234567Espressif 32 (3.4.0) &gt; ESP32 Pico Kitframework-arduinoespressif32 3.10006.210326 (1.0.6)tool-esptoolpy 1.30100.210531 (3.1.0)toolchain-xtensa32 2.50200.97 (5.2.0)&lt;lvgl&gt; 8.1.1-dev&lt;TFT_eSPI&gt; 2.3.89esptool.py v3.1 参考资料 https://github.com/lvgl/lvgl https://github.com/peng-zhihui/Peak https://www.youtube.com/watch?v=LY3ypzPcDCE Repo vf_font_on_esp32","link":"/lvgl-freetype-and-esp32-2/"},{"title":"为 AdSense 铺路：我如何修复 &#39;GSC 重复网页&#39; 与 Canonical 致命错误(Hexo, 301, robots 详解)","text":"背景之前 MCompass 项目的博文引来不少流量，Cloudflare 后台的数据看得我挺惊喜。原本想过把这个小装置做成产品，但版权和量产成本确实是个砍。于是我开始想，能不能通过 AdSense 这种成熟的平台，让这些流量转化成一点维护网站的服务器成本。 结果没想到，Google 在接连几次申请中都给我发了“需要采取行动”的回执。信里说申请需要调整，但具体的“痛苦面”在哪又没说清楚。 我意识到，单纯堆内容是不够的，站点的“技术卫生习惯”——也就是 SEO 和抓取合规性，可能已经烂透了。于是，我决定给博客做一次彻底的底层清理。 诊断：先看 Google 眼中的我第一步，我必须搞清楚“谷歌眼中的我”是什么样, 搜索引擎有个专门指定搜索内容的命令叫做site, 用法就是在搜索内容前面添加site: xxx.com, 这样搜索到的结果就只会来自我们指定的站点. site:命令的“恐怖”现状检索网站收录情况, 第一页内容中不仅没有根域名,还错误的收录了blog域名下的无关紧要的内容.比如这个莫名其妙的”快来抢沙发吧!”的links地址, 再靠后则是compass域名的相关页面. 行动一：内容上的“断舍离”删掉那些凑数的文章翻了下旧档，发现几年前学 Kotlin 时写的笔记写得惨不忍睹。基本就是对着官方文档复读了一遍，再加上一堆没意义的自言自语。这些东西存电脑里自己看还行，放网上确实是在浪费爬虫的精力。 还有一些早期的 Blender 练习展示，只有几张图，没有技术细节。AdSense 想要的是具有原创深度的内容，这种“搬运感”很重的薄内容 (Thin Content) 必须清理掉。 虽说有点舍不得，但我还是“壮士断腕”，把文章从 58 篇砍到了 22 篇。 清理低价值文章几年前, 我曾有过一段学习Kotlin的时光, 当时为了加深印象, 编写过一些学习Kotlin的笔记, 但是笔记基本上就是把官方文档的内容手动敲打了一遍.而且还有很多自言自语, 这种文章对于其他人的帮助其实是微乎其微的, 适合存放到一些专门的笔记工具(如notion)中去, 所以是首要清理对象. 此外,在19~20年的一些日子, 我还使用Blender进行了创作.内容只是简单的分享创作结果, 没有深入制作技巧, 细节. 这种类型的文章也很有可能被判定为低价值文章,也要被纳入清理对象中. AdSense 极其看重‘原创价值’。像这种单纯‘搬运文档’或‘自言自语’的内容，极易被判定为‘内容单薄’ (Thin Content)。为了不拖累整个网站的评分，我必须壮士断腕。 在仔细排查一番后, 从最开始的58篇文章, 减少到了22篇文章. 修复链接错误在保留下来的这22篇文章里面, 由于博客多次迁移, 导致的里面的图片和视频链接失效了.这个是不能容忍的, 因为爬虫会检测到, 所以能修复死链的一定要修复.我的这个修复起来比较简单, 因为只是少了?raw=true, 补充即可. 文章内容优化22篇文章中有些是属于原创性高, 但是内容略微简略, 我们可以对齐进行优化和扩充. 使其具有真实价值.比如我的那篇CS2胸章文章中详细介绍了元件选型策略, Aurora新增Script Device方法. 行动二：解决那四个技术症结1. 域名打架（301 重定向）我的站域名变迁史有点乱。最开始在 blog.chaosgoo.com，后来又试过 www。申请 AdSense 时必须提交 root 域名（chaosgoo.com），导致现在搜索结果里充斥着一堆过期的二级域名，权重全分散了。我的站点过去较长一段时间里部署在blog.上, root域名(chaosgoo.com)处于闲置状态.在申请AdSense时候,要求填入的是root域名, 而非blog.域名, 所以几个月前,还专门迁移到了root域名.再往前一段时间,网站也曾部署到www上, 所以site:命令检索到的结果能看到blog. 和 www. 两个“废弃”域名在“污染”索引。为了提高root域名权重, 还有搜索结果的整洁清晰, 这两个旧域名要进行大清理一番. 旧域名处理页面规则感谢赛博大善人Cloudflare 提供了很多方便的工具.这里我们来到cloudflare的控制台,找到页面规则, 为www.和blog.两个旧域名添加重定向规则.参数如下图所示: Cloudflare 解析优化配置好页面规则以后, 并不是万事大吉了, 还需要在解析添加两条虚拟的A记录特别注意： 这条 A 记录的代理状态必须开启（点亮橙色云朵），否则 Cloudflare 的页面规则无法接管流量。重要:否则页面规则不会生效. #2：索引污染（Robots 防火墙）是否还记得前面使用site:命令看到的tags页面相关的无关内容接下来我们要将其从搜索结果里面移除. robots.txt内容优化我们要主动告诉爬虫机器人, 这些页面是不需要的,请不要爬取这些内容.编写如下robots.txt规则 #3：地图混乱（Sitemap 白名单）虽然我们已经手动编写了robots.txt规则告诉谷歌不要再抓取指定的内容了, 但是在站点地图中依旧存在这些内容.为了保证内容规范统一, 就需要对不想要的内容标记,让他不要出现在sitemap中. hexo-generator-sitemap插件安装我的博客使用的是hexo生成, 所以使用hexo专用的sitemap生成工具, hexo-generator-sitemap安装很简单,只需要在博客源文件根目录输入1npm install hexo-generator-sitemap --save hexo-generator-sitemap使用使用起来也很简单, 只需要在根目录的_config.yml配置规则即可. 这个插件会在hexo g的时候自动生成一份对于的站点地图. #4：修复Canonical (致命错误)你是否还记得前面GSC 的“最终审判”一节提到的网页未纳入联系：重复网页，用户未选择规范网页 这是因为我们的网站页面缺少canonical标记, 谷歌不知道blog.和root版本哪一个才是规范网页, 然后根据经验选择了早就收录的blog.版本作为规范出现在搜索结果中. 排查因为一般而言,hexo的主题会为我们自动生成canonical标记才对.所以我打开站点主页, 按F12审查元素发现主页确实没有canonical标记, 但是随便点开几篇文章却又看到了canonical标记, 这就很诡异了.我以为是‘僵尸缓存’（db.json），清理之后重新生成页面检查, 还是没有canonical标记.难道是 _config.yml 里的 url 没配置, 也不对, 因为我早就配置了这个属性.于是决定搜索源码检查这个东西的生成规则. 手动标记canonical在我的主题生成canonical标记的代码逻辑是,主页没有page这个概念, 这里的三元运算符算出null, 所以需要手动修改此处逻辑为12345// 修改前 (Bug): 主页的 page.permalink 为空，导致 canonical 为空{canonical_url ? &lt;link rel=&quot;canonical&quot; href={canonical_url} /&gt; : null}// 修改后 (Fix): 强制回退使用 url 配置{&lt;link rel=&quot;canonical&quot; href={page.permalink || url} /&gt;}保存后重新生成页面本地部署, 使用F12审查元素成功看到了主页也有了canonical标记, 终于大功告成了. 重新部署站点现在我们修复了博客的robots.txt和sitemap.xml以及canonical标记, 可以重新部署了. 行动三：推 Google 一把，更新“记忆”光改完代码还没完，我得主动告诉 GSC 把旧的、乱的索引删掉。为了加快修复, 我们可以在Google Search Console上主动告诉谷歌sitemap在哪, 以及rotots.txt规则可以重新抓取了 申请重新抓取robots.txt 主动提交sitemap.xml文件 提交隐藏搜索结果申请还可以使用移除功能, 将不需要的网页移除.这里我希望把tags, links之类的内容移除, 所以创建了如下的请求 总结在做了上述操作后, 剩下的就是耐心等待谷歌的机器人抓取网页, 大概过了2天.我审查网页的时候看到root域名已经被正确收录了并且site:命令内容也变得干净许多, 基本上只剩下少部分blog.的连接了. 这次排查让我明白，SEO 不是玄学，而是对细节的极致把控。虽然 AdSense 申请还在路上，但看着 GSC 里那条昂扬向上的收录曲线，我知道，我已经准备好了。","link":"/hexo-seo-gsc-canonical-301/"},{"title":"ESP32 进阶开发杂谈：从异步请求、动图显示到资源OTA","text":"前言 很多时候，我们从零开始构建一个ESP32项目，往往会掉进各种各样的“坑”里。 在之前的一些项目中(比如做个桌面像素小屏幕吧)，我遇到过各种各样的问题：网络请求卡死主线程、屏幕显示太单调、休眠时PWM停转、以及每次只更新几张图片却要重刷整个固件的痛苦。 把这些坑踩平之后，我整理了四个在ESP32开发中非常实用的技巧。为了避免大家重蹈覆辙，也为了方便我自己日后查阅（Copy），这篇文章将把这些技术点汇总起来。 希望能给正在折腾ESP32的你提供一些灵感。 技巧一：拒绝阻塞！使用异步网络请求痛点分析在早期的像素小屏幕项目中，我为了获取B站粉丝数，直接使用了同步的HTTP Client。结果就是每次请求网络时，整个设备的UI都会卡住几百毫秒甚至几秒。这对于用户体验来说简直是灾难——你不能让用户觉得设备“死机”了。 为了优雅，必须上异步。 解决方案我们可以利用 AsyncTCP 库来实现非阻塞的HTTP请求。虽然写起来回调函数（Callback）套娃有点多，但换来的是丝般顺滑的主循环。 核心代码这里使用的是 AsyncTCP-esphome 库。 AsyncRequest.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;Arduino.h&gt;#include &lt;AsyncTCP.h&gt;#include &lt;WiFi.h&gt;// ... WiFi配置省略 ...void asyncReqeust() { static AsyncClient *aClient; if (aClient) return; // 防止重复创建 aClient = new AsyncClient(); if (!aClient) return; // 注册错误回调 aClient-&gt;onError([](void *arg, AsyncClient *client, int error) { Serial.println(&quot;Connect Error&quot;); aClient = NULL; delete client; }, NULL); // 注册连接回调 aClient-&gt;onConnect([](void *arg, AsyncClient *client) { Serial.println(&quot;Connected&quot;); aClient-&gt;onError(NULL, NULL); // 注册断开连接回调 client-&gt;onDisconnect([](void *arg, AsyncClient *c) { aClient = NULL; delete c; Serial.println(&quot;Disconnected&quot;); }, NULL); // 注册数据接收回调（核心逻辑） client-&gt;onData([](void *arg, AsyncClient *c, void *data, size_t len) { Serial.write((uint8_t *)data, len); // 这里可以解析JSON数据 }, NULL); // 发送HTTP GET请求 client-&gt;write(&quot;GET /x/relation/stat?vmid=14374079 HTTP/1.1\\r\\n&quot; &quot;Host: api.bilibili.com\\r\\n&quot; &quot;Content-Type: application/json; charset=utf-8\\r\\n\\r\\n&quot;); }, NULL); if (!aClient-&gt;connect(&quot;api.bilibili.com&quot;, 80)) { Serial.println(&quot;Connect Fail&quot;); AsyncClient *client = aClient; aClient = NULL; delete client; }} 这样，网络请求在后台默默进行，你的主循环 loop() 依然可以跑得飞起，去处理按键扫描或者屏幕刷新。 技巧二：让画面动起来——播放GIF动图视觉升级网络通畅了，界面也不能太寒酸。在做一个带有240x135分辨率的装置时，我实在想不出什么高级的算法动画，于是决定“偷懒”：直接在屏幕上播放GIF表情包。 这里推荐使用 AnimatedGIF 库，配合 TFT_eSPI 驱动，效果非常不错。 制作GIF头文件首先，我们需要把GIF文件转换成代码能读取的数组。在Linux或者WSL子系统下，一行 xxd 命令就能搞定： 12## 将GIF转换为C数组xxd -i angry_80px.gif &gt;&gt; loading.h 生成的 loading.h 里面就是一个巨大的 unsigned char 数组。 驱动代码代码基于官方示例修改，适配了 TFT_eSPI。 GifPlayer.cpp1234567891011121314151617181920212223242526272829##include &lt;AnimatedGIF.h&gt;##include &lt;TFT_eSPI.h&gt;##include &quot;loading.h&quot; // 刚才生成的头文件AnimatedGIF gif;TFT_eSPI tft = TFT_eSPI();// 回调函数：将解码后的一行像素推送到屏幕void GIFDraw(GIFDRAW *pDraw) { // ... 核心绘制逻辑，包含透明度处理和DMA加速 ... // 篇幅原因，核心逻辑是调用 tft.pushPixels 将 pDraw-&gt;pPixels 推送显示 // 完整逻辑参考 AnimatedGIF 的 TFT_eSPI_memory 示例}void setup() { tft.begin(); tft.setRotation(1); tft.fillScreen(TFT_BLACK); gif.begin(BIG_ENDIAN_PIXELS);}void loop() { if (gif.open((uint8_t *)angry_80px_gif, sizeof(angry_80px_gif), GIFDraw)) { while (gif.playFrame(true, NULL)) { yield(); // 喂狗，防止复位 } gif.close(); }} 只要内存够大，放个蔡徐坤打篮球的GIF也不是不可能（逃）。 技巧三：Light-Sleep模式下保持PWM输出奇怪的需求有些场景下（比如背光保持），我们需要ESP32进入 Light-Sleep 省电，但又不希望 屏幕背光的PWM 信号中断。默认情况下，进入睡眠后高速时钟会关闭，导致 PWM 停摆。 开启 RTC8M 时钟查阅 ESP-IDF 手册发现，如果将 PWM 的时钟源配置为 RTC8M_CLK，即使在 Light-Sleep 下也能工作。但这有个前提，需要修改 menuconfig。 环境配置： 1idf.py menuconfig 进入 Component config -&gt; Hardware Settings -&gt; Sleep Config。务必关闭 light sleep GPIO reset workaround。 代码实现：使用 ESP-IDF 原生 API 配置 LEDC。 pwm_sleep.c1234567891011121314151617181920212223242526272829#include &quot;driver/ledc.h&quot;#include &quot;esp_sleep.h&quot;void app_main(void) { // 1. 定时器配置：重点是选用 LEDC_USE_RTC8M_CLK ledc_timer_config_t ledc_timer = { .duty_resolution = LEDC_TIMER_13_BIT, .freq_hz = 1000, .speed_mode = LEDC_LOW_SPEED_MODE, // 必须是低速模式 .timer_num = LEDC_TIMER_0, .clk_cfg = LEDC_USE_RTC8M_CLK, // 关键！ }; ESP_ERROR_CHECK(ledc_timer_config(&amp;ledc_timer)); // 2. 通道配置... (常规配置，略) // 3. 强制开启RTC8M电源域 esp_sleep_pd_config(ESP_PD_DOMAIN_RTC8M, ESP_PD_OPTION_ON); while (1) { // 设置一个占空比 ledc_set_duty(LEDC_LOW_SPEED_MODE, LEDC_CHANNEL_0, 1000); ledc_update_duty(LEDC_LOW_SPEED_MODE, LEDC_CHANNEL_0); // 进入浅睡眠，PWM依然会保持输出 esp_sleep_enable_timer_wakeup(1000 * 1000 * 5); // 睡5秒 esp_light_sleep_start(); }} 实测这个功能对于降低功耗非常有用。 技巧四：只更新资源文件？试试 SPIFFS 分区 OTA场景随着项目越来越大，我发现一个问题：有时候我只想更新一下UI里的图片资源或者字体库，并不想更新代码。传统的OTA是更新 App 分区，这很浪费流量和时间。其实我们完全可以只针对 SPIFFS 数据分区进行 OTA。 分区表设计首先，我们需要自定义分区表（partitions.csv），把数据独立出来。 12345## Name, Type, SubType, Offset, Size, Flagsnvs, data, nvs, 0x9000, 0x5000,otadata, data, ota, 0xe000, 0x2000,app0, app, ota_0, 0x10000, 0x300000,storage, data, spiffs, 0x310000, 0xC000, 这里我划了一个 48KB 的 storage 分区用于演示。 OTA 核心逻辑不同于更新 App，更新分区实际上就是“擦除 + 写入”的过程。假设新的文件镜像已经通过网络下载到了内存中（或者像本例一样，为了演示直接 embed 在代码里）。 spiffs_ota.c123456789101112131415161718192021222324void update_spiffs_partition() { // 1. 查找 SPIFFS 分区 const esp_partition_t *spiffs_part = esp_partition_find_first( ESP_PARTITION_TYPE_DATA, ESP_PARTITION_SUBTYPE_DATA_SPIFFS, NULL); if (spiffs_part == NULL) { ESP_LOGE(&quot;OTA&quot;, &quot;SPIFFS partition not found!&quot;); return; } // 2. 擦除原分区内容 ESP_LOGI(&quot;OTA&quot;, &quot;Erasing partition...&quot;); esp_partition_erase_range(spiffs_part, 0, spiffs_part-&gt;size); // 3. 写入新数据 // 假设 spiffs2_start 和 spiffs2_end 是新镜像在内存中的地址 size_t image_size = spiffs2_end - spiffs2_start - 1; ESP_LOGI(&quot;OTA&quot;, &quot;Writing new data: %d bytes&quot;, image_size); esp_partition_write(spiffs_part, 0, spiffs2_start, image_size); ESP_LOGI(&quot;OTA&quot;, &quot;Done! Restarting...&quot;); esp_restart();} 这个技巧在做图片更换、字体切换等功能时特别好用，不用动核心代码，安全又快速。 总结以上就是我近期折腾ESP32时总结的四个实用技巧。从避免阻塞的异步请求，到花里胡哨的GIF播放，再到低功耗下的PWM控制和灵活的资源OTA，每一个点都是在实际开发中为了解决特定痛点而摸索出来的。 硬件开发的乐趣大概就在于此：遇到一个坑，填平它，然后看着设备按照预想的方式运行，那种成就感是无法替代的。 希望这些笔记对你有所帮助，我们下个项目见！","link":"/esp32-advanced-dev-tips/"},{"title":"在LVGL中实现可变字体(Variable Font)-第二章","text":"在LVGL中实现可变字体(Variable Font)-第一章 在LVGL中实现可变字体(Variable Font)-第二章 在LVGL中实现可变字体(Variable Font)-第三章 前言 (2025年11月 重制版说明):这篇文章的初版我曾发布于第三方平台（简书+Bilibili），并累计获得了50,000+ 次阅读 和大量开发者的反馈。为了提供更好的阅读体验，我对文章排版和部分内容进行了优化，并将其独家发布在此个人博客 我们在第一章中已经实现了模拟器环境下可变字体字重的设置. 是时候掏出你吃灰已久的ESP32了. 本文会使用PlatformIO创建一个全新的项目,直到显示出现上篇文章末尾的动图为止.如遇到问题,可参考常见问题内解答. 准备工作软件准备为了后续内容顺利进行下去,这里需要你安装好VSCode,并在VSCode上安装PlatformIO插件. 硬件准备 名称 数量 备注 图例 ESP32 开发板 1 \\ 1.54寸LCD 1 驱动ST7789,分辨率240x240 杜邦线若干 N \\ 创建项目使用PlatformIO创建一个名为lvgl_with_freetype的项目创建完毕后目录结构如下:12345678910.├── include│ └── README├── lib│ └── README├── platformio.ini├── src│ └── main.cpp└── test └── README 点亮屏幕网上充斥着大量点屏教程, 故本文不做过多赘述. 本次驱动依旧使用TFT_eSPI库, 且本次的屏幕分辨率是240x240, Driver IC是ST7789. 所以需要使用TFT_eSPI里面的Setup24_ST7789.h 同时接线变更为 ESP32引脚名称 液晶屏引脚名称 VCC VCC GND GND G23 SDA G18 SCL G2 DC G4 RES GND CS VCC BLK 对应Setup24_ST7789.h里面内容 Setup24_ST7789.h123456##define TFT_MISO 19##define TFT_MOSI 23##define TFT_SCLK 18##define TFT_CS -1##define TFT_DC 2##define TFT_RST 4 随便写点内容.测试下屏幕的点亮.main.cpp1234567891011121314151617##include &lt;Arduino.h&gt;##include &lt;TFT_eSPI.h&gt; // Hardware-specific library##include &lt;SPI.h&gt;TFT_eSPI tft = TFT_eSPI(); // Invoke custom libraryvoid setup() { Serial.begin(115200); // Set to a high rate for fast image transfer to a PC tft.init(); tft.setRotation(0); tft.fillScreen(TFT_BLACK);}void loop() { tft.print(&quot;Ready Perfectly&quot;);} 移植LVGL屏幕点亮以后,就可以开始移植LVGL了. 当前时间为2021.12.19,GitHub上LVGL最新版本是8.1.1-dev 使用命令1git clone https://github.com/lvgl/lvgl.git获取LVGL后将其复制到lib文件夹下.此时文件目录为123456789101112.├── include│ └── README├── lib│ └── README│ └── lvgl│ └── TFT_eSPI├── platformio.ini├── src│ └── main.cpp└── test └── READMEplatformio.ini文件内容12345678[env:pico32]platform = espressif32board = pico32framework = arduinomonitor_speed = 115200lib_extra_dirs = lib/TFT_eSPI lib/lvgl 修改LVGL配置文件创建LVGL的配置文件,找到lvgl文件夹内的lv_conf_templat.h,复制一份lv_conf_templat.h并重命名为lv_conf.h,然后打开lv_conf.h 为了使配置文件内容生效,找到第15行(其他版本的lvgl行数可能不在这里,需要自行寻找)1##if 0 /*Set it to &quot;1&quot; to enable content*/改为1##if 1 /*Set it to &quot;1&quot; to enable content*/ 找到第30行,修改颜色顺序1##define LV_COLOR_16_SWAP 0改为1##define LV_COLOR_16_SWAP 1 找到第49行,启用自定义内存管理1##define LV_MEM_CUSTOM 0修改为1##define LV_MEM_CUSTOM 1 找到第88行,设置自定义周期函数1##define LV_TICK_CUSTOM 0修改为1##define LV_TICK_CUSTOM 1 找到第174行,启用LVGL日志功能1##define LV_USE_LOG 1修改为1##define LV_USE_LOG 1 对接LVGL和TFT_eSPI按照目录123456789101112131415.├── include│ └── README├── lib│ └── README│ └── lvgl│ └── TFT_eSPI├── platformio.ini├── src│ └── main.cpp│ └── Port│ └── lv_port_disp.cpp│ └── lv_port_disp.h└── test └── README创建lv_port_disp.cpp和lv_port_disp.h lv_port_disp.h123456789101112131415##ifndef LV_PORT_DISP_H_##define LV_PORT_DISP_H_##include &quot;TFT_eSPI.h&quot;##include &quot;lvgl.h&quot;##define DISP_HOR_RES 240##define DISP_VER_RES 240##define DISP_BUF_SIZE (DISP_HOR_RES*DISP_VER_RES/4)extern TaskHandle_t handleTaskLvgl;void Port_Init();void lv_port_disp_init(TFT_eSPI* scr);##endif lv_port_disp.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899##include &quot;lv_port_disp.h&quot;// 用于初始化完毕后启用LVGL显示的TaskHandle_tTaskHandle_t handleTaskLvgl;// lvgl显示驱动static lv_disp_drv_t disp_drv;// lvgl更新任务void TaskLvglUpdate(void* parameter) { // 阻塞在此处,直到xTaskNotifyGive ulTaskNotifyTake(pdTRUE, portMAX_DELAY); for (;;) { lv_task_handler(); delay(5); }}/** * @brief 显示初始化 * @param 无 * @retval 无 */void Port_Init() { static TFT_eSPI screen; /* 屏幕初始化 */ screen.begin(); screen.initDMA(true); screen.setRotation(0); screen.fillScreen(TFT_BLACK); /* lvgl初始化 */ lv_init(); lv_port_disp_init(&amp;screen); printf(&quot;lvInitDone\\n&quot;); // 在核心2上执行LVGL xTaskCreatePinnedToCore(TaskLvglUpdate, &quot;LvglThread&quot;, 20480, nullptr, configMAX_PRIORITIES, &amp;handleTaskLvgl, 1);}/** * @brief 自定义打印函数 * @param 无 * @retval 无 */void my_print(lv_log_level_t level, const char *file, uint32_t line, const char *fun, const char *dsc) { Serial.printf(&quot;%s@%d %s-&gt;%s\\r\\n&quot;, file, line, fun, dsc); Serial.flush();}/** * @brief 屏幕刷新回调函数 * @param disp:屏幕驱动地址 * @param area:刷新区域 * @param color_p:刷新缓冲区地址 * @retval 无 */static void disp_flush_cb(lv_disp_drv_t *disp, const lv_area_t *area, lv_color_t *color_p) { TFT_eSPI *screen = (TFT_eSPI *)disp-&gt;user_data; int32_t w = (area-&gt;x2 - area-&gt;x1 + 1); int32_t h = (area-&gt;y2 - area-&gt;y1 + 1); screen-&gt;startWrite(); screen-&gt;setAddrWindow(area-&gt;x1, area-&gt;y1, w, h); screen-&gt;pushPixelsDMA((uint16_t *)(&amp;color_p-&gt;full), w * h); screen-&gt;endWrite(); lv_disp_flush_ready(disp);}/** * @brief 屏幕初始化 * @param 无 * @retval 无 */void lv_port_disp_init(TFT_eSPI* scr) { lv_log_register_print_cb(reinterpret_cast&lt;lv_log_print_g_cb_t&gt;( my_print)); /* register print function for debugging */ DMA_ATTR static lv_color_t *lv_disp_buf = static_cast&lt;lv_color_t *&gt;(heap_caps_malloc( DISP_BUF_SIZE * sizeof(lv_color_t), MALLOC_CAP_DMA)); static lv_disp_draw_buf_t disp_buf; lv_disp_draw_buf_init(&amp;disp_buf, lv_disp_buf, nullptr, DISP_BUF_SIZE); /*Initialize the display*/ lv_disp_drv_init(&amp;disp_drv); disp_drv.hor_res = DISP_HOR_RES; disp_drv.ver_res = DISP_VER_RES; disp_drv.flush_cb = disp_flush_cb; disp_drv.draw_buf = &amp;disp_buf; disp_drv.user_data = scr; lv_disp_drv_register(&amp;disp_drv);} 再写个简单例子测试下LVGL能不能运行main.cpp123456789101112131415161718##include &lt;Arduino.h&gt;##include &quot;./Port/lv_port_disp.h&quot;void setup() { Serial.begin(115200); // Set to a high rate for fast image transfer to a PC Port_Init(); lv_obj_t *label = lv_label_create(lv_scr_act()); lv_label_set_text(label, &quot;Toou.\\nAnata wa watashi no masuta ka?&quot;); // 一切就绪, 启动LVGL任务 xTaskNotifyGive(handleTaskLvgl);}void loop() {} Toou.Anata wa watashi no masuta ka? 施工中,待更新常见问题Q:点亮屏幕时候,编译器报找不到TFT_eSPI A:检查TFT_eSPI是否集成将TFT_eSPI放置在lib文件夹内,并向platformio.ini文件末尾添加1lib_extra_dirs = lib/TFT_eSPI Q:在移植LVGL时候,屏幕颜色异常 A:可能与lv_conf.h文件内#define LV_COLOR_16_SWAP 0有关可以尝试将此处的0改成1,或1改回0 环境:1234567Espressif 32 (3.4.0) &gt; ESP32 Pico Kitframework-arduinoespressif32 3.10006.210326 (1.0.6)tool-esptoolpy 1.30100.210531 (3.1.0)toolchain-xtensa32 2.50200.97 (5.2.0)&lt;lvgl&gt; 8.1.1-dev&lt;TFT_eSPI&gt; 2.3.89esptool.py v3.1 参考资料 https://github.com/lvgl/lvgl https://github.com/peng-zhihui/Peak","link":"/lvgl-freetype-and-esp32/"},{"title":"在 M5Stack Cardputer 上实现远程桌面串流（基于 H.264）","text":"This article is also available in the following language: English. 背景几年前，我曾试过在 ESP32 上实现串流操作。当时硬件搭建在面包板上，一快 1.14 寸的屏幕分辨率为 240x135，主控是初代 ESP32。文章较为详细地描述了实现细节。 时隔五年，我决定重新制作一次，将硬件环境迁移到 M5Stack 家的 Cardputer。 额外说明我的这块 Cardputer 被我手动升级过一次。原版主控使用的是 ESP32-S3FN8（内置 8MB Flash，无 PSRAM），我将其更换成了 ESP32-S3FH4R2。牺牲了 4MB Flash，换来了 2MB 的 PSRAM。 上图是更换芯片后的特写。为了保护周围精细的贴片元件，我动用了铝箔胶带进行隔热。可以看到焊点周围还有一些未清理干净的助焊剂残留，虽然卖相一般，但它确实赋予了这台小机器“新生”。 为什么 PSRAM 是必须的：无 PSRAM 的“软压榨”实验在决定更换芯片之前，我曾深度尝试过在 无 PSRAM 的原版 Cardputer 上跑通 H.264 解码，但这几乎是一次“不可能完成的任务”。 H.264 软件解码器对内存有刚性需求。即便在 240x136 这种极低分辨率下，DPB (Decoded Picture Buffer) 机制加上 SPS 序列参数集的激活，依然需要大量连续的、无碎片的内存块。而 ESP32-S3 的内部 RAM (SRAM) 在运行了 WiFi 协议栈、TCP/IP、WebSocket 服务之后，留给应用的连续空闲空间所剩无几。 为了省下内存，我曾尝试了以下极致操作： 移除 LVGL UI 系统：切换到纯裸机显示控制，收回了约 50KB 内存。 压榨核心组件：将 WiFi 的动态发送缓冲区从 32 压减至 4，静态接收缓冲区压至 3，收回约 45KB。 废弃双缓冲：采用“解码一帧 -&gt; 实时转换 -&gt; 立即推屏”的同步模型，试图消灭显示冗余。 然而，即便通过这些手段腾出了超过 100KB 的额外空间，esp-h264 库在初始化时依然会因为无法申请到足够的连续工作内存而报错。结论： 对于 H.264 这种对参考帧有依赖的编码格式，PSRAM 是 ESP32-S3 设备的“续命药”。如果你也想玩实时视频流，手动焊接一颗带 PSRAM 的芯片是最高效的解决方案。 架构设计由于有了额外的 PSRAM，我甚至可以直接在装置上进行 H.264 流的解码。乐鑫官方提供了一个名为 esp_h264 的组件，能够在 ESP32-S3 上执行软件解码。据实际测试，2MB 的 PSRAM 刚好足以支撑 240x136 分辨率的解码工作（画面原本是 240x135，但 H.264 编码器要求分辨率必须是偶数）。 系统链路为了保证极低的延迟，我重新设计了整个通信架构： 发送端 (Browser): 利用浏览器的 getDisplayMedia 捕获桌面，调用 WebCodecs 进行硬编码，输出 H.264 Annex B 格式流（设置为 GOP=1，即全 I 帧模式），最后通过 WebSocket 发送二进制数据。 接收与缓冲 (ESP32-S3): Cardputer 作为 WebSocket Server 接收数据，并存入 RingBuffer (环形缓冲区) 进行平滑。 解码核心 (Decode Pipeline): 专门的解码任务从 RingBuffer 取出原始字节流，通过 esp_h264 解码出 YUV420P 格式的图像。 颜色转换与显示: 解码后的图像实时转换为 RGB565 格式，随后通过 SPI DMA 直接写入 ST7789 屏幕。 核心挑战与解决方案1. 多核调度与 WDT (看门狗) 报错在最初的版本中，解码、颜色转换、屏幕刷新和 LVGL UI 更新都在同一个核心上运行，导致 CPU 占用率瞬间爆表，频繁触发 Task Watchdog 系统复位。解决方案： 核心绑定：将 Core 0 分配给 WiFi 协议栈、WebSocket 服务和 LVGL UI 任务。 解码专核：将核心 1 (Core 1) 设置为高优先级任务，全力负责 H.264 解码、YUV 转 RGB 以及 LCD 位图刷新。这种分工策略确保了即便在解码任务高负荷运行时，系统各组件依然能正常“喂狗”，保证了稳定性。 2. 内存管理esp_h264 软件解码器需要大量的连续内存块。即便开启了 GOP=1，解码器依然会申请一定的空间用于参考帧管理。我将解码器的所有的工作缓冲区都分配到了 PSRAM 中，而对实时性要求极高的双显示缓冲区与 SPI 描述符则保留在速度更快的 Internal RAM。 3. “跳帧追赶”算法解决延迟网络波动是串流的大敌。如果数据由于瞬时带宽不足积压在缓冲区，显示的画面就会产生越来越大的延迟。由于采用的是全 I 帧串流，我设计了一个简单的“追赶算法”：解码任务在处理数据前，会先探测 RingBuffer 的积压情况。如果发现积攒了多个待解码帧，则直接丢弃所有旧帧，只解码并显示最后一帧。这个技巧让设备在网络恢复后能瞬间重回实时画面。 上位机设计这次我没有使用 Python，而是直接在 Cardputer 上启动了一个精简的 Web Server 提供前端控制台。前端采用了 DaisyUI 构建界面，能够实时显示当前发送的比特率和流量统计。为了适配 ESP32-S3 的算力，我将 WebCodecs 的编码配置调整为： 比特率：150 - 300 kbps (非常节省带宽) 关键帧频率：高频率刷新 分辨率：强制限制在 240x136 总结从最初的 WDT 频繁崩溃，到如今能够实现稳定的 240x135 @ 15-20 FPS 串流，这个项目探索了 ESP32-S3 的极限负载能力。相比于五年前的面包板方案，现在的 Cardputer 串流方案不仅更加完整（无需 Python 脚本作为桥接），而且在多核优化和内存分配上有了质的提升。即便在微控制器上，也能玩出非常极致的流媒体体验。 硬件建议：必须使用带有 PSRAM 的 ESP32-S3 型号。","link":"/make-remote-streaming-on-m5stack-cardputer/"},{"title":"Arduino Pro Micro(Leonardo)无响应修复：强制 Bootloader 恢复指南","text":"背景我使用的 Pro Micro 是一款基于 ATmega32U4 芯片的紧凑型开发板。它的最大特点是内置 USB 控制器，可以直接被电脑识别为 HID 设备（键盘、鼠标等），无需额外的串口转 USB 芯片，体积小巧，USB 自更新。 最近着手制作一个新玩意儿，使用的开发板是 Pro Micro。起初用起来很正常，烧录程序各种控制都没有问题。 凌晨突然出现插入电脑无法识别，或者识别到了立刻又会断开，在 Windows 的设备管理器里面也是一闪而过。 问题分析虽然很不甘心的拆开了前天刚到的新 Pro Micro，想看看板子是不是真的出现了问题。好家伙，新板子也出现了同样的问题。 新板子坏掉的概率不是很大，于是转而去检查了编写的 .ino 文件。 🔍 根因定位经过排查，发现文件比上一次多了几行 SoftwareSerial 的内容。问题很有可能就是多的几行代码导致 Pro Micro 无法与 PC 正常通信。 原理分析：Pro Micro（以及 Leonardo、Micro 等 32U4 系列）的 USB 通信是由固件控制的。当你的代码在 setup() 或 loop() 中出现以下情况时，可能会阻塞 USB 通信： 无限循环等待：如 while (!Serial); 在未连接串口监视器时会永久阻塞 SoftwareSerial 冲突：在某些引脚上使用软串口可能干扰 USB 时序 中断占用过多：高频中断导致 USB 握手失败 代码崩溃：程序跑飞导致 USB 控制器无法正常响应 于是大量的搜集资料，终于找到了类似的情况，并成功解决了这个问题。 解决方法：强制进入 Bootloader 模式让 Pro Micro 强制进入 Bootloader 模式，并烧录进去正常的代码，就能恢复与电脑的连接。 ⚡ 关键操作步骤 步骤 操作 说明 1 准备一根杜邦线或镊子 用于短接 RST 和 GND 2 快速短接 RST 与 GND 两次 间隔约 0.5 秒，类似”双击” 3 进入 Bootloader 模式 板载 LED 会闪烁，持续约 8 秒 4 立即在 Arduino IDE 点击上传 必须在 8 秒内完成烧录 ⚠️ 注意：Bootloader 模式只会持续 8 秒，超时后会重新运行原来的问题代码。建议提前准备好空白工程，一触发 Bootloader 就立即上传。 📝 空白恢复代码创建一个空的工程，setup 和 loop 函数内都为空： 1234567void setup() { // 空}void loop() { // 空} 烧录完成后电脑就可以正常检测到端口号，就像往常一样使用了。 预防措施：避免再次”变砖”为了避免以后再次遇到类似问题，建议在代码中加入以下保护措施： 123456789101112void setup() { // 给 USB 初始化留出时间 delay(1000); // 或者使用带超时的等待 unsigned long startTime = millis(); while (!Serial &amp;&amp; (millis() - startTime &lt; 3000)) { // 最多等待 3 秒 } // 你的初始化代码...} 💡 其他建议 测试新代码时：先注释掉可能阻塞的代码，确认 USB 通信正常后再逐步启用 使用 ICSP 编程器：作为终极后备方案，可以通过 ICSP 接口强制烧录 Bootloader 标记危险代码：在使用 while(1)、delay(很大的值) 时添加注释提醒 环境信息 项目 版本/型号 开发板 Arduino Pro Micro (ATmega32U4, 5V/16MHz) IDE Arduino IDE 1.8.9+ 操作系统 Windows 10/11 参考资料 Pro Micro &amp; Fio V3 Hookup Guide - Troubleshooting Arduino Leonardo 官方文档 ATmega32U4 Datasheet","link":"/pro-micro/"},{"title":"使用Bindgen为ELK生成Rust绑定","text":"介绍bindgen 是一个能自动为 C（或 C++）库生成 Rust 绑定的辅助库和命令行工具。 elk 是一个迷你的JS引擎.能够实现类似于这样的效果main.rs12345678910111213141516171819##include &lt;stdio.h&gt;##include &quot;elk.h&quot;// C function that adds two numbers. Will be called from JSjsval_t sum(struct js *js, jsval_t *args, int nargs) { if (nargs != 2) return js_err(js, &quot;2 args expected&quot;); double a = js_getnum(args[0]); // Fetch 1st arg double b = js_getnum(args[1]); // Fetch 2nd arg return js_mknum(a + b);}int main(void) { char mem[200]; struct js *js = js_create(mem, sizeof(mem)); // Create JS instance js_set(js, js_glob(js), &quot;sum&quot;, js_mkfun(sum))); // Import sum() jsval_t result = js_eval(js, &quot;sum(3, 4);&quot;, ~0); // Call sum printf(&quot;result: %s\\n&quot;, js_str(js, result)); // result: 7 return 0;} 如果这个执行内容来自于服务器下发,那就可以很方便地动态下发程序然后执行特定的任务. 序之前在玩ESP-IDF时候就尝试内嵌一个Lua引擎来动态执行Lua脚本的操作,然后用蓝牙更新Lua脚本以实现动态的绘制界面.最近弄ESP-RS时候想试试类似的效果,因为感觉Lua用起来很啰嗦,现在已经完全忘记如何编写Lua脚本了.当然Rust也有一些Lua引擎的现成crates,比如rLua.但是数组索引从1开始真的是坏文明啊, 我们还是继续捣鼓js吧. 创建Rust项目1cargo new &quot;bindgen_elk&quot; 克隆elk源码进入刚才创建的目录后,在src同级目录下克隆elk. 123456789cd bindgen_elkgit clone https://github.com/cesanta/elk.gitCloning into 'elk'...remote: Enumerating objects: 932, done.remote: Counting objects: 100% (204/204), done.remote: Compressing objects: 100% (101/101), done.remote: Total 932 (delta 95), reused 152 (delta 87), pack-reused 728 (from 1)Receiving objects: 100% (932/932), 4.66 MiB | 12.09 MiB/s, done.Resolving deltas: 100% (442/442), done. 配置依赖在当前项目的Cargo.toml中添加bindgen和cc依赖.Cargo.toml1234567891011[package]name = &quot;bindgen_elk&quot;version = &quot;0.1.0&quot;edition = &quot;2024&quot;[dependencies]libc = &quot;0.2&quot;[build-dependencies]cc = &quot;1.0&quot;bindgen = &quot;0.69&quot; 创建wrapper.h根据bindgen的规则,需要在项目目录下创建一个叫做wrapper.h的头文件,并在该文件内引入想要绑定的库头文件. wrapper.h1##include &quot;elk/elk.h&quot; 编写build.rs在src同级别目录下创建一个名为build.rs的文件, 当存在build.rs文件时候, Cargo会优先编译执行该文件. 请注意指定include目录, 我用的是mingw64, 所以在bindgen::Builder::default()时候,手动指定了target和sysroot 1234567891011let bindings = bindgen::Builder::default() .header(&quot;wrapper.h&quot;) .parse_callbacks(Box::new(bindgen::CargoCallbacks)) // 1. 指定目标三元组 .clang_arg(&quot;--target=x86_64-w64-mingw32&quot;) // 2. 指定 MinGW 的根目录 .clang_arg(format!(&quot;--sysroot={}&quot;, &quot;C:/Program Files/mingw64&quot;)) // 3. 显式添加必要的 GCC 内部路径 (如果上述两项还不够) .clang_arg(&quot;-IC:/Program Files/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include&quot;) .generate() .expect(&quot;Unable to generate bindings&quot;); 内容如下,具体步骤含义见注释. build.rs123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960use std::{ env, path::{Path, PathBuf},};extern crate cc;/** * 编译出lib文件 */fn compile_libelk() { // 定义源文件路径 let src = [&quot;elk/elk.c&quot;]; // 创建cc builder let mut builder = cc::Build::new(); /* * files 源文件们 * include 头文件路径 * flag -DJS_DUMP宏用于打印js调试信息. 见elk.h内js_dump函数注释 */ let build = builder.files(src.iter()).include(&quot;elk&quot;).flag(&quot;-DJS_DUMP&quot;); build.compile(&quot;elk&quot;);}/** * 生成binding.rs */fn bindgen_generate() { // 获取当前Cargo.toml所在文件夹,一般来说就是该项目位置 let dir = env::var(&quot;CARGO_MANIFEST_DIR&quot;).unwrap(); // 指定库路径,即elk文件夹 println!( &quot;cargo:rustc-link-search=native={}&quot;, Path::new(&amp;dir).join(&quot;elk&quot;).display() ); // 如果 wrapper.h 文件发生了变化, 就重新运行构建脚本 println!(&quot;cargo:rerun-if-changed=wrapper.h&quot;); // 配置绑定 let bindings = bindgen::Builder::default() .header(&quot;wrapper.h&quot;) .parse_callbacks(Box::new(bindgen::CargoCallbacks)) // 1. 指定目标三元组 .clang_arg(&quot;--target=x86_64-w64-mingw32&quot;) // 2. 指定 MinGW 的根目录 .clang_arg(format!(&quot;--sysroot={}&quot;, &quot;C:/Program Files/mingw64&quot;)) // 3. 显式添加必要的 GCC 内部路径 (如果上述两项还不够) .clang_arg(&quot;-IC:/Program Files/mingw64/lib/gcc/x86_64-w64-mingw32/8.1.0/include&quot;) .generate() .expect(&quot;Unable to generate bindings&quot;); let out_path = PathBuf::from(env::var(&quot;OUT_DIR&quot;).unwrap()); // 生成文件写入到binding.rs bindings .write_to_file(out_path.join(&quot;bindings.rs&quot;)) .expect(&quot;Couldn't write bindings!&quot;);}fn main() { compile_libelk(); bindgen_generate();} 生成并使用binding.rs如果你的环境正常,这时候只需要执行cargo build即可1234PS E:\\GitHub\\bindgen_elk&gt; cargo build # ...忽略大量无用信息 Compiling bindgen_elk v0.1.0 (E:\\GitHub\\bindgen_elk) Finished `dev` profile [unoptimized + debuginfo] target(s) in 11.25s最终在target\\debug\\build\\bindgen_elk-b6aa022ece64a1fa\\out\\bindings.rs下找到生成绑定文件. 测试JS脚本参照文章开头的C调用JS代码, 我们写出Rust版本12345678910111213141516171819202122232425262728293031323334use std::ffi::{CString, CStr};include!(concat!(env!(&quot;OUT_DIR&quot;), &quot;/bindings.rs&quot;));##[unsafe(no_mangle)]pub unsafe extern &quot;C&quot; fn sum(js: *mut js, args: *mut jsval_t, nargs: i32) -&gt; jsval_t { if nargs != 2 { let msg = CString::new(&quot;2 args expected&quot;).unwrap(); return js_mkerr(js, msg.as_ptr()); } let a = js_getnum(*args.offset(0)); let b = js_getnum(*args.offset(1)); js_mknum(a + b)}fn main() { unsafe { let mut mem = [0u8; 8192]; let js = js_create(mem.as_mut_ptr() as *mut _, mem.len()); let name = CString::new(&quot;sum&quot;).unwrap(); js_set(js, js_glob(js), name.as_ptr(), js_mkfun(Some(sum))); let code = CString::new(&quot;sum(3, 4);&quot;).unwrap(); let code_len = code.as_bytes().len(); let result = js_eval(js, code.as_ptr(), code_len); let s = CStr::from_ptr(js_str(js, result)).to_str().unwrap(); println!(&quot;result: {}&quot;, s); }} 执行以后可以看到输出1234PS E:\\GitHub\\bindgen_elk&gt; cargo run Finished `dev` profile [unoptimized + debuginfo] target(s) in 0.94s Running `target\\debug\\bindgen_elk.exe`result: 7 环境 rustup 1.28.2 (e4f3ad6f8 2025-04-28) cargo 1.89.0-nightly (fc1518ef0 2025-06-06) elk @ a9bb856 参考资料 Rust Cargo 自定义构建 Rust Cargo使用指南 | 第十七篇 | 构建脚本 build.rs","link":"/rust-bindgen-for-elk/"},{"title":"声明式 UI 架构下的生命周期演进：从内建属性到显式订阅","text":"消失的“实体”: 从View到Composable/Widget在原生Android开发的世界, 创建模版项目后就会得到一个MainActivity和activity_main.xml.我们习惯了在MainActivity里去绑定Button和Text再设置各种属性. 他们都是内存中看得见,摸得着的View.但是到了Flutter中, 得到的了却是main()函数和一堆StatelessWidget和StatefulWidget.不仅仅是Flutter, 连Jetpack Compose也在向这种’声明式UI’靠拢.Compose中同样找不到onResume(入口Activity除外),取而代之的而是层层嵌套的Composable函数 这种转变本质上是：我们不再持有 UI 的“句柄”，我们只持有“数据”。 正因为我们持有的只是数据，而数据本身是没有‘前后台’概念的（一个 String 字符串哪里知道自己是否在前台？）。所以，在声明式 UI 中寻找 onResume 本身就是一个伪命题。只有当数据需要根据系统状态（如用户回来了）进行刷新时，我们才去主动询问系统。 为什么 onResume 不再属于 UI 组件View体系的“重形约束”在原生 Android 中，Activity 是一个重型容器，它直接占据着系统的窗口资源和输入焦点。这种设计决定了开发者必须拥有极强的“生存意识”： 前后台切换: 我们必须精确掌握 onPause 和 onResume，以便在失去焦点时停止动画或暂停视频。 极限生存： 在电池优化策略或“不保留活动”的极限测试下，Activity 随时会被销毁，我们不得不依赖 onSaveInstanceState 艰难地维持状态。 任务流转： 耗时后台任务必须挪到专门的 Foreground/Background Service 中，否则随时会被系统“祭天”。 声明式 UI 的“逻辑重构”但在 Flutter 和 Compose 的世界里，这种“资源焦虑”被屏蔽了。我们面对的是轻量级的函数和配置。 UI 即快照： 界面不再是长存的实体，而是数据的瞬时表达。销毁一个 Widget 就像扔掉一张草稿纸，成本极低。 底层重构： 这种变化不仅仅是语法上的，更是底层生存逻辑的重构。你不再需要盯着每一个 View 对象的死活，只需要守护好背后的 State。 消失的本质：为什么它们敢“干掉” onResume？在原生 Android 中，View 是一个具有稳定身份（Stable Identity）的对象。你通过 findViewById 拿到的 Button，在它被销毁前，其内存地址是不变的，因此它可以安全地持有状态与生命周期回调。 而在 Flutter 中，Widget 仅是不可变的配置描述（Immutable Configuration）。 它在每一帧都可能被重新创建。 你无法给一个“瞬时快照”绑定生命周期，因为这个对象本身随时会消失。 真正具有生命周期的不是 Widget，而是底层的 State 对象，因为它在 Widget 重建时依然保持稳定。 只有当业务需要时，才去“订阅”环境其实 Flutter 并非没有生命周期，只是它不再作为 UI 组件的内建能力。 我们需要区分三个维度的生命周期： App 级别（WidgetsBinding）：整个应用进程的前后台信号。 页面级别（RouteAware）：当前页面是否处于导航栈顶的可见状态。 组件级别（Composition）：Widget 进入或退出 UI 树的过程。 将这些信号与 UI 描述彻底解耦，正是 Flutter 极致灵活的原因。 Flutter 方案：监听 AppLifecycleState在 Flutter 中，需要通过 WidgetsBindingObserver 来扮演那个“哨兵”的角色。 WidgetsBindingObserver 的订阅是 State 级别的，而不是 Widget 级别的。 1234567891011121314151617181920212223// 建议替换原本的 Flutter 代码块class MyState extends State&lt;MyWidget&gt; with WidgetsBindingObserver { @override void initState() { super.initState(); WidgetsBinding.instance.addObserver(this); } @override void didChangeAppLifecycleState(AppLifecycleState state) { // 严谨判断：只有 App 回到前台，且当前页面正处于栈顶可见时，才触发逻辑 if (state == AppLifecycleState.resumed &amp;&amp; ModalRoute.of(context)?.isCurrent == true) { _refreshData(); } } @override void dispose() { WidgetsBinding.instance.removeObserver(this); super.dispose(); }} Compose 方案：通过副作用显式接入宿主生命周期Compose 并没有“移除” onResume，而是拒绝让 UI 组件隐式地持有它。123456789@Composablefun OnResumeEffect(onResume: () -&gt; Unit) { val lifecycleOwner = LocalLifecycleOwner.current LaunchedEffect(lifecycleOwner) { lifecycleOwner.lifecycle.repeatOnLifecycle(Lifecycle.State.RESUMED) { onResume() } }} 结语：从“被动接受”到“主动订阅”从原生 Android 转向 Flutter 或 Compose，最难的不是学习新的语法，而是思维权力的移交。 在传统的 View 体系中，生命周期是系统强行塞给我们的“全家桶”，我们作为开发者，更多是在被动地接受 Activity 的调度。而声明式 UI 的出现，将组件彻底从繁重的系统环境依赖中解放出来。 这种“消亡”实际上是一种进化： 它让我们更关注数据本身：UI 不再是长存的“房子”，而是随数据流动的“快照”。 它赋予了我们订阅的自由：不再为了那 1% 的业务需求让 100% 的组件去负担生命周期回调，而是根据业务逻辑，在需要的地方精准地拉出一根“信号线”。 生命周期没有消失，只是从“隐式回调”进化为了“显式订阅”。","link":"/the-death-of-onresume-declarative-ui-lifecycle/"},{"title":"Real-time Desktop Streaming on M5Stack Cardputer via H.264","text":"本文同时提供以下语言的翻译： 中文. BackgroundIt’s been five years since I first tinkered with ESP32 streaming on a messy breadboard.At that time, the setup was built on a breadboard, featuring a 1.14” screen with a 240x135 resolution, powered by the original ESP32. That post described the implementation details in depth. Five years later, I decided to revisit this project and migrate the hardware environment to the M5Stack Cardputer. Additional NoteMy Cardputer has been manually upgraded. The original main controller was an ESP32-S3FN8 (8MB built-in Flash, no PSRAM), which I replaced with an ESP32-S3FH4R2.I sacrificed 4MB of Flash to gain 2MB of PSRAM. The image above shows a close-up of the chip replacement. To protect the surrounding delicate SMD components, I used aluminum foil tape for heat insulation. You can still see some flux residue around the solder joints—it might not look pretty, but it gave this little machine “new life.” Why PSRAM is Mandatory: The “SRAM-Only” ExperimentBefore deciding to swap the chip, I tried extensively to get H.264 decoding running on the PSRAM-less original Cardputer. It turned out to be nearly a “Mission Impossible.” H.264 software decoders have rigid memory requirements. Even at a low resolution like 240x136, the DPB (Decoded Picture Buffer) mechanism and SPS activation require large, contiguous blocks of memory. After running the WiFi stack, TCP/IP, and WebSocket service, the internal SRAM of the ESP32-S3 has very little contiguous space left. I tried some extreme optimizations to save memory: Removing LVGL UI: Switched to bare-metal display control, reclaiming ~50KB. Squeezing System Components: Reduced WiFi dynamic TX buffers from 32 to 4 and static RX buffers to 3, saving ~45KB. Discarding Double Buffering: Implemented a “Decode -&gt; Convert -&gt; Push to Screen” synchronous model to eliminate display redundancy. Despite reclaiming over 100KB, the esp-h264 library still failed during initialization because it couldn’t allocate enough contiguous working memory.Conclusion: For H.264, which relies on reference frames, PSRAM is a “life-saver” for ESP32-S3. If you want to play with real-time video streams, manually soldering a PSRAM-capable chip is the most efficient solution. System ArchitectureWith the extra PSRAM, I can perform H.264 stream decoding directly on the device.Espressif provides a component called esp_h264, which enables software decoding on the ESP32-S3. My tests showed that 2MB of PSRAM is just enough to support 240x136 decoding (the screen is 240x135, but H.264 requires even dimensions). Communication PipelineTo ensure ultra-low latency, I redesigned the communication architecture: Sender (Browser): Uses the browser’s getDisplayMedia to capture the desktop, encodes it using WebCodecs into H.264 Annex B format (set to GOP=1 for I-frame only mode), and sends the binary data over WebSocket. Receiver &amp; Buffer (ESP32-S3): The Cardputer acts as a WebSocket Server, receiving data and storing it in a RingBuffer for smoothing. Decryption/Decoding Core: A dedicated decoding task pulls raw byte streams from the RingBuffer and decodes them into YUV420P images using esp_h264. Color Conversion &amp; Display: Decoded images are converted to RGB565 in real-time and pushed directly to the ST7789 screen via SPI DMA. Key Challenges &amp; Solutions1. Multi-core Scheduling &amp; Watchdog (WDT) ErrorsIn early versions, decoding, color conversion, screen refresh, and LVGL UI updates all ran on the same core. This caused the CPU usage to spike, frequently triggering Task Watchdog resets.Solution: Core Affinity: Core 0 handles the WiFi stack, WebSocket service, and LVGL UI tasks. Dedicated Decoding Core: Core 1 is assigned as a high-priority task, solely responsible for H.264 decoding, YUV-to-RGB conversion, and LCD bitmap refreshing.This strategy ensures that even when the decoding task is under heavy load, the system components can still “feed the dog,” ensuring stability. 2. Memory ManagementThe esp_h264 decoder requires significant contiguous memory. Even with GOP=1, it still allocates space for reference frame management.I allocated all the decoder’s working buffers to PSRAM, while keeping the high-performance double display buffers and SPI descriptors in the faster Internal RAM. 3. “Frame-Catching” Algorithm for LatencyNetwork jitter is the enemy of streaming. If data accumulates in the buffer due to transient bandwidth drops, the display will experience increasing latency.Since I use an all-I-frame stream, I implemented a simple “catching” algorithm:Before processing, the decoding task checks the RingBuffer’s occupancy. If it detects multiple frames waiting, it discards all older frames and only decodes/displays the latest one. This trick allows the device to snap back to real-time visuals the moment network conditions recover. Controller DesignThis time, I didn’t use Python. Instead, I launched a lightweight Web Server directly on the Cardputer to provide a frontend console. The frontend uses DaisyUI for a modern interface and displays real-time bitrates and traffic statistics.To fit the ESP32-S3’s processing power, I tuned the WebCodecs configuration: Bitrate: 150 - 300 kbps (highly bandwidth efficient) Keyframe Interval: High frequency Resolution: Forced to 240x136 ConclusionFrom frequent WDT crashes to stable 240x135 @ 15-20 FPS streaming, this project explores the performance limits of the ESP32-S3.Compared to the breadboard setup from five years ago, this Cardputer solution is more complete (no Python bridge required) and features significant improvements in multi-core optimization and memory management. Even on a microcontroller, you can achieve a truly extreme streaming experience. Hardware Suggestion: An ESP32-S3 model with PSRAM is required.","link":"/en/make-remote-streaming-on-m5stack-cardputer/"},{"title":"UNO R4 Wi-Fi 接入 Home Assistant","text":"项目介绍本项目是Funpack第五期板卡三的任务1实现.任务目标是让UNO R4 Wi-Fi通过网络连接到智能云端, 并模拟成一个可以控制的灯, 通过远程控制调整自带的LED矩阵点亮范围. 实现思路将UNO R4作为灯装置接入IOT平台, 随后在IOT平台上下发命令来操作UNO R4, 调整这个”灯”的亮度.这里我选择的是可以部署在内网环境下的Home Assistant. UNO R4通过MQTT服务器与Home Assistant进行通信. MQTT服务器选择EMQX开源版. 服务器部署本项目需要有一台服务器,并且在服务器上部署Home Assistant和EMQX两个服务.本节简单介绍下两个服务的部署方式. Home Assistant在Home Assistant官网上有较为详细的多种安装方式介绍.这里我选择的是使用Docker进行安装,可以忽略很多具体环境差异,只需要输入命令便可将Home Assistant跑起来.具体介绍位于Install Home Assistant Container 123456789docker run -d \\ --name homeassistant \\ --privileged \\ --restart=unless-stopped \\ -e TZ=MY_TIME_ZONE \\ -v /PATH_TO_YOUR_CONFIG:/config \\ -v /run/dbus:/run/dbus:ro \\ --network=host \\ ghcr.io/home-assistant/home-assistant:stable 命令执行完毕,打开使用服务器IP配合默认端口号8123-&gt;http://&lt;host&gt;:8123即可进入主面板. EMQXEMQX同样可以使用Docker进行安装部署. 运行以下命令获取 Docker 镜像：1docker pull emqx/emqx:5.8.1运行以下命令启动 Docker 容器。1docker run -d --name emqx -p 1883:1883 -p 8083:8083 -p 8084:8084 -p 8883:8883 -p 18083:18083 emqx/emqx:5.8.1 HomeAssistant对接到EMQX进入HomeAssistant主页后点击右下角设置,选择设备与服务, 搜索MQTT 安装好MQTT插件后,进入插件面板点击添加条目填写上一步配置的EMQX信息即可. 代码编写注册到Home Assistantpublish 指定格式的payload到topic其中topic格式为homeassistant/设备类型/自定义名称/config,根据格式要求.得到主题应当为homeassistant/light/fun_matrix/config.payload内容是一个描述设备的json字符串, 如下代码所示. 其中name是设备名称; device_class要和注册topic中设备类型对应; command_topic代表设备的开关状态; brightness_command_topic灯的亮度控制; unique_id装置唯一ID; device设备描述; schema代表当前为json格式; brightness代表本装置支持亮度控制;1234567891011121314151617181920212223void registerToHomeAssistantServer() { const char* topic = &quot;homeassistant/light/fun_matrix/config&quot;; std::string message = R&quot;({ &quot;name&quot;: &quot;led&quot;, &quot;device_class&quot;: &quot;light&quot;, &quot;command_topic&quot;: &quot;fun_matrix/light/state&quot;, &quot;brightness_command_topic&quot;: &quot;fun_matrix/light/brightness/set&quot;, &quot;unique_id&quot;: &quot;fun_matrix&quot;, &quot;device&quot;: { &quot;identifiers&quot;: &quot;fun_matrix&quot;, &quot;name&quot;: &quot;UnoR4WiFi&quot; }, &quot;schema&quot;: &quot;json&quot;, &quot;brightness&quot;: true})&quot;; bool retained = false; int qos = 1; bool dup = false; mqttClient.beginMessage(topic, message.length(), retained, qos, dup); mqttClient.print(message.c_str()); mqttClient.endMessage();} 响应HomeAssistant命令根据注册时候payload中brightness_command_topic和command_topic, 来响应具体的动作即可.其中command_topic固定传递ON和OFF字符串, brightness_command_topic传递亮度值0-255.123456789101112131415161718192021222324252627282930void onMqttMessage(int messageSize) { String topic = mqttClient.messageTopic(); Serial.println(topic); String payload; while (mqttClient.available()) { payload = mqttClient.readString(); Serial.println(payload); } if (topic.endsWith(&quot;state&quot;)) { Serial.print(&quot;brightness_state_topic&quot;); bool enable = payload.equals(&quot;ON&quot;); if (lightIsOn != enable) { lightIsOn = enable; if (lightIsOn) { showFrame(level); } else { showFrame(0); return; } } } if (topic.endsWith(&quot;set&quot;)) { Serial.print(&quot;brightness_command_topic&quot;); level = payload.toInt() / 25; Serial.println(level); showFrame(level); return; }} 功能展示在网页上设置亮度, 均能够在设备上得到实时的响应.不同的亮度,亮起的区域.","link":"/uno-r4-wifi-and-home-assistant/"}],"tags":[{"name":"DIY","slug":"DIY","link":"/tags/DIY/"},{"name":"ESP32","slug":"ESP32","link":"/tags/ESP32/"},{"name":"Arduino","slug":"Arduino","link":"/tags/Arduino/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"Kotlin","slug":"Kotlin","link":"/tags/Kotlin/"},{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"AI","slug":"AI","link":"/tags/AI/"},{"name":"Claude Code","slug":"Claude-Code","link":"/tags/Claude-Code/"},{"name":"Embedded","slug":"Embedded","link":"/tags/Embedded/"},{"name":"C","slug":"C","link":"/tags/C/"},{"name":"Dithering","slug":"Dithering","link":"/tags/Dithering/"},{"name":"ESP-IDF","slug":"ESP-IDF","link":"/tags/ESP-IDF/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"算法","slug":"算法","link":"/tags/%E7%AE%97%E6%B3%95/"},{"name":"图像处理","slug":"图像处理","link":"/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"移动开发","slug":"移动开发","link":"/tags/%E7%A7%BB%E5%8A%A8%E5%BC%80%E5%8F%91/"},{"name":"Hardware Analysis","slug":"Hardware-Analysis","link":"/tags/Hardware-Analysis/"},{"name":"Keyboard","slug":"Keyboard","link":"/tags/Keyboard/"},{"name":"UI","slug":"UI","link":"/tags/UI/"},{"name":"WCH","slug":"WCH","link":"/tags/WCH/"},{"name":"CH592","slug":"CH592","link":"/tags/CH592/"},{"name":"IoT","slug":"IoT","link":"/tags/IoT/"},{"name":"BLE","slug":"BLE","link":"/tags/BLE/"},{"name":"Hardware DIY","slug":"Hardware-DIY","link":"/tags/Hardware-DIY/"},{"name":"SEO","slug":"SEO","link":"/tags/SEO/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"}],"categories":[{"name":"Hardware &amp; IoT","slug":"Hardware-IoT","link":"/categories/Hardware-IoT/"},{"name":"Software &amp; Dev","slug":"Software-Dev","link":"/categories/Software-Dev/"},{"name":"Project Logs","slug":"Project-Logs","link":"/categories/Project-Logs/"}],"pages":[{"title":"404 Not Found","text":"404 很抱歉，您访问的页面似乎已经去流浪了... 这可能是因为文章已被移除，或者您输入了错误的链接。 返回首页","link":"/404.html"},{"title":"关于 Chaosgoo","text":"Chaosgoo 是由 Chaos Goo 创建并维护的独立运行的技术博客。 本网站专注于发布与嵌入式系统、电子工程和软硬件结合相关的原创实战技术文章。本站所有内容均由站长基于真实的开发和工程实践编写、编辑和维护。 本站处于持续维护中，并计划长期发布。本站不存在任何采集、自动生成或聚合的内容。 有关内容、版权或广告合作的咨询，请通过 admin@chaosgoo.com 联系站长。 关于我 你好～ 我是 Goo（Chaos Goo），一个沉迷 DIY 的爱好者。 这里记录开发过程中的实验代码、调试经验以及设计思路，同时保留真实开发过程中的思考与总结。 技术栈 &amp; 专长领域 领域 技术/工具 嵌入式开发 ESP32 / ESP-IDF / ESP8266 / WCH (CH58x/CH592) / Arduino GUI 框架 LVGL / FreeType 字体引擎 / TFT_eSPI 智能家居 HomeKit / Home Assistant / MQTT 移动开发 Android (Kotlin / Flutter) 硬件设计 KiCad / Fusion 360 / 3D 打印 (Bambu Lab P1SC) 版本控制 Git / GitHub 核心折腾方向 低成本芯片创意应用：主力使用乐鑫 ESP32 系列，从构思到 PCB 设计、焊接、固件开发全程独立完成 WCH 芯片探索：最近在解锁 CH58x/CH592 等超低功耗芯片，研究蓝牙 BLE + 墨水屏的极限应用 游戏道具还原：不只做到外观神似，更要复刻核心功能 —— 发光、音效、交互动画 代表项目 项目 描述 链接 ESPFlash Android 平台的 ESP32 烧录工具，已上架 Google Play Play Store SerialFlow Android 带有搜索过滤功能的串口监视器，已上架 Google Play Play Store CS2 HealthPin 真实还原 CS2 生命值胸章，支持游戏 GSI 实时同步 博文 Friday Ink 基于 CH582F 的超低功耗墨水屏时钟 (≈3μA 休眠) 博文 LVGL FreeType 系列 ESP32 上实现可变字体动态字重 (50,000+ 阅读量) 系列文章 硬件装备 3D 打印机：Bambu Lab P1SC（定制外壳和机械零件） 建模软件：Fusion 360（对比 Inventor 更轻量，上手更顺） 联系方式 Email: admin@chaosgoo.com GitHub: github.com/chaosgoo Bilibili: 个人主页 YouTube: @chaosgoo 该电子邮件地址由站长直接管理。 版权声明本站作为笔者的唯一官方技术存档点，持续更新中。 所有原创文章、代码片段和项目资料均遵循 CC BY-NC 4.0 协议发布。 本站部分文章的早期版本曾发布在其他平台，现已在本站进行了重新修订、整合并由本站独家维护。所有内容的创建均出于教育和信息目的，并在发布前经过审核。本站不接受用户生成的内容或公开投稿。本站显示的任何广告均不影响编辑决策或内容创作。 广告与商业化本网站可能会展示第三方广告（如 Google AdSense），以支持网站托管和持续的内容创作。 广告不会影响内容的编辑独立性。 历史账号说明 Bilibili (旧): uid:14374079（已注销） 简书: 一只不咕的鸽子（已停更）","link":"/about/index.html"},{"title":"联系我们","text":"如果您对本站的内容（如 ESP32 开发、Android 技术分享等）有任何疑问、建议，或者有商务合作意向，欢迎通过以下方式与我取得联系。 电子邮件 (Email)这是最推荐的联系方式，通常会在 24-48 小时内回复。 admin@chaosgoo.comsindoutriqua@gmail.com (建议在邮件标题中注明来意，例如：“关于[文章标题]的疑问”) 社交媒体 (Social Media)您也可以通过以下平台关注我的最新动态： Bilibili: 点击访问我的 B 站主页 (分享硬件制作视频) GitHub: 点击访问我的 GitHub (获取项目源码) 版权声明本站所有原创文章及代码，未经授权请勿转载。如需转载或引用，请先通过邮件联系确认。","link":"/contact/index.html"},{"title":"410 Gone &#x2F; 资源已移除","text":"410 此内容已永久移除 (Permanently Gone) 抱歉，该页面由于过时、低质量或不再符合本站主题，已被作者主动永久删除。 SEO 提示：410 状态码明确告知搜索引擎该资源已不存在且不会恢复，这有助于优化搜索索引质量，避免死链影响。 &lt;p style=&quot;margin-bottom: 2rem;&quot;&gt;您可以尝试在首页搜索相关主题，或浏览最新文章。&lt;/p&gt; &lt;a href=&quot;/&quot; style=&quot;display: inline-block; padding: 12px 30px; background: #2bbc8a; color: white; text-decoration: none; border-radius: 4px; font-weight: bold; transition: background 0.2s;&quot;&gt; 返回首页 &lt;/a&gt; &lt;/div&gt;","link":"/410.html"},{"title":"ESP32 开发指南：从入门到进阶","text":"ESP32 开发资源汇总ESP32 是乐鑫（Espressif）推出的一款低成本、低功耗的系统级芯片（SoC），集成了 Wi-Fi 和蓝牙功能，广泛应用于物联网（IoT）、智能家居、可穿戴设备等领域。 本页面汇总了本站所有与 ESP32 开发相关的技术文章，涵盖从基础入门到高级应用的完整知识体系。 文章索引GUI 开发：LVGL + FreeType 可变字体系列这是本站最受欢迎的系列文章，累计阅读量超过 50,000+。 章节 标题 简介 第一章 在 LVGL 中实现可变字体 (Variable Font) FreeType 字体引擎基础，在 Windows 模拟器上实现动态字重 第二章 LVGL + FreeType - ESP32 移植篇 PlatformIO 项目配置，TFT_eSPI 屏幕驱动 第三章 LVGL + FreeType - 动画效果实现 SD 卡加载字体，字重动画实现 网络与通信 文章 简介 ESP32 显示公网 JPG 图片 HTTP 协议详解，AsyncTCP 分块传输，Content-Length 解析 ESP32 + 4G 模块：PPPoS 联网方案 告别 AT 指令，使用 PPPoS 将串口虚拟为网卡 ESP32 PC 画面实时串流 Python 抓帧编码 + 自定义 TCP 协议 + DMA 渲染 智能家居：HomeKit 系列 章节 标题 简介 第一章 ESP32 控制灯光 - 舵机方案 非侵入式改造，舵机 PWM 控制原理 第二章 ESP32 控制灯光 - WSL 环境配置 esp-homekit-demo 编译与烧录 第三章 ESP32 控制灯光 - 代码融合 Siri 语音控制闭环实现 进阶项目： 米家屏幕挂灯 HomeKit 改造 - 拆解分析 + 芯片替换 开发技巧与填坑指南 文章 简介 ESP32 进阶开发技巧 异步 HTTP、Light-Sleep PWM、GIF 播放、SPIFFS OTA ESP-IDF embed_txtfiles 使用技巧 资源嵌入机制详解，证书/HTML 管理最佳实践 ESP32-C3 PlatformIO embed_txtfiles 修复 RISC-V 工具链配置 Bug 解决方案 SPI LCD vs 并口 LCD 性能对比 60MHz SPI 与 8 位并口实测数据分析 图像处理：Ditherpunk 抖动算法 文章 简介 Ditherpunk (一)：算法原理与 JS 实时演示 Gamma 校正、Bayer 矩阵、误差扩散算法详解 Ditherpunk (二)：ESP32 + 单色屏实战 ST7305 1.54 寸屏驱动，全套抖动效果移植 推荐外部资源 ESP-IDF 官方文档 LVGL 官方文档 PlatformIO ESP32 平台 乐鑫官方论坛 联系与反馈如果你在 ESP32 开发过程中遇到问题，或者对文章内容有任何建议，欢迎通过以下方式联系我： Email: admin@chaosgoo.com GitHub: github.com/chaosgoo 本页面持续更新中，收录本站所有 ESP32 相关技术文章。","link":"/esp32-guide/index.html"},{"title":"GDPR 数据保护合规声明","text":"Last updated: 2026 年 02 月 02 日 本博客（以下简称 “本站”）尊重并保护用户的个人数据隐私，依据欧盟《通用数据保护条例》（GDPR，Regulation (EU) 2016/679）及相关数据保护法律法规，明确告知欧盟用户本站的数据收集、使用、保护规则及用户享有的数据权利。若你对数据保护有任何疑问，可通过 “联系我们” 方式与本站管理员沟通。 一、我们收集哪些用户数据？结合本站运营实际，仅收集以下与服务必要相关的数据，无额外主动收集行为： 主动联系数据 若你通过电子邮件（admin@chaosgoo.com）或其他方式主动联系本站，我们会收集你提供的联系信息（如邮箱地址、沟通内容）。 收集目的：仅用于回复你的查询、处理你的建议，不会用于其他无关用途。 第三方工具关联数据 本站使用 Google Analytics（流量分析）和 Google AdSense（广告服务），相关数据收集由谷歌负责： Google Analytics 可能收集你的 IP 地址、浏览器类型、设备信息、访问页面、访问时间（仅用于流量统计与内容优化）； Google AdSense 可能通过 Cookie 收集你的浏览行为数据（用于推送关联广告）； 说明：此类数据的收集、使用遵循谷歌官方隐私政策，本站不直接控制或存储该部分数据。 二、我们如何保护用户数据？ 本站直接收集的 “主动联系数据”，仅保留至沟通需求完成后 1 个月，之后将永久删除，不长期留存； 第三方服务（评论系统、Google 工具）的数据保护，由对应第三方负责，本站已选择合规性较强的服务商，并要求其遵循 GDPR 规则； 本站不将任何用户数据（含第三方间接提供的数据）出售、出租或转让给除合作服务商外的其他第三方； 本站采用基础网络安全措施（如服务器防火墙、邮箱加密沟通），防止直接收集的数据被未授权访问。 三、欧盟用户享有的数据权利（依据 GDPR）作为欧盟用户，你对自身数据享有以下权利，可随时联系本站行使： 知情权：有权了解本站及第三方服务收集你数据的具体类型、用途及存储期限； 访问权：有权要求本站提供直接收集的你的联系数据（如你曾发送的邮件内容），或协助你向第三方评论系统申请访问你的评论数据； 更正权：若本站直接收集的你的联系数据存在错误（如邮箱地址拼写错误），有权要求更正； 删除权：有权要求本站删除直接收集的你的联系数据，或协助你向第三方评论系统申请删除你的评论及关联信息； 拒绝权：有权拒绝本站收集你的主动联系数据（如不提供邮箱进行沟通），或通过谷歌官方渠道拒绝 Google Analytics/AdSense 的数据收集（具体路径见下文）； 数据可携带权：有权要求本站将直接收集的你的数据，以结构化、机器可读格式提供给你或你指定的其他合规主体（如适用）。 协调第三方删除：根据 GDPR/CCPA 等法规，我们将尽力协调 Google 等第三方服务商删除与您相关的个人数据（如可能）。 四、如何行使数据权利？ 联系本站 若你需要行使上述权利（如删除联系数据、咨询第三方数据收集详情），可通过以下方式联系本站管理员： 电子邮件： admin@chaosgoo.com（优先处理方式）； sindoutriqua@gmail.com我们会在收到请求并核实身份后的 30 天内响应。为了确保数据安全，请提供足够的身份验证信息（如注册邮箱、联系时的主题等）。我们将视情况协调 Google 等第三方删除相关数据。 针对第三方工具的权利行使 若你想拒绝或管理 Google Analytics/AdSense 的数据收集，可通过以下官方渠道操作： Google AdSense（DART Cookie）：访问 Google 广告和内容网络隐私权政策，选择停用相关 Cookie； Google Analytics：访问 Google Analytics 隐私设置，按指引调整数据授权范围。 五、投诉渠道若你认为本站或合作第三方未按 GDPR 保护你的数据，除联系本站外，也可向欧盟数据保护机构（EDPB）或你所在欧盟成员国的本地数据保护机构提交投诉，维护自身权益。","link":"/gdpr/index.html"},{"title":"友情链接","text":"大黄猫の博客粤北山区的技术宅","link":"/links/index.html"},{"title":"MCompass 固件下载与编译","text":"This article is also available in the following language: English. 返回制作指南 固件获取方式如果你不打算修改源代码，可以直接下载编译好的二进制文件 (Firmware)。 1. 从 GitHub Actions 自动构建下载 (推荐)本项目已配置 GitHub Actions 自动编译。通过这种方式，你可以始终获得对应最新代码的固件： 前往 GitHub 项目的 Actions 页面。 找到最近一次构建成功的 “Build Firmware Workflow” 记录。 在页面下方的 Artifacts 区域，根据你的需求选择对应的 .bin 文件： 文件名关键字段 描述 GPS 硬件安装了 GPS 模块的版本 LITE 标准版 (无 GPS 或屏蔽 GPS) BLE 默认开启蓝牙模式 (通过小程序配置) WIFI 默认开启 WiFi 模式 (通过网页配置) 2. 手动编译本项目使用 PlatformIO 进行管理： 固件: 基于 Arduino 框架，依赖库已完整迁移至本地 lib 文件夹。 网页资源 (Web Server): WiFi 模式后台使用 Next.js 开发。 进入 Server 文件夹，执行 npm i 和 npm run build。 将生成的 out 目录内容拷贝至固件的 data 文件夹下。 使用 Firmware/assets/compass_web_data.py 进行资源压缩以减小 Flash 占用。 烧录指南1. 使用官方工具 (PC)下载 Flash Download Tool： 芯片选择: ESP32-C3 下载模式: USB 文件选择: 将下载的 .bin 文件加载到地址 0x0。 参数: SPI SPEED: 40MHz, SPI MODE: DIO。 注意: 固件已合并 bootloader 和 partition table，只需烧录至 0x0 即可。 2. 使用手机烧录 (Android)如果你身边没有电脑，可以使用作者开发的 ESPFlash 直接通过手机 USB 指向烧录： 声明 版权声明: 本项目所用 Minecraft 像素素材版权归微软/Mojang 所有。本项目面板文件仅作为像素分布示意，不提供罗盘原始贴图。 商业用途禁止: PCB 背面使用的“标准银河字母”字体版权归原作者。如需进行任何商业行为，请务必删除背面丝印文字。","link":"/mcompass/guide.html"},{"title":"MCompass 制作全攻略","text":"This article is also available in the following language: English. The Real-life Minecraft Compass 欢迎来到 MCompass 的制作指南。在这里你可以找到从物料准备、自动化编译、固件烧录到日常交互的所有技术细节。 快速导航 物料与模型 (BOM & 3D) 查看完整的零件清单、选型建议与 3D 打印模型。 烧录与编译 (Flash) 从 GitHub 下载现存固件或使用 PlatformIO 手动编译。 交互使用说明 (Manual) 学习如何操作按钮切换模式、校准传感器及进入后台。 立创开源 PCB 工程 GitHub 源码仓库 重要声明 (Copyright &amp; Safety)在使用或制作 MCompass 之前，请务必阅读以下声明： 素材声明：Minecraft 游戏相关视觉素材版权均归 Microsoft / Mojang 所有。本项目仅提供基于点阵分布的开源设计，不分发任何游戏原始资源。 商业使用限制： 严禁 用于任何商业盈利行为。 PCB 背面使用的标准银河字母（Standard Galactic Alphabet）字体版权不明确，如需商业化请务必自行删除相关丝印。 制作建议：本装置涉及锂电池充电与小型电子元件焊接，请在具备基本电子制作常识的情况下进行。 常见问题汇总 (Q&amp;A) Q: GPS 定位需要多久？ A: 模块首次定位（冷启动）在开阔地带通常需要 30秒以上。 Q: 启动后屏幕显示绿色 \"x4\" 是什么意思？ A: 这代表了 I2C 通信失败，通常是 QMC5883 传感器或排母焊接虚焊导致的。 Q: 支持双头 Type-C 线线充电吗？ A: 需要在 PCB 上焊接对应的 CC1/CC2 下拉电阻方可识别 C-to-C 线缆。 更新日志 (Changelog) 2025.09.17 指针过冲效果：完美复刻游戏中的跳动感，转动过快时指针会产生物理惯性。 启动容错优化：多次检测地磁传感器，提高启动稳定性。 2024.12.07 智能电源策略：根据距离动态开关 GPS 以延长续航。 回到项目列表","link":"/mcompass/index.html"},{"title":"MCompass 交互与功能说明","text":"This article is also available in the following language: English. 返回制作指南 按钮交互逻辑MCompass 的所有操作通过机身侧边的单按键完成。 操作次数 功能描述 备注 单击 1 次 切换模式 在“出生点模式”与“指南针模式”间切换 连按 4 次 查询状态 网页模式下会显示当前设备的 IP 地址 连按 6 次 地磁校准 倒计时结束后，需拿稳罗盘在空中平稳画“8”字旋转 连按 8 次 出厂设置 清除所有保存的配置并重启，恢复初始状态 长按 3秒 背景功能 出生点模式：将当前位置设为新的出生点 (需 GPS 信号)指南针模式：切换到 Nether(下界) 模式，指针将无序乱转 注：地磁校准对指针准确度至关重要，如发现指针指向偏差过大，请务必执行校准。 后台配置模式1. 蓝牙后台 (WeChat Mini Program)启动后 1 分钟内，你可以通过微信小程序 “罗盘控制台” 搜索并连接。 功能: 自定义指针颜色、校准传感器、通过地图选择/搜索目标经纬度。 注意: 请确保已开启手机蓝牙和定位权限。 2. 网页后台 (Web Dashboard)如果未连接蓝牙，设备会尝试连接已有的 WiFi；如果没有 WiFi 配置，则会开启名为 The Lost Compass 的 AP 热点。 进入方式: 连接热点后，浏览器访问 esp32.local 或 192.168.4.1。 高级操作: 你可以在网页端实现 GZIP 压缩管理、更改 WiFi 设置以及实时调试传感器数值。 特殊状态说明 指针乱转: 处于 Nether(下界) 模式（手动长按开启）。 处于出生点/指南针模式，但没有 GPS 信号（请前往室外或开阔地带）。 显示绿色 “x4”: 代表 I2C 通信异常，即地磁传感器 (QMC5883) 无法识别。请检查焊接或芯片是否损坏。","link":"/mcompass/manual.html"},{"title":"隐私政策","text":"生效日期： 2025 年 10 月 10 日最后更新日期： 2026 年 02 月 02 日 欢迎访问 Chaosgoo | ESP32, IoT &amp; Hardware DIY Blog（以下简称“本网站”）。我们深知隐私对您的重要性，本政策旨在说明本网站在运营过程中如何收集、使用和保护您的信息。 1. 我们收集的信息作为一个静态博客，本网站不会主动收集可识别您个人身份的信息（Personal Identifiable Information, PII），除非您自愿提供： 直接联系数据： 如果您通过电子邮件或其他方式主动联系我们，我们将收集您提供的联系信息（如邮箱地址、邮件内容），以便进行回复和沟通。 2. 通过第三方服务收集的信息（关键披露）本网站使用以下第三方服务来优化用户体验，这些服务可能会间接收集您的非个人信息和使用数据。 A. Google AdSense (广告服务) Google AdSense： Google 作为第三方供应商，使用 Cookie 来根据用户访问本网站和互联网上其他网站的情况投放广告。 Google 广告设置： 您可以通过访问 Google 广告设置 选择停用个性化广告。 Google 广告隐私政策： 访问 Google 广告隐私政策 了解 Google 广告的详细做法。 DART Cookie 详情： Google 使用 DART Cookie 向用户投放广告。 本网站使用 Google Analytics 来分析网站流量。该服务可能会收集您的 IP 地址、浏览器类型、设备信息、访问页面、访问时间等数据。这些数据仅用于统计分析，以改进本网站的内容和结构。 IP 匿名化： 我们已启用 Google Analytics 的 IP 匿名化功能（anonymizeIp），以进一步保护您的隐私。数据可能传输至美国，并受 Google 的隐私盾框架或等效机制保护。 隐私政策： 您可以访问 Google Analytics 隐私政策 获取详细信息。 C. Cookie 和其他跟踪技术本网站和上述第三方服务会使用 Cookie（储存在您设备上的小型文本文件）来记录您的偏好设置、跟踪访问活动和维护会话状态。如启用广告服务，Cookie 也将用于投放广告。 Google Analytics Cookie 详情 Cookie 名称 用途 保留期限 _ga 用于区分用户，生成唯一客户端 ID 2 年 _ga_&lt;ID&gt; 用于保持会话状态 2 年 _gid 用于区分用户 24 小时 _gat 用于限制请求速率 1 分钟 数据接收方： Google LLC 作为我们的分析数据处理方 数据保留： 我们仅在 Analytics 控制台中查看匿名的聚合报告 收集的数据： IP 地址、大致地理位置、设备类型、语言、访问的页面 Google AdSense Cookie 详情（如启用）如本网站启用 Google AdSense，可能使用以下 Cookie： Cookie 名称 用途 保留期限 __gads 投放广告并衡量广告效果 13 个月 __gpi 用于广告个性化 13 个月 DSID 识别已登录用户以进行广告个性化 2 周 IDE 用于展示 Google 广告 13 个月 数据接收方： Google 及其广告合作伙伴 用途： 根据您对本网站和/或互联网上其他网站的访问，向您投放相关广告 管理 Cookie您有权通过浏览器设置随时拒绝或删除 Cookie，但这可能会影响您访问本网站或使用某些第三方功能的能力。 3. 信息的使用目的我们收集的信息主要用于以下用途： 运营和维护本网站的正常运行。 分析用户行为，以改进和优化网站内容及用户体验。 如启用广告服务，可能通过 Google AdSense 向您展示相关的广告。 回复和处理您的查询或建议。 4. 信息的共享与披露除非法律要求或征得您的明确同意，本网站承诺不会向任何无关的第三方出售、交易或转让您的个人信息。 我们可能会与为我们提供技术支持、业务运营或服务的第三方共享信息（例如 Google Analytics，以及如启用时的 Google AdSense），但这些合作方需严格遵守保密协议。 5. 外部链接本网站可能包含指向其他网站的链接。对于这些外部网站的内容、安全措施或隐私做法，我们不承担任何责任。建议您在访问任何外部网站时仔细阅读其隐私政策。 6. 第三方服务及资源我们尽量选择透明且合规的服务商。以下是当前使用的第三方服务完整清单： 服务名称 用途说明 隐私政策/详情 Google Analytics 收集匿名的流量统计数据 隐私政策 Google AdSense 展示个性化或通用广告 广告隐私 Google Tag Manager 动态加载 Analytics 和 AdSense 脚本 GTM 详情 jsDelivr / Font Awesome 提供静态资源、CSS 和字体加载 仅加载静态文件，不收集 PII 关于 CDN 服务本网站使用 CDN（如 jsDelivr、Font Awesome）来加载必要的静态资源。这些服务仅用于传输公共资源库文件，不会主动收集您的个人可识别信息。我们优先使用隐私友好的 CDN，无需额外追踪。 7. 您的权利 (GDPR/CCPA)根据 GDPR/CCPA 等法规，您有权访问、更正、删除您的个人数据，或反对处理。 联系我们： 请发送邮件至 admin@chaosgoo.com，并提供足够身份验证信息（如注册邮箱）。我们将在 30 天内响应，并协调 Google 等第三方删除相关数据（如可能）。 退出 Google Analytics 追踪： 安装 Google Analytics 退出浏览器插件。 管理 Google 广告： 访问 Google 广告设置 选择退出。 管理浏览器 Cookie： 您可以通过浏览器设置随时拒绝或删除 Cookie。 8. 儿童隐私保护本网站面向 13 岁及以上的用户。我们不会故意收集 13 岁以下儿童的任何个人数据。如果您认为某位儿童通过本网站向我们的第三方合作伙伴（如 Google）发送了个人数据，请立即联系我们，我们将配合相关服务提供商删除该数据。 9. 联系我们如果您对本隐私政策或您个人信息的处理有任何疑问或疑虑，请随时通过以下方式联系本网站管理员： 网站管理员： chaosgoo 电子邮件： admin@chaosgoo.com（优先处理方式）； sindoutriqua@gmail.com","link":"/privacy-policy/index.html"},{"title":"MCompass 物料清单与 3D 模型","text":"返回制作指南 This article is also available in the following language: English. MCompass 结构件 (3D 模型)如果你有 3D 打印机（推荐拓竹 Bambu Lab 系列），可以直接前往 MakerWorld 下载已经配置好耗材参数的工程文件。 官方模型地址: MakerWorld - MCompass (The Lost Compass) 打印建议: 推荐使用 PLA 或 PETG 材质。黑色外壳配合适当的填充率可以获得更好的质感。 电子物料 (BOM)部分零件和立创开源广场上不同，但和本设计兼容，可放心购买。 核心芯片与模块 类别 名称 规格 备注 主控 ESP32-C3-MINI 磁力计 QMC5883L / P LGA-16 3x3 L 已停产多为翻新，推荐用 P 型号 GPS ATGM336H-5N71 13.1x15.7mm 需包含配套陶瓷天线 LED WS2812B 0807 1.7x2.0x0.85mm 需要 42 颗，推荐雾状灯珠 电池 213455 锂电池 500mAh 尺寸需严格匹配外壳空间 关键辅助原件 LDO电源: AP2112K-3.3 或 ME6211 (省钱型号) 充电管理: MCP73831 USB接口: GT-USB-7010ASV (USB-C 16P) 结构五金: 滚花螺母: M2x3x3.2 (用于通过热熔嵌入外壳) 螺丝: M2x4 内六角 选型建议与调试指南 C1206 100uF 电容: 非必须焊接。如遇到灯珠颜色异常或闪烁（电源波纹太大），请务必焊接该电容。 Type-C 5.1K 电阻: 位于 CC1/CC2。如果不焊接，将无法识别双头 Type-C 线供电（只能用 A-to-C 线）。 匀光材料 (关键): 建议使用 1.0mm 半透黑色亚克力 作为前盖面板。 配合 PET LGT075J 匀光膜 使用，可以让 LED 像素感更加匀称，不刺眼。","link":"/mcompass/bom.html"},{"title":"Projects","text":".project-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); gap: 25px; margin-top: 30px; } .project-card { background: #fff; border: 1px solid #eee; border-radius: 12px; overflow: hidden; transition: transform 0.3s ease, box-shadow 0.3s ease; display: flex; flex-direction: column; height: 100%; } .project-card:hover { transform: translateY(-8px); box-shadow: 0 10px 25px rgba(0,0,0,0.08); } .project-image { width: 100%; height: 180px; background-size: cover; background-position: center; background-color: #f5f5f5; } .project-content { padding: 20px; flex: 1; display: flex; flex-direction: column; } .project-title { font-size: 1.4rem; font-weight: bold; margin-bottom: 10px; color: #333; } .project-desc { font-size: 0.95rem; color: #666; line-height: 1.6; margin-bottom: 15px; flex: 1; } .project-tags { display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 20px; } .tag { font-size: 0.75rem; padding: 3px 10px; background: #f0f0f0; color: #888; border-radius: 20px; } .project-links { display: flex; gap: 12px; border-top: 1px solid #f5f5f5; padding-top: 15px; } .btn-primary { background: #2bbc8a; color: white !important; padding: 8px 16px; border-radius: 6px; text-decoration: none; font-size: 0.9rem; font-weight: 500; transition: opacity 0.2s; background-image: none !important; border-bottom: none !important; display: inline-block; text-align: center; } .btn-secondary { background: #f5f5f5; color: #666 !important; padding: 8px 16px; border-radius: 6px; text-decoration: none; font-size: 0.9rem; transition: background 0.2s; background-image: none !important; border-bottom: none !important; display: inline-block; text-align: center; } .btn-primary:hover, .btn-secondary:hover { opacity: 0.8; } 项目展示 / Projects这里记录了我的一些开源 DIY 项目，涵盖硬件设计、内核驱动及跨平台应用集成。 MCompass ESP32-C3 Hardware Compass 利用 ESP32-C3 结合高精度磁力计，在现实中还原 Minecraft 指南针的跳动感。支持 GPS 动态定位与动态过冲物理模拟。 Star 制作指南 Git Friday Ink CH582F EPD Low Power 超低功耗墨水屏时钟，深度优化休眠电流至 3μA。旨在用最优雅的方式回答：今天是周五吗？ Star 项目详情 Git 更多有趣的小玩意儿正在整理中…","link":"/projects/index.html"},{"title":"免责声明","text":"技术风险提示本站（Chaosgoo）发布的所有关于嵌入式系统、硬件电路设计（如 ESP32、WCH 芯片）、焊接、3D 打印及软件开发的内容仅供参考和教育目的。硬件开发涉及电力安全、高温焊接和机械操作，任何操作均存在烧毁设备、引发火灾或造成人身伤害的风险。读者在参考本站内容进行实践时，需具备相应的专业背景，并对自己的行为承担全部责任。 内容准确性尽管站长（Chaos Goo）努力确保文章内容的准确性，但技术环境、库版本（如 LVGL, ESP-IDF）及硬件参数更新迅速。本站不保证所有信息在任何时间点都是完整、准确或最新的。 第三方链接本站可能包含指向外部网站或资源的链接。这些链接仅为方便读者提供，本站无法控制这些外部站点的内容，且不对其准确性、合法性或安全性负责。 广告与附属链接本站可能会展示由 Google AdSense 提供的广告。广告内容由第三方系统自动生成，并不代表本站对该产品或服务的认可。","link":"/disclaimer/index.html"},{"title":"使用条款","text":"最后更新日期： 2025-11-01 欢迎访问本博客（以下简称 “本站”）。本使用条款（以下简称 “条款”）旨在规范你（用户）访问和使用本站的所有行为。通过访问、浏览或使用本站内容及服务，即表示你已阅读、理解并同意遵守本条款的全部规定。若你不同意本条款，请勿使用本站。​ 一、网站使用范围​本站是个人非商业性质博客，主要分享 DIY 硬件制作、芯片使用经验、代码片段、3D 建模与打印作品及个人日常分享（以下简称 “内容”），仅为用户提供信息参考 and 交流用途。​ 你有权在遵守本条款及相关法律法规的前提下，自由浏览、阅读本站公开内容。​ 二、用户权利与义务​年龄限制声明： 未满 18 周岁的用户，需在父母或法定监护人的指导和监督下使用本站。 合法使用义务：你承诺使用本站时，不得违反任何国家 / 地区法律法规、公序良俗，不得实施以下行为： 未经授权获取、篡改本站数据、代码或后台信息； 传播恶意软件、病毒、垃圾信息，或进行网络攻击、爬虫滥用等破坏本站运行的行为； 发布、传播违法、色情、暴力、诽谤、侵权等不良信息； 冒充本站作者或其他用户，进行欺诈、误导他人的行为。 互动规范： 若你通过电子邮件或其他方式参与互动，需对自身发布的内容（如邮件内容）承担全部责任，确保内容真实、合法，不侵犯第三方权益。本站有权根据自身判断，删除违规互动内容或限制你的互动权限。 账号使用：若本站后续开通用户注册功能，你需妥善保管账号密码，对账号下的所有行为负责。若发现账号被盗用，应及时联系本站处理，本站不承担未及时通知导致的损失。 三、内容知识产权声明​本站所有原创内容（包括但不限于文字、代码、图片、视频、3D 模型文件等）的知识产权均归本站作者（以下简称 “作者”）所有，受《著作权法》《商标法》等相关法律法规保护。​ 非商业性合理使用：你可在以下条件下引用、分享本站原创内容：​ 需注明内容来源（如 “转载自 Chaosgoo | ESP32, IoT &amp; Hardware DIY Tech Blog”）及作者信息；​ 不得修改、篡改内容的核心信息及完整性；​ 不得用于商业用途（包括但不限于盈利性宣传、售卖、二次创作后商用等）。​ 禁止侵权使用：未经作者书面授权，任何单位或个人不得擅自复制、转载、传播、商用本站原创内容，否则作者有权追究其法律责任。​ 第三方内容声明：本站部分引用的图片、代码片段、参考资料等第三方内容，其知识产权归原权利人所有。若相关权利人认为本站内容侵犯其权益，请及时联系作者，作者将在核实后尽快处理（如删除、标注正确来源等）。​ 四、免责声明​本站内容均为作者基于个人经验、兴趣分享的原创内容，仅为参考交流之用，不构成专业建议（如技术指导、投资建议等）。你根据本站内容进行的任何操作（如硬件制作、代码使用、3D 打印等），风险由你自行承担，作者不承担因操作不当导致的任何损失（包括但不限于设备损坏、数据丢失等）。​ 本站力求内容准确、完整，但不保证内容无错误、无遗漏，也不保证网站服务的连续性、稳定性（如因服务器故障、网络问题等导致无法访问）。作者有权随时修改、更新或删除本站内容，无需提前通知用户。​ 对于因不可抗力（如自然灾害、政策变动等）、第三方行为（如网络攻击、黑客入侵等）导致的本站服务中断或内容损失，作者不承担任何责任。​ 你通过本站链接访问第三方网站（如芯片官网、工具下载平台等），相关网站的使用条款和隐私政策与本站无关，作者不承担第三方网站的任何责任。​ 五、条款的修改与更新​作者有权根据法律法规变化、网站运营需求等情况，随时修改本条款。​ 条款修改后，将在本站显著位置更新发布，更新后的条款自发布之日起生效。​ 你继续使用本站，即视为同意修改后的条款；若你不同意，应立即停止使用本站。​ 六、争议解决​本条款的解释与执行均适用你所在地区的法律法规。​ 因使用本站产生的任何争议，你与作者应首先通过友好协商解决；协商不成的，可向有管辖权的人民法院提起诉讼。​ 七、联系我们​若你对本条款有任何疑问、建议或投诉，请通过以下方式联系作者：​admin@chaosgoo.com","link":"/terms/index.html"},{"title":"Contact Us","text":"If you have any questions, suggestions regarding the content of this site (such as ESP32 development, Android technical sharing, etc.), or have business cooperation intentions, please feel free to contact me through the following methods. EmailThis is the most recommended way to contact, usually replying within 24-48 hours. admin@chaosgoo.comsindoutriqua@gmail.com (It is recommended to state your purpose in the email subject, e.g., “Question about [Article Title]”) Social MediaYou can also follow my latest updates through the following platforms: Bilibili: Visit my Bilibili homepage (Sharing hardware production videos) GitHub: Visit my GitHub (Get project source code) Copyright NoticeAll original articles and code on this site are not to be reproduced without authorization. For reproduction or citation, please contact via email for confirmation first.","link":"/en/contact/index.html"},{"title":"Disclaimer","text":"Technical Risk HintAll content published on this site (Chaosgoo) regarding embedded systems, hardware circuit design (such as ESP32, WCH chips), soldering, 3D printing, and software development is for reference and educational purposes only. Hardware development involves electrical safety, high-temperature soldering, and mechanical operations. Any operation carries risks of burning equipment, causing fires, or personal injury. Readers who practice based on the content of this site must have a corresponding professional background and take full responsibility for their actions. Accuracy of InformationAlthough the webmaster (Chaos Goo) strives to ensure the accuracy of the article content, technical environments, library versions (such as LVGL, ESP-IDF), and hardware parameters change rapidly. This site does not guarantee that all information is complete, accurate, or up-to-date at any point in time. The technical information on this site is provided “as is” without any warranties. Third-party LinksThis site may contain links to external websites or resources. These links are provided for convenience only. This site has no control over the content of these external sites and is not responsible for their accuracy, legality, or security. Ads and AffiliatesThis site may display advertisements provided by Google AdSense. Advertisement content is automatically generated by third-party systems and does not represent an endorsement of any project, product, or service by this site.","link":"/en/disclaimer/index.html"},{"title":"MCompass BOM &amp; 3D Models","text":"本文同时提供以下语言的翻译： 中文. Back to Build Guide MCompass Structural Parts (3D Model)If you have a 3D printer (Bambu Lab series recommended), you can go directly to MakerWorld to download the project files with pre-configured material parameters. Official Model: MakerWorld - MCompass (The Lost Compass) Printing Suggestions: PLA or PETG is recommended. A black shell with an appropriate infill rate provides a better texture. Bill of Materials (BOM)Some parts may differ from those on EasyEDA Open Source Square but are compatible with this design. Core Chips &amp; Modules Category Name Specs Notes MCU ESP32-C3-MINI Magnetometer QMC5883L / P LGA-16 3x3 L is discontinued (mostly refurbished), P is recommended GPS ATGM336H-5N71 13.1x15.7mm Ceramic antenna included LED WS2812B 0807 1.7x2.0x0.85mm 42 pcs required, frosted beads recommended Battery 213455 Li-Po 500mAh Size must strictly match the shell space Critical Components LDO: AP2112K-3.3 or ME6211 (budget-friendly) Charger: MCP73831 USB Port: GT-USB-7010ASV (USB-C 16P) Fasteners: Knurled Nuts: M2x3x3.2 (heat-set into the shell) Screws: M2x4 Hex Socket Selection Advice &amp; Troubleshooting C1206 100uF Capacitor: Not mandatory. If you encounter abnormal LED colors or flickering (high power ripple), be sure to solder this capacitor. Type-C 5.1K Resistors: Located at CC1/CC2. If not soldered, dual-head Type-C cables will not be recognized (only A-to-C cables will work). Diffuser Material (Crucial): It is recommended to use 1.0mm semi-transparent black acrylic as the front panel. Use with PET LGT075J diffuser film to make the LED pixels more uniform and less glaring.","link":"/en/mcompass/bom.html"},{"title":"MCompass Firmware &amp; Compilation","text":"本文同时提供以下语言的翻译： 中文. Back to Build Guide How to Get FirmwareIf you don’t plan to modify the source code, you can directly download the pre-compiled binary files (Firmware). 1. Download from GitHub Actions (Recommended)This project is configured with GitHub Actions for automatic compilation. This way, you can always get the firmware corresponding to the latest code: Go to the Actions page of the GitHub project. Find the most recent successful “Build Firmware Workflow” record. In the Artifacts section at the bottom of the page, select the corresponding .bin file according to your needs: Filename Keyword Description GPS Version with GPS module installed LITE Standard version (No GPS or GPS shielded) BLE Bluetooth mode enabled by default WIFI WiFi mode enabled by default (Web Dashboard) 2. Manual CompilationThis project is managed using PlatformIO: Firmware: Based on the Arduino framework, dependency libraries have been fully migrated to the local lib folder. Web Resources (Web Server): The WiFi mode backend is developed using Next.js. Enter the Server folder, run npm i and npm run build. Copy the generated out directory contents to the data folder of the firmware. Use Firmware/assets/compass_web_data.py to compress resources to reduce Flash occupancy. Flashing Guide1. Using Official Tool (PC)Download Flash Download Tool: Chip Selection: ESP32-C3 DownLoad Mode: USB File Selection: Load the downloaded .bin file to address 0x0. Parameters: SPI SPEED: 40MHz, SPI MODE: DIO. Note: The firmware has merged bootloader and partition table, so you only need to flash to 0x0. 2. Using Mobile Phone (Android)If you don’t have a computer nearby, you can use ESPFlash, developed by the author, to flash directly via mobile phone USB: Disclaimer Copyright: Minecraft pixel assets used in this project are copyrighted by Microsoft/Mojang. The panel file of this project serves only as a pixel distribution diagram and does not provide original compass textures. Commercial Use Prohibited: The “Standard Galactic Alphabet” font used on the back of the PCB is copyrighted by the original author. For any commercial activities, be sure to delete the silkscreen text on the back.","link":"/en/mcompass/guide.html"},{"title":"MCompass Build Guide","text":"本文同时提供以下语言的翻译： 中文. The Real-life Minecraft Compass Welcome to the MCompass build guide. Here you can find all the technical details from material preparation, automated compilation, firmware flashing to daily interactions. Quick Navigation BOM & 3D Models Check the complete parts list, selection advice, and 3D printing models. Flash & Compilation Download existing firmware from GitHub or compile manually using PlatformIO. User Manual Learn how to operate buttons to switch modes, calibrate sensors, and enter the web dashboard. EasyEDA Open Source PCB GitHub Repository Important Disclaimer (Copyright &amp; Safety)Before using or building MCompass, please be sure to read the following statement: Assets Disclaimer: All visual assets related to Minecraft are copyrighted by Microsoft / Mojang. This project only provides open-source designs based on dot matrix distribution and does not distribute any original game resources. Commercial Use Restrictions: Strictly Prohibited for any commercial profit-making activities. The copyright of the Standard Galactic Alphabet font used on the back of the PCB is unclear. If you wish to commercialize, please delete the relevant silkscreen on your own. Build Tips: This device involves lithium battery charging and small electronic component soldering. Please proceed with basic knowledge of electronic production. Q&amp;A Q: How long does GPS positioning take? A: The module usually takes more than 30 seconds for the first fix (cold start) in an open area. Q: What does it mean if the screen shows a green \"x4\" after startup? A: This represents an I2C communication failure, usually caused by poor soldering of the QMC5883 sensor or the header pins. Q: Does it support charging with a dual-head Type-C cable? A: You need to solder the corresponding CC1/CC2 pull-down resistors on the PCB to recognize C-to-C cables. Changelog 2025.09.17 Pointer Overshoot Effect: Perfectly replicates the bouncy feel in the game. The pointer creates physical inertia when turning quickly. Startup fault tolerance optimization: Multiple checks for the geomagnetic sensor to improve startup stability. 2024.12.07 Smart Power Strategy: Dynamically toggles GPS according to distance to extend battery life. Back to Projects","link":"/en/mcompass/index.html"},{"title":"MCompass Interaction &amp; Manual","text":"本文同时提供以下语言的翻译： 中文. Back to Build Guide Button Interaction LogicAll operations of MCompass are completed via a single button on the side. Actions Description Notes Single Click Switch Mode Toggle between “Spawn Point Mode” and “Compass Mode” Click 4 Times Check Status In Web mode, it displays the current IP address Click 6 Times Compass Calibration After the countdown, rotate the compass in a steady “8” pattern in the air Click 8 Times Factory Reset Clear all saved configurations and restart to the initial state Long Press 3s Special Actions Spawn Mode: Set Current Position as new spawn point (GPS req.)Compass Mode: Switch to Nether Mode, where the pointer spins randomly Note: Compass calibration is crucial for accuracy. If the pointer deviation is too large, please perform calibration. Configuration Modes1. Bluetooth Dashboard (WeChat Mini Program)Within 1 minute of startup, you can connect via the WeChat Mini Program “罗盘控制台” (Compass Console). Features: Customize pointer colors, calibrate sensors, select/search target coordinates via a map. Note: Ensure Bluetooth and location permissions are enabled on your phone. 2. Web DashboardIf Bluetooth is not connected, the device will try to connect to an existing WiFi; if no WiFi is configured, it will open an AP hotspot named The Lost Compass. How to Enter: After connecting to the hotspot, visit esp32.local or 192.168.4.1 in your browser. Advanced Actions: You can manage GZIP compression, change WiFi settings, and debug sensor values in real-time. Special Status Explanations Pointer Spinning Randomly: In Nether Mode (manually enabled via long press). In Spawn/Compass mode, but no GPS signal (please go outdoors or to an open area). Green “x4” displayed: Indicates an I2C communication error, meaning the geomagnetic sensor (QMC5883) cannot be recognized. Please check soldering or chip damage.","link":"/en/mcompass/manual.html"},{"title":"Terms of Use","text":"Last Updated: November 01, 2025 Welcome to this blog (hereinafter referred to as “this site”). These Terms of Use (hereinafter referred to as “Terms”) are intended to regulate all behaviors of you (the user) accessing and using this site. By accessing, browsing, or using the content and services of this site, you indicate that you have read, understood, and agreed to abide by all the provisions of these Terms. If you do not agree to these Terms, please do not use this site. 1. Scope of Website UseThis site is a personal non-commercial blog, mainly sharing DIY hardware production, chip experience, code snippets, 3D modeling and printing works, and personal daily sharing (hereinafter referred to as “Content”), provided for information reference and exchange purposes only. You have the right to freely browse and read the public content of this site under the premise of complying with these Terms and relevant laws and regulations. 2. User Rights and ObligationsAge Restriction Statement: Users under the age of 18 must use this site under the guidance and supervision of a parent or legal guardian. Legal Use Obligations: You promise that when using this site, you will not violate any national/regional laws and regulations, or public order and good customs, and will not implement the following behaviors: Unauthorized access to or tampering with the data, code, or background information of this site; Spreading malicious software, viruses, spam, or conducting network attacks, crawler abuse, and other behaviors that damage the operation of this site; Publishing or spreading illegal, pornographic, violent, defamatory, infringing, or other harmful information; Impersonating the author of this site or other users, conducting fraud, or misleading others. Interaction Norms: If you participate in interaction through email or other means, you are fully responsible for the content you publish (such as email content), ensuring the content is true and legal, and does not infringe on third-party rights. This site has the right to delete violating interactive content or restrict your interaction permissions based on its own judgment. Account Use: If this site opens a user registration function in the future, you must properly keep your account password and be responsible for all behaviors under the account. If you find your account has been stolen, you should contact this site in time for processing. 3. Intellectual Property StatementThe intellectual property rights of all original content on this site (including but not limited to text, code, pictures, videos, 3D model files, etc.) belong to the author of this site (hereinafter referred to as “the Author”). Non-commercial Fair Use: You may cite and share the original content of this site under the following conditions: Must indicate the source (e.g., “Reprinted from Chaosgoo | ESP32, IoT &amp; Hardware DIY Tech Blog”) and author information; Core information and integrity of the content must not be modified or tampered with; Must not be used for commercial purposes (including but not limited to profitable publicity, selling, secondary creation for commercial use, etc.). Prohibition of Infringing Use: Without the written authorization of the Author, no unit or individual may copy, reprint, spread, or commercialize the original content of this site without authorization. 4. DisclaimerThe content of this site is original content shared by the Author based on personal experience and interests, for reference and exchange only, and does not constitute professional advice. Any operations you conduct based on the content of this site (such as hardware production, code use, 3D printing, etc.) are at your own risk. 5. Modification and Update of TermsThe Author has the right to modify these Terms at any time according to changes in laws and regulations or website operation needs. 6. Dispute ResolutionThe interpretation and execution of these Terms are subject to the laws and regulations of your region. 7. Contact UsIf you have any questions, suggestions, or complaints about these Terms, please contact the Author:admin@chaosgoo.com","link":"/en/terms/index.html"},{"title":"Privacy Policy","text":"Effective Date: October 10, 2025Last Updated: February 02, 2026 Welcome to Chaosgoo | ESP32, IoT &amp; Hardware DIY Blog (hereinafter referred to as “this website”). We understand the importance of privacy to you, and this policy is intended to explain how this website collects, uses, and protects your information during operation. 1. Information We CollectAs a static blog, this website does not actively collect Personal Identifiable Information (PII) unless you provide it voluntarily: Direct Contact Data: If you proactively contact us via email or other means, we will collect the contact information you provide (such as your email address and message content) for the purpose of responding and communicating. 2. Information Collected via Third-Party Services (Key Disclosures)This website uses the following third-party services to optimize the user experience, which may indirectly collect your non-personal information and usage data. A. Google AdSense (Advertising Service) Google AdSense: Google, as a third-party vendor, uses cookies to serve ads based on a user’s prior visits to this website and other websites on the internet. Google Ad Settings: You may opt out of personalized advertising by visiting Google Ad Settings. Google Advertising Privacy Policy: Visit Google Advertising Privacy Policy to understand Google’s advertising practices in detail. B. Google Analytics (Analysis Service) This website uses Google Analytics to analyze traffic. This service may collect data such as your IP address, browser type, device info, pages visited, and visit duration. This data is used solely for statistical analysis to improve the content and structure of this website. IP Anonymization: We have enabled the IP anonymization feature (anonymizeIp) in Google Analytics to further protect your privacy. Privacy Policy: You can visit Google Analytics Privacy Policy for detailed information. C. Cookies and Other Tracking TechnologiesThis website and the third-party services mentioned above use cookies (small text files stored on your device) to record your preferences, track visit activity, and maintain session states. If advertising services are enabled, cookies will also be used for ad serving. Google Analytics Cookie Details Cookie Name Purpose Retention _ga Distinguishes users; generates a unique client ID 2 years _ga_&lt;ID&gt; Maintains session state 2 years _gid Distinguishes users 24 hours _gat Limits request rate 1 minute Data Recipient: Google LLC acts as our analysis data processor. Data Retention: We only view anonymous aggregated reports in the Analytics console. Google AdSense Cookie Details (If Enabled)If Google AdSense is enabled on this website, the following cookies may be used: Cookie Name Purpose Retention __gads Serves ads and measures ad performance 13 months __gpi Used for ad personalization 13 months DSID Identifies logged-in users for ad personalization 2 weeks IDE Used for displaying Google ads 13 months Managing CookiesYou have the right to refuse or delete cookies at any time through your browser settings, but this may affect your ability to access this website or use certain third-party features. 3. Use of InformationThe information we collect is primarily used for the following purposes: Operating and maintaining the normal functioning of this website. Analyzing user behavior to improve and optimize website content and user experience. Displaying relevant advertisements via Google AdSense if enabled. Responding to and processing your inquiries or suggestions. 4. Information Sharing and DisclosureUnless required by law or with your explicit consent, this website commits not to sell, trade, or transfer your personal information to any unrelated third parties. 5. External LinksThis website may contain links to other websites. We are not responsible for the content, security measures, or privacy practices of these external sites. We suggest you carefully read the privacy policy of any external site you visit. 6. Third-Party Services &amp; ResourcesWe strive to choose transparent and compliant service providers. Here is the full list of currently used third-party services: Service Name Purpose Privacy Policy / Details Google Analytics Anonymous traffic stats Privacy Policy Google AdSense Personalized or generic ads Ad Privacy Google Tag Manager Loads Analytics and AdSense scripts GTM Details jsDelivr / Font Awesome Static assets, CSS, and fonts Static files only, no PII collected About CDN ServicesThis website uses CDNs (such as jsDelivr, Font Awesome) to load necessary static assets. These services are used only for transmitting public library files and do not actively collect your personal identifiable information. 7. Your Rights (GDPR/CCPA)According to regulations such as GDPR/CCPA, you have the right to access, correct, delete your personal data, or object to processing. Contact Us: Please email admin@chaosgoo.com. We will respond within 30 days and coordinate with third parties like Google to delete relevant data if possible. Opt-out of Google Analytics: Install the Google Analytics Opt-out Browser Add-on. Manage Google Ads: Visit Google Ad Settings to opt out. 8. Children’s Privacy ProtectionThis website is intended for users 13 years and older. We do not knowingly collect any personal data from children under 13. 9. Contact UsIf you have any questions or concerns regarding this privacy policy or the processing of your personal information, please feel free to contact the administrator: Administrator: chaosgoo Email: admin@chaosgoo.com (Preferred) sindoutriqua@gmail.com","link":"/en/privacy-policy/index.html"},{"title":"Projects","text":".project-grid { display: grid; grid-template-columns: repeat(auto-fill, minmax(320px, 1fr)); gap: 25px; margin-top: 30px; } .project-card { background: #fff; border: 1px solid #eee; border-radius: 12px; overflow: hidden; transition: transform 0.3s ease, box-shadow 0.3s ease; display: flex; flex-direction: column; height: 100%; } .project-card:hover { transform: translateY(-8px); box-shadow: 0 10px 25px rgba(0,0,0,0.08); } .project-image { width: 100%; height: 180px; background-size: cover; background-position: center; background-color: #f5f5f5; } .project-content { padding: 20px; flex: 1; display: flex; flex-direction: column; } .project-title { font-size: 1.4rem; font-weight: bold; margin-bottom: 10px; color: #333; } .project-desc { font-size: 0.95rem; color: #666; line-height: 1.6; margin-bottom: 15px; flex: 1; } .project-tags { display: flex; flex-wrap: wrap; gap: 8px; margin-bottom: 20px; } .tag { font-size: 0.75rem; padding: 3px 10px; background: #f0f0f0; color: #888; border-radius: 20px; } .project-links { display: flex; gap: 12px; border-top: 1px solid #f5f5f5; padding-top: 15px; } .btn-primary { background: #2bbc8a; color: white !important; padding: 8px 16px; border-radius: 6px; text-decoration: none; font-size: 0.9rem; font-weight: 500; transition: opacity 0.2s; background-image: none !important; border-bottom: none !important; display: inline-block; text-align: center; } .btn-secondary { background: #f5f5f5; color: #666 !important; padding: 8px 16px; border-radius: 6px; text-decoration: none; font-size: 0.9rem; transition: background 0.2s; background-image: none !important; border-bottom: none !important; display: inline-block; text-align: center; } .btn-primary:hover, .btn-secondary:hover { opacity: 0.8; } ProjectsHere are some of my open-source DIY projects, covering hardware design, kernel drivers, and cross-platform application integration. MCompass ESP32-C3 Hardware Compass A real-life Minecraft compass powered by ESP32-C3 and high-precision magnetometer. Features GPS dynamic positioning and physical overshoot simulation. Star Build Guide Git Friday Ink CH582F EPD Low Power Ultra-low power E-ink clock with sleep current optimized to 3μA. Designed to answer the most elegant question: Is it Friday today? Star Details Git More interesting things are coming soon…","link":"/en/projects/index.html"},{"title":"About Chaosgoo","text":"Chaosgoo is an independently run technical blog created and maintained by Chaos Goo. This website focuses on publishing original practical technical articles related to embedded systems, electronic engineering, and the combination of software and hardware. All content on this site is written, edited, and maintained by the webmaster based on real development and engineering practices. This site is under continuous maintenance and is planned for long-term publication.There is no collected, automatically generated, or aggregated content on this site. For inquiries regarding content, copyright, or advertising cooperation, please contact the webmaster via admin@chaosgoo.com. About Me Hello~ I’m Goo (Chaos Goo), a DIY enthusiast. Here I record experimental code, debugging experience, and design ideas during the development process, while preserving thoughts and summaries from actual development. Tech Stack &amp; Specialties Domain Technolgies / Tools Embedded Development ESP32 / ESP-IDF / ESP8266 / WCH (CH58x/CH592) / Arduino GUI Frameworks LVGL / FreeType Font Engine / TFT_eSPI Smart Home HomeKit / Home Assistant / MQTT Mobile Development Android (Kotlin / Flutter) Hardware Design KiCad / Fusion 360 / 3D Printing (Bambu Lab P1SC) Version Control Git / GitHub Core Exploration Directions Creative Applications of Low-cost Chips: Primarily using the Espressif ESP32 series, independently completing the entire process from conception to PCB design, soldering, and firmware development. WCH Chip Exploration: Recently unlocking ultra-low power chips like CH58x/CH592, researching extreme applications of Bluetooth BLE + E-ink screens. Game Prop Replicas: Not just achieving a similar appearance, but replicating core functions — lighting, sound effects, and interactive animations. Featured Projects Project Description Link ESPFlash ESP32 flashing tool for Android, available on Google Play Play Store SerialFlow Android serial monitor with search filtering, available on Google Play Play Store CS2 HealthPin Real-life CS2 Health Pin, supports real-time synchronization via Game GSI Post Friday Ink Ultra-low power E-ink clock based on CH582F (≈3μA sleep) Post LVGL FreeType Series Dynamic font weights on ESP32 (50,000+ views) Series Hardware Gear 3D Printer: Bambu Lab P1SC (Custom enclosures and mechanical parts) Modeling Software: Fusion 360 (Lighter and easier than Inventor) Contact Email: admin@chaosgoo.com GitHub: github.com/chaosgoo Bilibili: Personal Homepage YouTube: @chaosgoo This email address is managed directly by the webmaster. Copyright NoticeThis site serves as the author’s only official technical archive and is continuously updated. All original articles, code snippets, and project materials are released under the CC BY-NC 4.0 license. Early versions of some articles on this site were published on other platforms, but have now been revised, integrated, and are exclusively maintained by this site.All content is created for educational and informational purposes and is reviewed before publication.This site does not accept user-generated content or public submissions.Any advertisements displayed on this site do not affect editorial decisions or content creation. Ads &amp; CommercializationThis website may display third-party advertisements (such as Google AdSense) to support website hosting and ongoing content creation. Advertising does not affect editorial independence. Historical Accounts Bilibili (Old): uid:14374079 (Closed) Jianshu: 一只不咕的鸽子 (Discontinued)","link":"/en/about/index.html"}]}